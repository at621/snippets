Great, I will analyze how AI-driven transformations are reshaping the risk management departments of commercial universal banks like ING and HSBC, with a focus on the European Union. I will examine:

- The current distribution of roles within a typical 100-person risk department.
- How AI will shift this distribution over the next three years.
- The evolution of each role in terms of responsibilities, skills, and daily tasks.
- The types of professionals and skill sets that will thrive in this AI-driven landscape.
- Specific steps that risk professionals should take to stay competitive in this evolving field.

I will let you know once the analysis is ready.

# AI-Driven Transformations in Risk Management Departments

AI is rapidly reshaping risk management in universal banks. Advanced analytics and machine learning can automate many traditional risk tasks, from credit scoring to fraud detection. European banks like ING and HSBC are embracing these tools but must do so within a strict regulatory environment (e.g. GDPR data privacy rules, Basel III/IV capital regulations, and forthcoming EU AI Act requirements). As a result, risk departments are evolving **cautiously** – seeking efficiency gains while ensuring compliance and sound governance ([Citi: AI threatens 54% of current banking jobs, but will create new ones](https://www.computing.co.uk/news/4327380/citi-ai-threatens-54-current-banking-jobs-create-ones#:~:text=The%20banking%20sector%20is%20data,are%20all%20potential%20problem%20areas)). Below, we analyze how a 100-person risk management team’s composition and roles might change over the next three years under AI’s influence, focusing on EU banks.

## Current Distribution of Roles (100-Person Risk Department)

In a typical 100-person risk management department at a large universal bank, roles span a wide range of specialized functions ([Transforming risk efficiency and effectiveness | McKinsey](https://www.mckinsey.com/capabilities/risk-and-resilience/our-insights/transforming-risk-efficiency-and-effectiveness#:~:text=However%2C%20efforts%20to%20improve%20risk,Banking%20regulators%20remain)). A possible current breakdown is as follows (approximate headcount out of 100):

- **Risk Modelers (~12):** Experts who develop quantitative risk models (e.g. credit scoring, market risk, capital models) to meet regulatory standards like Basel III/IV. They focus on statistical modeling (PD/LGD models, VaR, etc.), model validation, and documentation to satisfy regulators’ rigorous requirements.  
- **Credit Decision Makers (~15):** Credit risk officers and underwriters who approve or veto loans and counterparty exposures. They evaluate credit applications, large corporate deals, and portfolio limits in line with the bank’s risk appetite and policies. Much of their work is judgment-based, reviewing analyses and using experience to make lending decisions.  
- **Policy & Governance Specialists (~10):** Staff dedicated to crafting risk policies, frameworks, and governance processes. They maintain the bank’s risk appetite statement, internal controls, and ensure alignment with regulatory guidelines (e.g. ensuring internal processes comply with Basel III/IV and ECB/EBA guidance). They also organize risk committees and reporting structures.  
- **Compliance & Regulatory Analysts (~15):** Professionals focused on regulatory compliance, monitoring and reporting. They ensure the bank adheres to laws and regulations (AML, KYC, conduct rules) and prepare regulatory filings (e.g. Basel capital reports, stress test results). They review transactions for compliance and handle audits. This has become a sizable group given the post-2008 rise in regulatory requirements.  
- **Data Analysts (~10):** Analysts who gather, clean, and report risk data. They produce risk dashboards, portfolio reports, and analytics for management. Often they perform routine data extraction and trend analysis (credit portfolio performance, operational loss stats, etc.), supporting decision-makers with data-driven insights.  
- **Data Scientists (~8):** A smaller but growing group of specialists applying data science and machine learning to risk problems. They work on advanced analytics projects (e.g. improving fraud detection models, developing AI tools for credit risk) and prototyping new modeling techniques beyond traditional statistics.  
- **Risk & Operations Analysts (~10):** General risk analysts and operational risk managers who run day-to-day risk processes. This includes identifying and assessing non-financial risks (operational, cyber, reputational risk), tracking risk indicators, and coordinating risk incident responses. They handle risk control self-assessments, scenario analysis, and ensure risk processes run smoothly.  
- **IT/Data Engineering Support (~8):** Technical support staff assigned to the risk function. They manage risk IT systems (risk databases, model platforms) and data pipelines. They ensure data quality and implement risk software, working with the bank’s IT to support risk’s analytical needs (model runs, reporting systems).  
- **Project Managers/Coordinators (~5):** Personnel who manage risk-related projects and change initiatives. They coordinate cross-functional projects like new regulatory implementations (e.g. IFRS9, Basel changes), system upgrades, or AI pilot programs. They ensure timelines, compliance, and stakeholder alignment for risk initiatives.  
- **Other Support/Administration (~7):** Support staff handling administrative duties and miscellaneous support. This can include team assistants, documentation specialists, and training coordinators. They schedule meetings (e.g. risk committee meetings), maintain documentation, and support the CRO and risk managers in their daily administrative needs.

*Overall,* today’s risk department is highly specialized and labor-intensive, reflecting the diversity of expertise needed for effective risk management ([Transforming risk efficiency and effectiveness | McKinsey](https://www.mckinsey.com/capabilities/risk-and-resilience/our-insights/transforming-risk-efficiency-and-effectiveness#:~:text=However%2C%20efforts%20to%20improve%20risk,Banking%20regulators%20remain)). Many roles deal with manual processes, data aggregation, and compliance checks, which are targets for upcoming AI-driven automation.

## Projected Distribution in Three Years Due to AI

In the next three years, AI and automation are expected to significantly shift this team’s composition. Banks will automate routine, repetitive tasks and augment human decision-making with AI insights. According to industry studies, over half of banking jobs have high potential for automation, especially **back-office and analyst roles** ([Citi: AI threatens 54% of current banking jobs, but will create new ones](https://www.computing.co.uk/news/4327380/citi-ai-threatens-54-current-banking-jobs-create-ones#:~:text=As%20ever%2C%20automation%20is%20most,to%20be%20delegated%20to%20AI)). Risk management is no exception – many analytical and monitoring tasks can be handled by algorithms, allowing a leaner, more technically-focused team. Some estimates suggest an end-to-end risk transformation (with advanced analytics) can reduce risk function costs by up to ~20% ([Transforming risk efficiency and effectiveness | McKinsey](https://www.mckinsey.com/capabilities/risk-and-resilience/our-insights/transforming-risk-efficiency-and-effectiveness#:~:text=Fortunately%2C%20the%20most%20potent%20levers,and%20employee%20and%20customer%20experience)). This likely translates to a moderately smaller headcount or redeployment of staff into new roles. 

Assuming the department remains roughly ~100-strong (with some efficiency gains reinvested in new skills), a **future role distribution** might look like:

- **Risk Modelers (~8):** *Reduced.* Fewer traditional modelers are needed as AI-driven modeling tools (AutoML, etc.) handle more of the model development process. Some current modelers re-skill into “AI model developers,” while others focus on model oversight. The emphasis shifts from manually crafting statistical models to supervising and validating AI-generated models.  
- **Credit Decision Makers (~10):** *Reduced.* Routine credit decisions (especially for smaller exposures or retail loans) will be largely automated using AI credit scoring. Humans will handle exceptions and complex cases. Many credit officers transition to oversight roles – monitoring AI decision outcomes for fairness and accuracy rather than individually reviewing every application. The remaining credit officers focus on strategic credit policy and relationship-based judgments that AI can’t make.  
- **Policy & Governance Specialists (~9):** *Slightly reduced/redefined.* Policy teams become more centered on AI governance. While the headcount stays similar, their focus shifts to developing frameworks for **responsible AI use**, updating risk policies to cover AI-driven processes, and ensuring compliance with new AI regulations. For example, they will draft internal guidelines on algorithmic transparency, bias mitigation, and alignment with the EU’s AI governance expectations.  
- **Compliance & Regulatory Analysts (~12):** *Slightly reduced/redefined.* Compliance staff benefit from RegTech and AI that automate compliance monitoring (e.g. AI-powered transaction screening, automated regulatory report generation). This efficiency means slightly fewer analysts can cover the workload. Those remaining take on new duties as **AI compliance specialists** – overseeing AI systems for regulatory compliance and ethical issues. For instance, as AI systems in credit risk will likely be classified as “high-risk” under the EU AI Act, banks will create roles to ensure these systems have proper controls and documentation ([Risk managers, AI will replace you if you don’t upskill quickly | Opinion | Strategic Risk Global](https://www.strategic-risk-global.com/opinion/risk-managers-ai-will-replace-you-if-you-dont-upskill-quickly/1451903.article#:~:text=,requires%20specialised%20skills%20that%20may)). Thus, some traditional compliance analysts evolve into **“AI compliance managers”** and **AI ethics officers** ([Citi: AI threatens 54% of current banking jobs, but will create new ones](https://www.computing.co.uk/news/4327380/citi-ai-threatens-54-current-banking-jobs-create-ones#:~:text=However%2C%20while%20some%20jobs%20may,will%20become%20increasingly%20important)), focusing on algorithmic accountability (checking that AI decisions respect GDPR, fairness, etc.).  
- **Data Analysts (~5):** *Significantly reduced.* Much of the pure data crunching and report generation is handled by AI-driven BI tools and automated dashboards. Simple analysis that once required human effort (copying data between systems, compiling reports) will be delegated to AI ([Citi: AI threatens 54% of current banking jobs, but will create new ones](https://www.computing.co.uk/news/4327380/citi-ai-threatens-54-current-banking-jobs-create-ones#:~:text=As%20ever%2C%20automation%20is%20most,to%20be%20delegated%20to%20AI)). Many data analysts either up-skill into data science roles or are replaced by self-service AI analytics. The few that remain act as **data quality monitors and business interpreters**, validating AI outputs and ensuring data inputs are correct. They spend more time investigating anomalies flagged by AI rather than manually producing reports.  
- **Data Scientists & AI Specialists (~15):** *Increased and expanded.* This group grows as the engine of an AI-driven risk department. Banks will hire more data scientists, machine learning engineers, and AI specialists to build, maintain, and refine AI models. Their share of the team rises (from ~8 to ~15 or more). New roles here include **ML engineers** (to deploy models into production and manage model lifecycle) and specialists in areas like NLP for risk document analysis. These experts work on advanced use cases – e.g. improving credit risk models with machine learning, AI for fraud detection, scenario simulations, etc. Crucially, they also embed **explainability and bias checks** into models to satisfy regulators that models are “trustworthy” and compliant with EU requirements.  
- **Risk & Operations Analysts (~7):** *Reduced.* Operational risk management and other risk process roles shrink as AI tools take over routine monitoring. For example, AI can automatically scour incident logs and external news for potential operational risks, reducing manual scanning. Remaining analysts focus on interpreting AI-generated risk insights and coordinating responses. They become *risk interpreters* and strategic advisors rather than data gatherers. Additionally, a portion of them may shift to a **“model risk analyst”** function – i.e. managing the risk of the AI models themselves (validating model performance, ensuring controls around AI, etc., as required by model risk management policies).  
- **IT/Data Engineering Support (~10):** *Slightly increased.* The technical backbone of AI in risk demands strong IT and data engineering support. As more data streams and cloud-based AI tools are implemented, banks will invest in a few more specialists here. These team members set up and maintain the data infrastructure for AI (data lakes, model deployment pipelines, etc.). They also enforce data governance standards (in line with regulations like EBA guidelines on data management) so that AI models use high-quality, properly governed data.  
- **Project Managers/Coordinators (~5):** *Roughly stable.* There will still be numerous projects (AI implementation, regulatory changes, digital transformations) requiring coordination. Project managers will increasingly need to understand tech implementations. We may see slightly **fewer** pure project managers if agile squads handle some delivery, but those that remain likely manage complex initiatives (e.g. rolling out an enterprise-wide AI risk platform) and ensure AI projects meet compliance checkpoints.  
- **Other Support/Administration (~3):** *Reduced.* Administrative support needs diminish as automation and digital tools streamline workflows. Scheduling, documentation, and knowledge management are increasingly handled by collaboration software or AI assistants (for example, AI tools drafting meeting minutes or populating risk reports). A smaller number of support staff remain to oversee these tools and handle sensitive communications or exceptions that automation can’t cover.

- **New AI-Focused Roles (~15):** *Newly emerged positions.* As noted above, AI adoption gives rise to entirely new roles that did not exist before. We anticipate a cluster of around 15 people in new capacities such as:  
  - **AI Governance & Ethics Officers:** Overseeing the ethical use of AI and compliance with AI regulations. They develop standards for AI transparency, fairness, and security, working closely with Policy/Governance and Compliance teams. Citi’s analysis suggests that banks will create many such roles to address regulatory and ethical considerations ([Citi: AI threatens 54% of current banking jobs, but will create new ones](https://www.computing.co.uk/news/4327380/citi-ai-threatens-54-current-banking-jobs-create-ones#:~:text=However%2C%20while%20some%20jobs%20may,will%20become%20increasingly%20important)).  
  - **AI Model Validation Specialists:** A new breed of risk model validator focusing on machine learning models. They rigorously test AI models for bias, stability, and alignment with regulatory requirements (e.g. ensuring a credit ML model meets **“prudent use”** standards under Basel rules ([The EBA publishes follow-up Report on the use of machine learning for internal ratings-based models | European Banking Authority](https://www.eba.europa.eu/publications-and-media/press-releases/eba-publishes-follow-report-use-machine-learning-internal#:~:text=In%20this%20Report%2C%20the%20EBA,context%20of%20the%20IRB%20framework))). These specialists often come from risk modeler or validator backgrounds, now augmented with AI expertise.  
  - **AI/ML Ops Engineers:** Technical roles bridging risk and IT, responsible for the ongoing operation of AI models. They monitor model performance, implement updates, and guard against model drift. This ensures the AI tools remain accurate and compliant over time.  
  - **Data Privacy Risk Officers:** Focused on GDPR compliance in all AI-driven risk processes. They ensure that personal data used in risk models is handled lawfully, manage customer consent/issues for automated decisions, and liaise with the bank’s Data Protection Officer. This role grows in importance because AI can intensify privacy risks if not properly managed.  

In summary, the risk department of the near future will likely have **fewer traditional analysts and more tech-savvy experts.** Routine work will be heavily automated, while humans concentrate on oversight, strategy, and the “hard-to-automate” judgment calls. Notably, entirely new roles in AI governance and model risk are added to handle the **risks of the AI itself** ([Citi: AI threatens 54% of current banking jobs, but will create new ones](https://www.computing.co.uk/news/4327380/citi-ai-threatens-54-current-banking-jobs-create-ones#:~:text=However%2C%20while%20some%20jobs%20may,will%20become%20increasingly%20important)). The overall headcount might shrink modestly (if efficiency gains aren’t reinvested), but banks like ING and HSBC are more likely to redeploy people into new functions rather than see a net dramatic cut in risk staff over just three years. The **shape** of the team changes: a higher proportion of data scientists and AI specialists, and fewer pure process administrators.

## Evolution of Each Role in an AI-Driven Risk Department

Every role in the risk team will undergo some evolution in responsibilities, required skills, and daily tasks as AI tools become embedded in workflows. Below is how each role is expected to change:

- **Risk Modelers:**  Today’s risk modelers (often statisticians or quants) currently build risk models by hand (e.g. regression models for credit risk). Going forward, they will work *alongside AI*. **Auto-modeling** software might do the initial heavy lifting of model development, so modelers shift to a supervisory and tuning role. They’ll need to master machine learning techniques to validate and improve AI-generated models. For instance, rather than coding logistic regressions from scratch, they may fine-tune an ensemble model created by an AI tool and ensure it meets regulatory standards for explainability. Their documentation duties increase as well – regulators will demand detailed documentation on how AI models work and are controlled (aligned with **Basel’s model risk governance** and EBA’s guidance on prudent ML use ([The EBA publishes follow-up Report on the use of machine learning for internal ratings-based models | European Banking Authority](https://www.eba.europa.eu/publications-and-media/press-releases/eba-publishes-follow-report-use-machine-learning-internal#:~:text=In%20this%20Report%2C%20the%20EBA,context%20of%20the%20IRB%20framework))). In short, the role evolves from pure developer to **model risk manager** and AI technician – blending domain knowledge (risk theory, Basel norms) with data science skills (Python, ML algorithms). Communication skills become vital too: they must explain complex AI models to regulators and management in simple terms.

- **Credit Decision Makers:** These roles (credit officers, underwriters) will transition from being hands-on decision-makers to **augmented supervisors** of credit AI systems. Currently, they manually review credit applications and use their judgment to approve or decline. In three years, most standard credit decisions (especially retail and SME lending) will be made automatically by AI credit scoring engines. The credit officer’s new task is to **set the rules and review exceptions**. They will calibrate AI decision thresholds, define policy constraints (e.g. no lending to certain high-risk segments without human review), and handle the complex cases the AI flags. Their deep knowledge of credit policy and borrower behavior remains crucial, but now they apply it by overseeing model outputs and intervening only when necessary. These professionals will need to be comfortable reading model-generated risk reports and spotting when “something looks off” (e.g. if the AI starts approving loans outside expected policy boundaries). They’ll also play a role in ensuring **fair lending** – checking that the AI’s decisions comply with anti-discrimination laws and are explainable to customers, as required under GDPR’s automated decision rules. Essentially, credit officers become **credit AI curators**, focusing on strategy and quality control rather than individual transaction processing.

- **Policy & Governance Specialists:** The guardians of risk frameworks will increasingly incorporate **AI governance** into their remit. Today they focus on traditional areas (risk appetite, committee charters, policy manuals aligned with regulations like Basel). Going forward, their responsibilities broaden to cover **AI policy**: drafting guidelines on acceptable AI use cases, model validation standards, and AI risk assessment processes. They’ll lead efforts to ensure the bank’s AI use in risk is compliant with emerging frameworks – for example, implementing governance to fulfill the EU AI Act’s requirements for high-risk AI systems (which include credit scoring and AML). This means defining roles and accountability for AI outcomes, ensuring transparency (documentation of algorithms and decisions), and establishing AI oversight committees. A Policy Specialist might, for instance, create an internal policy that any AI model used in credit decisions must undergo bias testing and sign-off by a model risk committee. Their day-to-day will involve staying abreast of new regulatory guidance on AI (from bodies like the EBA, ECB, and national regulators) and updating internal policies accordingly. **Skills-wise**, they need a solid understanding of technology and data ethics in addition to classic risk governance know-how. In essence, they evolve into **“AI risk governance”** experts – bridging compliance, risk, and tech. 

- **Compliance & Regulatory Analysts:** Compliance officers will lean heavily on AI tools to monitor transactions and adherence to rules, which changes their workflow significantly. For example, instead of manually sampling transactions for AML, they might supervise an AI system that flags suspicious activities in real time. HSBC already uses AI to scan 1.35 billion transactions a month for financial crime, vastly improving detection and reducing false positives ([Harnessing the power of AI to fight financial crime | Views](https://www.hsbc.com/news-and-views/views/hsbc-views/harnessing-the-power-of-ai-to-fight-financial-crime#:~:text=At%20HSBC%2C%20we%20check%20about,to%20help%20us%20do%20this)) ([Harnessing the power of AI to fight financial crime | Views](https://www.hsbc.com/news-and-views/views/hsbc-views/harnessing-the-power-of-ai-to-fight-financial-crime#:~:text=The%20results%20speak%20for%20themselves,previously%2C%20with%20much%20greater%20accuracy)) – this kind of tool will become standard. Thus, compliance analysts will spend less time sifting through raw data and more time investigating the *alerts* that AI generates. Their investigative work becomes more targeted and efficient (since AI filters out noise). **Crucially,** they also take on new responsibilities to ensure the AI itself complies with regulations. They must validate that automated decisions meet regulatory expectations for fairness and customer protection. In the EU, if an AI system makes a credit decision, customers have rights under GDPR to explanation and human review; compliance teams must make sure those processes are in place. Additionally, with AI Act provisions classifying many financial AI applications as “high-risk”, compliance officers will need to maintain documentation and risk assessments for each AI model ([Risk managers, AI will replace you if you don’t upskill quickly | Opinion | Strategic Risk Global](https://www.strategic-risk-global.com/opinion/risk-managers-ai-will-replace-you-if-you-dont-upskill-quickly/1451903.article#:~:text=,requires%20specialised%20skills%20that%20may)). New sub-roles like **AI compliance manager** or **model ethics analyst** may emerge, as noted, to focus on these tasks ([Citi: AI threatens 54% of current banking jobs, but will create new ones](https://www.computing.co.uk/news/4327380/citi-ai-threatens-54-current-banking-jobs-create-ones#:~:text=However%2C%20while%20some%20jobs%20may,will%20become%20increasingly%20important)). In summary, compliance analysts become both *users of AI regtech* and *watchdogs over AI*, requiring them to be data-savvy, inquisitive, and knowledgeable about AI risks. Their skill set shifts toward understanding algorithms, data privacy (to ensure AI doesn’t misuse personal data), and coordinating with both IT and regulators on AI oversight.

- **Data Analysts:** Traditional data analyst roles are among the most affected by AI automation. Currently, they spend a lot of time on data preparation (extracting, cleaning, aggregating data) and producing routine reports (risk exposure summaries, trend analyses for risk committees). AI and advanced analytics platforms are rapidly automating these functions – for instance, self-service dashboards can auto-generate many periodic reports, and machine learning can clean and reconcile data faster than humans. As a result, the **volume of manual data grunt-work drops** sharply ([Citi: AI threatens 54% of current banking jobs, but will create new ones](https://www.computing.co.uk/news/4327380/citi-ai-threatens-54-current-banking-jobs-create-ones#:~:text=As%20ever%2C%20automation%20is%20most,to%20be%20delegated%20to%20AI)). The data analysts who thrive will be those who elevate their role: they will focus on interpreting results and ensuring data integrity for AI models. Rather than building every report from scratch, they’ll validate automated outputs and investigate anomalies or unexpected findings flagged by AI (acting as a quality check). They’ll also work closely with data scientists, perhaps assisting in feature selection or providing business context to model results. Many current data analysts may transition into **data science or BI developer roles** by learning new tools. Those who don’t upskill could see their traditional tasks disappear. Thus, the role evolves into a *data translator* position – sitting between raw data churned by AI and the risk managers who need to act on it. Key skills will include mastery of analytics software, understanding how to interrogate AI outputs, and strong communication to explain data insights. Data analysts will also need to be aware of **data governance** – ensuring the data used by AI is accurate, timely, and compliant with privacy rules (since garbage-in to an AI could mean flawed risk predictions).

- **Data Scientists:** Data scientists in the risk department move from a niche support role to a **central, mission-critical role**. Currently, a few data scientists might experiment with machine learning models for risk, but in three years these professionals will be driving many core risk processes (credit scoring models, fraud detection, market risk forecasts, etc.). Their responsibilities expand to end-to-end model development and deployment: they will identify opportunities where AI can improve risk decisions, develop models, and then work with IT to deploy those models into live systems. Crucially, they must do this in a controlled, transparent manner because of the regulatory context. For example, if a data scientist builds a complex neural network to approve loans, they must also devise ways to explain the model’s decisions to regulators and customers (perhaps using XAI – explainable AI – techniques). They’ll routinely collaborate with risk modelers and compliance officers to incorporate domain constraints (ensuring models don’t violate Basel capital rules or produce biased outcomes). **Skill needs:** in addition to programming (Python, R, etc.) and machine learning expertise, risk data scientists will need knowledge of finance regulations and “model risk management” principles. They should understand concepts like stress testing, capital calculations, and the bank’s risk appetite, so that the AI models align with these. Day-to-day, data scientists will likely spend more time on model monitoring and refinement in production, as opposed to just R&D. As the volume of models grows, they’ll implement tools to detect model drift or data quality issues early. Essentially, the data scientist role in risk becomes more multidisciplinary: part quant, part software engineer, part risk manager. Those who can integrate these skill sets will thrive, and their career path could even lead to titles like **“AI Risk Architect”** or **“Head of Risk Analytics”** as the field matures.

- **Risk & Operations Analysts:** Operational risk managers and general risk analysts will see their jobs augmented by AI in several ways. Today, they might collect risk event data, maintain risk registers, and produce qualitative analysis on scenarios. AI will help by **scanning large datasets and external information** to identify potential risks much faster. For instance, AI systems can monitor thousands of news sources and internal logs to spot emerging risks (cyber threats, fraud patterns) that a human might miss ([Risk managers, AI will replace you if you don’t upskill quickly | Opinion | Strategic Risk Global](https://www.strategic-risk-global.com/opinion/risk-managers-ai-will-replace-you-if-you-dont-upskill-quickly/1451903.article#:~:text=,making%20process%20requires%20clear%20protocols)). Consequently, the human analyst’s role shifts to interpreting these AI-generated risk alerts and determining the appropriate action. They will focus more on strategy – e.g. refining the scenarios that AI models use for stress testing or scenario analysis, and deciding on mitigations for risks that AI flags. Another evolution is that these analysts will spend time on **model risk** and process integrity: as the bank relies on automated controls, analysts must ensure those controls (often AI-based) are functioning correctly. For example, an operational risk analyst might oversee an AI that classifies risk incidents – they need to verify it’s categorizing events accurately and not missing anything critical. If previously they logged incidents manually, now they verify the AI’s log and investigate discrepancies. They will also likely coordinate closely with IT on things like cybersecurity (since AI tools introduce new tech risks) and with compliance on business continuity for AI systems. In terms of skills, traditional risk knowledge (operations, processes) must be complemented by data interpretation and some tech savvy. The ability to **work cross-functionally** is key – these analysts will liaise between the AI outputs and business decision-makers, translating technical risk signals into business terms. Overall, their day-to-day becomes less about rote data gathering and more about *oversight and decision support*, backed by AI insights. 

- **IT/Data Engineering Support:** The IT support personnel in risk will transform into a more specialized tech team that enables AI at scale. Currently, they manage databases and risk applications; in the near future, they will be deeply involved in deploying machine learning models (MLOps) and maintaining the infrastructure for real-time risk analytics. This means their expertise must extend to cloud computing, big data platforms, and model deployment frameworks. For example, if ING’s risk team decides to implement an AI model for early warning of credit defaults, the data engineering team will set up the data pipelines feeding that model (potentially on cloud platforms, ensuring compliance with data localization and security). They’ll also implement the monitoring tools that track model performance and trigger alerts if something goes wrong (e.g. data feed breaks, model output anomalies). Additionally, IT support will need to enforce **controls** around these systems – access controls, audit logs, and cybersecurity measures – because AI systems become part of critical risk infrastructure. Given EU’s focus on operational resilience (e.g. DORA – Digital Operational Resilience Act – and other guidelines), these roles will ensure that AI models in risk are resilient and secure. The role thus shifts from traditional sysadmin work to **DevOps/MLOps** and data governance. These staff will coordinate with the central IT and also directly with risk data scientists to push new model code into production quickly but safely. They essentially become *partners in innovation* for the risk team. Key new skills include knowledge of containerization (Docker, etc.), data pipeline tools, and familiarity with compliance requirements for data (like knowing that under EBA guidelines certain risk data cannot leave certain jurisdictions ([The EBA publishes follow-up Report on the use of machine learning for internal ratings-based models | European Banking Authority](https://www.eba.europa.eu/publications-and-media/press-releases/eba-publishes-follow-report-use-machine-learning-internal#:~:text=The%20use%20of%20ML%20techniques,consequences%20of%20the%20AI%20Act)), which affects how they design systems). In summary, the IT/data engineering support role becomes more complex and essential – those in it will be the behind-the-scenes enablers making sure the fancy AI algorithms actually run correctly day in, day out, under the watchful eye of regulators.

- **Project Managers/Coordinators:** Project managers in risk will continue to play a vital role, but the nature of projects will change. Right now, many projects are driven by regulatory changes or large system implementations. In three years, a significant portion of projects will revolve around **AI integration and process re-engineering**. For example, a project might be “Implement an AI-driven credit underwriting platform across all EU branches” – which involves coordinating data scientists, risk officers, IT, compliance, and business units. The project manager’s ability to speak both the language of risk/compliance and the language of tech will be critical. They need to ensure that AI projects meet deadlines *and* satisfy regulatory checkpoints (for instance, making sure model validation and regulator approvals are built into the timeline). As risk teams adopt agile methodologies, some project managers might take on more **product owner** or agile coach characteristics, focusing on iterative delivery of AI tools. However, given the high stakes of risk management, more formal project governance will still be present, and PMs ensure nothing falls through the cracks (especially regarding regulatory expectations or inter-department coordination). One notable change is that project managers will also oversee **vendor partnerships** more, since banks often collaborate with fintech or big tech (like HSBC’s partnership with Google for AI in financial crime ([Harnessing the power of AI to fight financial crime | Views](https://www.hsbc.com/news-and-views/views/hsbc-views/harnessing-the-power-of-ai-to-fight-financial-crime#:~:text=We%20partnered%20with%20Google%20to,HSBC%20as%20Dynamic%20Risk%20Assessment))). Managing such partnerships and contracts becomes part of the role. In terms of day-to-day, PMs will likely spend time using AI-enhanced project tools (perhaps AI assists in reporting project status or identifying risks in the project schedule). Their skill set should include a good grasp of data analytics and AI concepts, so they can effectively plan projects around them. Also, strong stakeholder management remains key, as they’ll mediate between risk experts, IT developers, and external regulators or vendors. Essentially, while the core skill of coordination remains, the content knowledge required for risk PMs rises (they must understand things like what it means to deploy an AI model in a regulated environment). Those who adapt will become **innovation project leads**, driving the transformation of the risk function.

- **Support/Administration:** Administrative and support roles in the risk department will diminish in number, but those that remain will adapt by leveraging technology. AI and automation will handle many support tasks – for example, intelligent assistants can draft routine memos, schedule meetings, or route inquiries. This means support staff will focus more on *exception handling* and facilitating communication. A remaining admin might become the go-to person for managing the risk department’s knowledge base, possibly curating an AI-driven internal wiki that houses all risk policies and model documentation (with AI tools helping to keep it updated). They could also supervise compliance with documentation standards – ensuring that all new AI models have the proper paperwork filed, etc., acting almost like a librarian of risk information. Additionally, support roles might assist in training staff on new systems (organizing training sessions for new AI tools, helping with onboarding of new risk technology). Their day-to-day will involve using advanced office tools and possibly simple scripting or RPA (robotic process automation) to further streamline workflows. In terms of skills, beyond standard office management, they’ll benefit from being adept at using collaboration platforms (Teams/Slack, etc.), and comfortable with basic data tasks (maybe running a quick report or query when needed). Networking internally will also be a part – connecting the right people to solve a problem quickly. Essentially, the support role becomes more tech-enabled and specialized, shedding purely clerical duties that AI can handle. Those in these roles will thrive if they embrace new tools (perhaps becoming the **department expert** on the latest risk dashboard or AI document search tool). If not, the necessity of the role could fade. So adaptability and willingness to continuously learn new administrative technologies will define the support staff’s value in an AI-driven department.

Overall, **each role shifts toward higher-value activities**: less manual labor, more oversight and strategy. Humans will work **with** AI tools as copilots – e.g., an analyst uses AI to crunch numbers, then applies human judgment to the result. Importantly, new competencies are threaded through almost every role: data literacy, understanding of AI/ML basics, and the ability to consider ethical and regulatory implications of technology. Traditional silo boundaries blur (e.g., modelers and IT folks working side by side), emphasizing cross-functional collaboration. Risk professionals who can adapt to these expanded responsibilities will remain crucial, while purely routine-focused roles will fade.

## Professionals and Skill Sets That Will Thrive

As the risk function transforms, certain types of professionals and skill sets will be especially valuable. The environment will favor those who combine risk domain expertise with technological proficiency and adaptability. In particular, the following will thrive:

- **Tech-Savvy Risk Experts:** Risk management professionals who embrace technology – for example, a credit risk manager who learns Python or an operational risk officer adept at using data visualization tools. These individuals marry deep risk domain knowledge (credit, market, ops risk, etc.) with practical data science or analytics skills. They can engage meaningfully with data scientists, understand model outputs, and even develop their own analytics. Banks will highly value such hybrid talent, as they serve as the bridge between traditional risk teams and new AI capabilities. Candidates who are **adept in machine learning, data analytics and AI integration** are already *highly sought after* ([Is artificial intelligence the future for risk management? | Leonid Group](https://www.leonid-group.com/insights/is-artificial-intelligence-the-future-for-risk-management-/#:~:text=There%E2%80%99s%20no%20doubt%20that%20AI,work%20effectively%20with%20the%20technology)). A risk officer who can, say, tweak a decision tree model or run a SQL query on risk data, will outperform one who relies on others for all tech needs.

- **AI Governance and Compliance Specialists:** Professionals with a strong grasp of regulations and ethics who also understand AI’s workings. This includes roles like the aforementioned AI compliance managers or model risk officers. Individuals who perhaps started in compliance or audit but picked up knowledge of data science and AI risk will excel. They will thrive by ensuring the organization’s AI tools meet regulatory expectations – a critically important area in the EU. Knowledge of **GDPR, Basel III/IV, and upcoming AI regulations** combined with the ability to interface with technical teams is a rare and valuable skill set. For example, someone who understands both credit risk modeling and the details of the EU AI Act’s requirements can help the bank navigate new rules smoothly. These people will likely lead or staff the new risk governance forums focused on AI. Citi’s report predicts new openings specifically for **“AI compliance managers” and “ethics and governance staff”** in banks ([Citi: AI threatens 54% of current banking jobs, but will create new ones](https://www.computing.co.uk/news/4327380/citi-ai-threatens-54-current-banking-jobs-create-ones#:~:text=However%2C%20while%20some%20jobs%20may,will%20become%20increasingly%20important)) – those with the right background to fill these roles will be in high demand. 

- **Data Scientists and Quants with Domain Knowledge:** Data scientists who not only are coding wizards but also speak the language of banking risk. Those who understand concepts like default rates, value-at-risk, or operational loss distributions can create AI models that truly add value and pass regulatory muster. In the AI-driven risk department, a pure data scientist with no context might build a model that is technically great but fails regulatory expectations; conversely, a data scientist **with finance/risk credentials** (say, a PhD who also obtained a FRM – Financial Risk Manager certification) will be extremely effective. Banks like ING have been actively hiring such profiles – “quants who code,” so to speak. These professionals also tend to be good at explaining models in business terms. Given that advanced quantitative skills remain in short supply, those who have them and can apply them to risk problems will thrive. Even current risk modelers who upskill into modern machine learning fall into this bucket. Essentially, **quantitative innovators** comfortable with AI will shape the future of risk analytics.

- **Adaptable Learners and Communicators:** With processes changing rapidly, the people who excel will be those who are flexible, eager to learn, and strong in soft skills. Soft skills actually become *more* important in an AI-heavy environment ([Citi: AI threatens 54% of current banking jobs, but will create new ones](https://www.computing.co.uk/news/4327380/citi-ai-threatens-54-current-banking-jobs-create-ones#:~:text=However%2C%20while%20some%20jobs%20may,will%20become%20increasingly%20important)). For example, the ability to communicate insights from an AI model to an executive or to work on a cross-departmental team implementing an AI solution is invaluable. Professionals who show leadership, critical thinking, and collaboration – in addition to whatever their technical role is – will stand out. A risk professional might not need to code the AI, but if they can ask the right questions of a model (“Does this outcome make sense economically? Could there be bias?”) and then articulate concerns or results clearly, they’ll be a key asset. Those with strong **“human” skills like creativity, judgment, and empathy** will complement AI’s computational power. This is why even as technical skills rise, banks are looking for well-rounded individuals. The ideal future risk manager might be described as having a “**tech-driven mindset with solid experience**,” blending new and old competencies ([Is artificial intelligence the future for risk management? | Leonid Group](https://www.leonid-group.com/insights/is-artificial-intelligence-the-future-for-risk-management-/#:~:text=If%20you%27re%20looking%20to%20hire,on%20navigating%20this%20new%20landscape)). 

- **Cross-Functional Project Leaders:** People who can take ownership of initiatives that span risk, IT, data, and business units. These could be project managers, product owners, or simply risk managers who naturally work well across silos. As risk management becomes everyone’s business (with AI embedding risk controls into front-line processes), professionals who can navigate different departments and bring teams together will thrive. For instance, implementing an AI trading surveillance system involves traders, compliance, IT, and risk – someone who can understand each perspective and drive the project is invaluable. Skills here include stakeholder management, broad business acumen, and a knack for translating between “tech speak” and “business speak.” Such individuals often end up in leadership roles because they help the organization realize AI’s benefits effectively.

In summary, the winners in the evolving risk landscape will be **those who combine deep expertise (be it risk policy or data science) with adaptability and collaboration.** A common theme is continuous learning – thriving professionals are not static in their skill set. Whether it’s a long-time credit officer learning about AI fairness, or a young data scientist learning about Basel regulations, the ability to pick up new knowledge and integrate it with existing expertise will define success. Banks will gravitate towards professionals who demonstrate this blend of **technical, domain, and interpersonal skills**, as they are best suited to harness AI in a controlled, intelligent way.

## Steps for Professionals to Stay Competitive in an AI-Driven Future

Given these shifts, risk management professionals should take proactive steps to prepare and remain relevant. Here are several recommendations to ensure you thrive alongside AI, rather than be displaced by it:

1. **Build Technical Skills in Data and AI:** Invest in learning data analytics and basic coding, even if you are in a non-technical risk role. Gaining proficiency in tools like Python or R, understanding how machine learning models work, and becoming comfortable with big data will greatly enhance your value. You don’t need to become a full-fledged data scientist, but you should be able to work with data scientists and understand their language. Consider taking online courses or certifications in data science or AI for finance. For example, earning a certification in using the NIST AI Risk Management Framework or a machine learning specialization can signal your commitment. The goal is to be the risk manager who can “play” with an AI tool – maybe you can pull your own risk metrics from a database or adjust parameters on a dashboard. As one commentary put it, *“AI models take care of the complex maths, allowing risk managers to focus on decision-making… The question isn’t whether AI will transform risk management, it’s whether you will upskill quickly enough to utilize it”* ([Risk managers, AI will replace you if you don’t upskill quickly | Opinion | Strategic Risk Global](https://www.strategic-risk-global.com/opinion/risk-managers-ai-will-replace-you-if-you-dont-upskill-quickly/1451903.article#:~:text=,it%5D%E2%80%9D)). In short, don’t be intimidated by tech – embrace it. Your deep risk knowledge combined with tech skills is a powerful combination.

2. **Develop AI Governance and Regulatory Knowledge:** Ensure you are well-versed in the regulatory side of AI and data. In the EU, this means understanding GDPR’s impact on automated decision-making (e.g. knowing that customers can request human review of an AI-made credit decision, and ensuring your processes allow for that). It also means keeping an eye on the EU AI Act and guidelines from bodies like the European Banking Authority regarding AI use ([The EBA publishes follow-up Report on the use of machine learning for internal ratings-based models | European Banking Authority](https://www.eba.europa.eu/publications-and-media/press-releases/eba-publishes-follow-report-use-machine-learning-internal#:~:text=The%20use%20of%20ML%20techniques,consequences%20of%20the%20AI%20Act)). If you work with risk models, familiarize yourself with model risk management principles (many banks have internal policies aligned with regulatory expectations for validating models, which now extend to AI models). You might take courses or attend seminars on “AI ethics and governance” or join industry forums discussing these topics. Building expertise in how to deploy AI **responsibly** and in compliance with laws will put you at the forefront of new roles. For instance, if you can confidently discuss how to mitigate bias in AI or implement controls for an AI system, you’ll be a prime candidate for an AI oversight role. Additionally, strengthen your foundation in classic regulations like Basel III/IV – these aren’t going away, and any AI solutions in risk still have to fit into the Basel capital and risk framework. A solid grasp of both old and new regulatory requirements will make you indispensable as a “translator” between regulators and technologists. 

3. **Upskill in Analytics Tools and Embrace Automation:** Start using the analytics and automation tools that are becoming available in your organization. Many banks are rolling out self-service analytics platforms, robotic process automation bots, or AI-driven assistants. Volunteer to pilot these or at least adopt them early. For example, if your compliance team is introducing an AI tool to prioritize alerts, learn how it works and offer feedback. This hands-on experience will not only improve your productivity but also signal to management that you are adaptable. You might also practice with visualization tools (Tableau, PowerBI) to better present risk data, or learn SQL to directly query data. The more you can automate the tedious parts of your job, the more time you free up to focus on higher-level analysis – which is exactly where you want to be. It’s wise to **reimagine your own role**: identify tasks you do that could be done faster by a machine, and then pursue ways to automate or streamline them (perhaps in partnership with your IT team or by using scripting). This initiative will keep you ahead of the curve and prevent your role from becoming obsolete due to automation. Remember, AI is there to augment you – if you become the person who knows how best to leverage that augmentation, you remain essential.

4. **Cultivate Strong Soft Skills and Domain Expertise:** In an AI-enhanced environment, human judgment and communication become even more critical. Work on your ability to interpret and communicate insights. Practice distilling complex analysis (whether from a model or AI output) into clear, actionable terms for senior management. Enhance your presentation skills and your ability to write succinct, insightful reports – AI may draft a report, but a human needs to ensure it makes sense and highlights the right issues. Additionally, double down on your core domain knowledge. If you’re a credit risk expert, stay current on industry trends, credit products, and macroeconomic factors; if you’re an operational risk manager, deepen your understanding of emerging risks (cyber threats, etc.). This contextual expertise lets you question AI results intelligently (e.g., “Does this model’s prediction align with economic reality?”). **Critical thinking** is a soft skill to actively hone: challenge assumptions, test outcomes, and don’t accept AI outputs at face value if they conflict with your informed intuition. By being a thoughtful, communicative professional, you ensure that you complement the AI rather than compete with it. Remember that as automation takes over rote tasks, your role in **providing insight, ethical consideration, and strategic direction** becomes what sets you apart. As the Citi report noted, *“soft skills” like understanding customer needs and exercising judgment will be **increasingly valued** ([Citi: AI threatens 54% of current banking jobs, but will create new ones](https://www.computing.co.uk/news/4327380/citi-ai-threatens-54-current-banking-jobs-create-ones#:~:text=However%2C%20while%20some%20jobs%20may,will%20become%20increasingly%20important))*. So, invest time in developing these through feedback, training, or mentorship.

5. **Network and Collaborate Across Functions:** Break out of the silo of your specific risk niche and build relationships with colleagues in data science, IT, and other business units. The future risk department works closely with many other teams – for example, risk modelers with IT on deployment, compliance with data privacy officers, etc. By networking, you can learn from others and also make yourself known as someone interested in innovative projects. Perhaps join an internal “AI in Finance” working group if your bank has one, or if you’re at HSBC/ING, engage with their innovation labs or digital teams that often need risk insight. Externally, consider joining professional associations or forums (like PRMIA or GARP) that have special interest groups on AI and machine learning in risk management. Attend conferences or webinars on fintech, RegTech, or AI in banking to stay inspired and informed. Not only will you gain knowledge, but you might meet professionals leading AI initiatives at other banks – expanding your perspective and opportunities. **Mentorship** can be another avenue: seek out a mentor who has a strong grasp of both risk and technology to guide you, or conversely, mentor junior analysts and encourage them (teaching often reinforces your own learning and positions you as a leader). By being well-networked, you’ll hear about new trends early, can benchmark what others are doing, and potentially position yourself for roles in new projects. Organizations often look for internal candidates who already have cross-functional rapport to champion transformation initiatives – you want to be on that shortlist. In essence, being collaborative and visible will help you surf the wave of change rather than be caught off guard by it.

6. **Stay Agile and Embrace Lifelong Learning:** Finally, adopt a mindset that change is constant and that you’re never “done” learning. The AI tools of today will evolve – for instance, three years ago few talked about GPT-style generative AI in risk, and now suddenly it’s on the radar for use in risk reporting or code generation. Be ready to continually update your skills as new technologies emerge. This might mean setting aside regular time each month for learning (online courses, reading research, etc.). Many banks are offering internal training on digital skills – take advantage of these. Also, keep an eye on how the regulatory landscape evolves with technology so you can anticipate what knowledge will be valuable (e.g., if the EU mandates certain certifications for those managing AI, you’d want to obtain those). An excellent strategy is to learn by doing: if your department is piloting an AI tool, volunteer or at least experiment with it in a safe environment. Additionally, maintain a healthy skepticism and learning attitude towards AI itself – understand its limitations as well as strengths. If you treat each new project or tool as a chance to grow your expertise, you will gradually build a very robust skill set. Banking leaders have noted that adopting AI is not just about technology, but also about **culture and mindset** – showing curiosity and flexibility in your work will mark you as someone who is part of that forward-looking culture. In summary, be prepared to reinvent aspects of your role over time. As one risk expert quipped, *“AI will replace you if you don’t upskill quickly”* – so commit to **continuous upskilling** as a career-long habit ([Risk managers, AI will replace you if you don’t upskill quickly | Opinion | Strategic Risk Global](https://www.strategic-risk-global.com/opinion/risk-managers-ai-will-replace-you-if-you-dont-upskill-quickly/1451903.article#:~:text=protocols.%20,decision%20science%20and%20behavioural%20economics)). This resilience and willingness to evolve will ensure you remain a key player in your organization’s risk management, no matter how much AI is implemented.

By following these steps – blending technical upskilling with regulatory knowledge, enhancing soft skills, and staying networked – risk management professionals can position themselves not just to survive the AI revolution, but to lead it. The future risk department in EU banks will still need human expertise at its core: people who can guide AI to make prudent decisions, interpret complex outcomes, and ensure that the bank’s use of technology remains safe and ethical. By becoming one of those well-rounded professionals, you’ll thrive in a landscape transformed by AI. The banks that succeed will be those with teams that harness AI’s power **and** human judgment in tandem, thereby managing risk more effectively in an increasingly digital world ([Citi: AI threatens 54% of current banking jobs, but will create new ones](https://www.computing.co.uk/news/4327380/citi-ai-threatens-54-current-banking-jobs-create-ones#:~:text=Nevertheless%2C%20while%20adoption%20will%20be,banking%20industry%2C%20according%20to%20Citigroup)).

**Sources:**

- Citigroup Report on AI in Banking – job automation and new roles ([Citi: AI threatens 54% of current banking jobs, but will create new ones](https://www.computing.co.uk/news/4327380/citi-ai-threatens-54-current-banking-jobs-create-ones#:~:text=As%20ever%2C%20automation%20is%20most,to%20be%20delegated%20to%20AI)).  
- Leonid Group – AI’s impact on risk management jobs and skill demand ([Is artificial intelligence the future for risk management? | Leonid Group](https://www.leonid-group.com/insights/is-artificial-intelligence-the-future-for-risk-management-/#:~:text=There%E2%80%99s%20no%20doubt%20that%20AI,work%20effectively%20with%20the%20technology)).  
- HSBC – AI usage in financial crime risk management (transaction monitoring improvements) ([Harnessing the power of AI to fight financial crime | Views](https://www.hsbc.com/news-and-views/views/hsbc-views/harnessing-the-power-of-ai-to-fight-financial-crime#:~:text=At%20HSBC%2C%20we%20check%20about,to%20help%20us%20do%20this)) ([Harnessing the power of AI to fight financial crime | Views](https://www.hsbc.com/news-and-views/views/hsbc-views/harnessing-the-power-of-ai-to-fight-financial-crime#:~:text=The%20results%20speak%20for%20themselves,previously%2C%20with%20much%20greater%20accuracy)).  
- European Banking Authority (EBA) – guidance on Machine Learning in credit risk models, highlighting GDPR and AI Act considerations ([The EBA publishes follow-up Report on the use of machine learning for internal ratings-based models | European Banking Authority](https://www.eba.europa.eu/publications-and-media/press-releases/eba-publishes-follow-report-use-machine-learning-internal#:~:text=The%20use%20of%20ML%20techniques,consequences%20of%20the%20AI%20Act)).  
- McKinsey – future risk function efficiency and role specialization (20% cost reduction potential via analytics) ([Transforming risk efficiency and effectiveness | McKinsey](https://www.mckinsey.com/capabilities/risk-and-resilience/our-insights/transforming-risk-efficiency-and-effectiveness#:~:text=Fortunately%2C%20the%20most%20potent%20levers,and%20employee%20and%20customer%20experience)) ([Transforming risk efficiency and effectiveness | McKinsey](https://www.mckinsey.com/capabilities/risk-and-resilience/our-insights/transforming-risk-efficiency-and-effectiveness#:~:text=However%2C%20efforts%20to%20improve%20risk,Banking%20regulators%20remain)).  
- *Strategic Risk* magazine – opinion on upskilling for AI in risk (importance of quick adaptation) ([Risk managers, AI will replace you if you don’t upskill quickly | Opinion | Strategic Risk Global](https://www.strategic-risk-global.com/opinion/risk-managers-ai-will-replace-you-if-you-dont-upskill-quickly/1451903.article#:~:text=,it%5D%E2%80%9D)) ([Risk managers, AI will replace you if you don’t upskill quickly | Opinion | Strategic Risk Global](https://www.strategic-risk-global.com/opinion/risk-managers-ai-will-replace-you-if-you-dont-upskill-quickly/1451903.article#:~:text=protocols.%20,decision%20science%20and%20behavioural%20economics)).  
- Computing News – AI in banking will create new compliance and AI governance roles; soft skills increasingly important ([Citi: AI threatens 54% of current banking jobs, but will create new ones](https://www.computing.co.uk/news/4327380/citi-ai-threatens-54-current-banking-jobs-create-ones#:~:text=However%2C%20while%20some%20jobs%20may,will%20become%20increasingly%20important)).  
- Additional industry insights on AI in risk and compliance (EY, Deloitte, etc.) aligning with EU regulations (GDPR, Basel, EU AI Act) ([Citi: AI threatens 54% of current banking jobs, but will create new ones](https://www.computing.co.uk/news/4327380/citi-ai-threatens-54-current-banking-jobs-create-ones#:~:text=However%2C%20while%20some%20jobs%20may,their%20needs%20becoming%20increasingly%20valued)) ([Risk managers, AI will replace you if you don’t upskill quickly | Opinion | Strategic Risk Global](https://www.strategic-risk-global.com/opinion/risk-managers-ai-will-replace-you-if-you-dont-upskill-quickly/1451903.article#:~:text=,requires%20specialised%20skills%20that%20may)).  
