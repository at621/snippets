{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e85cb85e-d4bb-4e30-9dbd-4aea333ad553",
   "metadata": {},
   "source": [
    "## Generate documents\n",
    "\n",
    "This Jupyter cell contains Python code designed to automatically generate a book in LaTeX format.  It leverages several key technologies to streamline the process:\n",
    "\n",
    "*   **OpenAI's language models (like o1):** To generate the actual content of each book section based on a defined outline and relevant background information.\n",
    "*   **Pandas:** To efficiently manage and load background data, which is expected to be pre-processed and saved in a pickle file. This background data contains text and pre-calculated embeddings for similarity searches.\n",
    "*   **Pickle:** To load the background data quickly from a `.pkl` file, preserving the data structure and embeddings.\n",
    "*   **LaTeX:** To format the generated book content into a professional, high-quality PDF document.\n",
    "\n",
    "**Here's a high-level overview of what the code does:**\n",
    "\n",
    "1.  **Loads Book Outline:** Reads a JSON file (`book_outline.json`) that defines the structure of your book (sections, titles, goals, and required background for each section).\n",
    "2.  **Loads Background Data:** Loads a pre-processed Pandas DataFrame from a pickle file (`regulations_with_embeddings.pkl`). This DataFrame should contain background text and their corresponding embeddings.\n",
    "3.  **Iterates Through Book Sections:**  Loops through each section defined in the book outline.\n",
    "4.  **Finds Relevant Background Text:** For each section, it uses cosine similarity to find the most relevant background text from the loaded DataFrame based on the \"required background\" description in the outline.\n",
    "5.  **Generates Section Content with OpenAI:**  Uses OpenAI's API to generate the text content for each section, providing the section title, goal, and the most similar background text as context to the language model.\n",
    "6.  **Formats Content in LaTeX:**  Structures the generated text into LaTeX sections, including proper LaTeX preamble and postamble for a complete document.  It also includes basic escaping of LaTeX special characters in titles and preamble.\n",
    "7.  **Saves LaTeX File:**  Saves the complete LaTeX code to a `.tex` file (`generated_book.tex`).\n",
    "8.  **Compiles LaTeX to PDF (Optional):**  Attempts to automatically compile the generated `.tex` file into a PDF document using `pdflatex`.\n",
    "\n",
    "This code provides a framework for automated book generation, and you can customize the outline, background data, prompts, and LaTeX formatting to create your own unique book.  Run the cell to start the book generation process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c10ac4ae-b158-4054-bf1e-27d4156d356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import logging\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import openai\n",
    "from typing import Any, Dict\n",
    "import textwrap\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import subprocess\n",
    "\n",
    "# --- Logging Configuration ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b3db3-9aac-4382-9391-4cbad8b9c9e0",
   "metadata": {},
   "source": [
    "### A. Parametrisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c6eecf0-04ec-43b5-99b5-fd3fe14ace25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "JSON_OUTLINE_FILE = \"validation_book_outline.json\"  # Path to your JSON outline file\n",
    "PANDAS_DF_FILE = \"regulations_with_embeddings.pkl\"  # Path to your pickle file with background data\n",
    "TEXT_COLUMN_NAME = \"body_of_the_text\"  # Column with text content\n",
    "EMBEDDING_COLUMN_NAME = \"combined_text_embedding\"  # Column with pre-calculated embeddings\n",
    "OPENAI_MODEL = \"o1-preview\"  # \"gpt-4o\"  # Your preferred OpenAI model\n",
    "LATEX_OUTPUT_FILE = \"generated_book_v2.tex\"  # Name of the output LaTeX file\n",
    "\n",
    "# Global variable to track the total cost for the whole run\n",
    "TOTAL_COST = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa23ee-ce15-4582-ae15-a61c4b844bb1",
   "metadata": {},
   "source": [
    "### B. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b3422d-53c6-478e-acc9-691d5a5d9e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions ---\n",
    "def load_json_outline(json_file: str) -> Dict[str, Any]:\n",
    "    \"\"\"Loads the book outline from a JSON file.\"\"\"\n",
    "    try:\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            outline = json.load(f)\n",
    "        logging.info(f\"Book outline loaded from {json_file}\")\n",
    "        return outline\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading JSON outline: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def load_dataframe_from_pickle(pickle_filepath: str) -> Any:\n",
    "    \"\"\"Loads a DataFrame from a pickle file.\"\"\"\n",
    "    try:\n",
    "        with open(pickle_filepath, \"rb\") as f:\n",
    "            loaded_df = pickle.load(f)\n",
    "        logging.info(f\"DataFrame loaded from pickle file: {pickle_filepath}\")\n",
    "        return loaded_df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading DataFrame pickle: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def load_pandas_dataframe(pkl_file: str) -> Any:\n",
    "    \"\"\"\n",
    "    Loads a pandas DataFrame from a pickle file and converts embedding strings to numpy arrays.\n",
    "    Use this if your embeddings are stored as strings.\n",
    "    \"\"\"\n",
    "    df = load_dataframe_from_pickle(pkl_file)\n",
    "    try:\n",
    "        df[EMBEDDING_COLUMN_NAME] = df[EMBEDDING_COLUMN_NAME].apply(\n",
    "            lambda x: np.array(json.loads(x)) if isinstance(x, str) else x\n",
    "        )\n",
    "        logging.info(\"Embeddings converted to numpy arrays (if necessary).\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting embeddings: {e}\")\n",
    "        raise\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_embedding(text: str, model: str = \"text-embedding-ada-002\") -> list:\n",
    "    \"\"\"Generates an embedding for the given text using OpenAI.\"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    try:\n",
    "        response = openai.embeddings.create(input=[text], model=model)\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating embedding: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def find_similar_background_text(df: Any, background_description: str,\n",
    "                                 text_column: str, embedding_column: str) -> str:\n",
    "    \"\"\"\n",
    "    Finds the most similar text in the DataFrame to the background description using cosine similarity.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        description_embedding = get_embedding(background_description)\n",
    "        background_embeddings = np.vstack(df[embedding_column].to_numpy())\n",
    "        similarities = cosine_similarity(np.array([description_embedding]), background_embeddings)\n",
    "        most_similar_index = np.argmax(similarities)\n",
    "        return df[text_column].iloc[most_similar_index]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error finding similar background text: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eaf254-dea5-4baf-ba76-e92894f4263f",
   "metadata": {},
   "source": [
    "### C. Content functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b073b2bc-075b-4fab-9f73-90f417ce2d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_content_text(title: str, \n",
    "                          goal: str,\n",
    "                          level: int,\n",
    "                          background_text: str,\n",
    "                          model: str = OPENAI_MODEL,\n",
    "                          use_langchain: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Generates LaTeX-formatted text for either a section or a subsection.\n",
    "    \n",
    "    Parameters:\n",
    "      - title: The title of the section/subsection.\n",
    "      - goal: The goal of the section/subsection.\n",
    "      - background_text: Background content to guide the writing.\n",
    "      - level: Either \"section\" or \"subsection\". This will modify the prompt.\n",
    "      - model: The OpenAI model to use.\n",
    "      - use_langchain: If True, use LangChain's ChatOpenAI; otherwise, use openai.chat.completions.create.\n",
    "    \"\"\"\n",
    "    global TOTAL_COST\n",
    "    \n",
    "    header = f\"\"\"\n",
    "        You are a helpful AI assistant specialized in writing technical books about regulatory compliance and model validation in finance.\n",
    "\n",
    "        Level {level} heading | Title: {title}\n",
    "\n",
    "        Goal of this book part of the book: {goal}\n",
    "\n",
    "        Background information to consider when writing:\n",
    "        {background_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    instructions = f\"\"\"\n",
    "        ---\n",
    "        Write the content for the {title} above, keeping in mind the goal and background information.\n",
    "        Format the output as LaTeX, suitable for inclusion in a LaTeX document.\n",
    "        Level 1 heading stands for section, level 2 heading stands for subsection, level 3 stands for sub-subsection - add it to Latex. \n",
    "        Please use standard LaTeX commands for formatting (e.g., \\\\textbf{{important text}}, \\\\textit{{emphasized text}}).\n",
    "        If you need to include lists, use LaTeX list environments like \\\\begin{{itemize}} ... \\\\end{{itemize}} or \\\\begin{{enumerate}} ... \\\\end{{enumerate}}.\n",
    "    \"\"\"\n",
    "    \n",
    "    instructions += \"For mathematical formulas, use inline math mode $...$ or display math mode \\\\begin{{equation}} ... \\\\end{{equation}}.\\n\"\n",
    "    instructions += \"Do not use mathematical formulas.\\n\\n\"\n",
    "    instructions += \"----\\n\"\n",
    "    instructions += \"When writing Python code, **format the output as valid Python code enclosed in ```python code blocks.**\\n\"\n",
    "    instructions += \"Include comments to explain the code where necessary.\\n\"\n",
    "    instructions += \"Focus on clarity, correctness, and efficiency of the Python code.\\n\"\n",
    "    instructions += \"Do not include any explanations outside of the code block.\\n\"\n",
    "\n",
    "    prompt = header + instructions\n",
    "    \n",
    "    # Remove any unwanted indentation from the multi-line string.\n",
    "    prompt = textwrap.dedent(prompt)\n",
    "\n",
    "    try:\n",
    "        if use_langchain:\n",
    "            llm = ChatOpenAI(model_name=model, temperature=1.0)\n",
    "            with get_openai_callback() as cb:\n",
    "                response = llm.invoke(prompt)\n",
    "                content = response.content.strip()\n",
    "                logging.info(\"LLM call for content generation completed.\")\n",
    "                logging.info(f\"Generation token usage: {cb.total_tokens} (Prompt: {cb.prompt_tokens}, \"\n",
    "                             f\"Completion: {cb.completion_tokens}, Cost: ${cb.total_cost:.4f})\")\n",
    "\n",
    "                 # Accumulate the cost from this call\n",
    "                TOTAL_COST += cb.total_cost\n",
    "                \n",
    "            return content\n",
    "        else:\n",
    "            response = openai.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant specialized in LaTeX output for technical books.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                # temperature=0.7,\n",
    "                max_completion_tokens=1700\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating text for Level {level} '{title}': {e}\")\n",
    "        return f\"**Error generating content for this Level {level}. Please check logs.**\"\n",
    "\n",
    "\n",
    "def create_latex_section(section_text: str) -> str:\n",
    "    \"\"\"Formats a section with a LaTeX \\\\section header.\"\"\"\n",
    "    return f\"{section_text}\"\n",
    "\n",
    "\n",
    "def create_latex_subsection(subsection_text: str) -> str:\n",
    "    \"\"\"Formats a subsection with a LaTeX \\\\subsection header.\"\"\"\n",
    "    return f\"{subsection_text}\"\n",
    "\n",
    "\n",
    "def create_latex_preamble(title: str, author: str, header_text: str = 'Validation Standards') -> str:\n",
    "    \"\"\"\n",
    "    Creates the LaTeX preamble for the document, including a custom title page.\n",
    "    \"\"\"\n",
    "    preamble = f\"\"\"\n",
    "\\\\documentclass[12pt,a4paper]{{article}}\n",
    "\n",
    "\\\\usepackage[utf8]{{inputenc}}\n",
    "\\\\usepackage[T1]{{fontenc}}\n",
    "\\\\usepackage{{lmodern}}\n",
    "\\\\usepackage[margin=1in]{{geometry}}\n",
    "\\\\usepackage{{setspace}}\n",
    "\\\\usepackage{{titlesec}}\n",
    "\\\\usepackage{{etoolbox}}\n",
    "\\\\usepackage{{fancyhdr}}\n",
    "\\\\usepackage{{graphicx}}\n",
    "\\\\usepackage{{amsmath}}\n",
    "\\\\usepackage{{listings}} % For code listings\n",
    "\\\\lstset{{\n",
    "  basicstyle=\\\\ttfamily\\\\footnotesize,\n",
    "  breaklines=true,\n",
    "  showstringspaces=false\n",
    "}}\n",
    "\n",
    "% Ensure each \\\\section begins on a new page\n",
    "\\\\preto\\\\section{{\\\\clearpage}}\n",
    "\n",
    "% Format for section and subsection titles\n",
    "\\\\titleformat{{\\\\section}}{{\\\\large\\\\bfseries}}{{\\\\thesection}}{{1em}}{{}}\n",
    "\\\\titleformat{{\\\\subsection}}{{\\\\normalsize\\\\bfseries}}{{\\\\thesubsection}}{{1em}}{{}}\n",
    "\n",
    "\\\\setlength{{\\\\parindent}}{{10pt}}\n",
    "\\\\setlength{{\\\\parskip}}{{0.5\\\\baselineskip}}\n",
    "\\\\setlength{{\\\\headheight}}{{14.5pt}}\n",
    "\n",
    "\\\\pagestyle{{fancy}}\n",
    "\\\\fancyhf{{}}\n",
    "\\\\fancyhead[C]{{{header_text}}}\n",
    "\\\\fancyfoot[C]{{\\\\thepage}}\n",
    "\\\\renewcommand{{\\\\headrulewidth}}{{0pt}}\n",
    "\n",
    "\\\\begin{{document}}\n",
    "\\\\pagenumbering{{gobble}}\n",
    "\n",
    "% --- Custom Title Page ---\n",
    "\\\\begin{{titlepage}}\n",
    "    \\\\begin{{center}}\n",
    "        \\\\vspace*{{3cm}}\n",
    "        \n",
    "        {{\\\\Huge \\\\textbf{{{title}}}}}\\\\\\\\[0.8em]\n",
    "        {{\\\\Huge \\\\textbf{{credit risk validation tests}}}}\\\\\\\\[2.0cm]\n",
    "        \n",
    "        {{\\\\Large \\\\textit{{Review and application of key validation tests}}}}\\\\\\\\[2.5cm]\n",
    "        \n",
    "        {{\\\\large \\\\textbf{{{author}}}}}\\\\\\\\[0.5cm]\n",
    "        \n",
    "        \\\\vfill\n",
    "        {{\\\\large \\\\today}}\n",
    "    \\\\end{{center}}\n",
    "\\\\end{{titlepage}}\n",
    "\n",
    "\\\\thispagestyle{{empty}}\n",
    "\\\\tableofcontents\n",
    "\\\\pagenumbering{{arabic}}\n",
    "\\\\setcounter{{page}}{{1}}\n",
    "\"\"\"\n",
    "    return preamble\n",
    "\n",
    "def create_latex_postamble() -> str:\n",
    "    \"\"\"Creates the LaTeX postamble for the document.\"\"\"\n",
    "    return \"\\n\\\\end{document}\\n\"\n",
    "\n",
    "\n",
    "def convert_markdown_code_blocks_to_lstlisting(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts Markdown code blocks (```python ... ```) into LaTeX lstlisting environments.\n",
    "    This helps prevent errors from raw backticks in the LaTeX document.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"```python\\s*(.*?)\\s*```\", re.DOTALL)\n",
    "    def repl(match):\n",
    "        code_content = match.group(1)\n",
    "        return \"\\\\begin{lstlisting}[language=Python]\\n\" + code_content + \"\\n\\\\end{lstlisting}\"\n",
    "    return pattern.sub(repl, text)\n",
    "\n",
    "\n",
    "def compile_latex_to_pdf(tex_filename):\n",
    "    \"\"\"\n",
    "    Compiles a .tex file to PDF using pdflatex (requires LaTeX installed).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Run pdflatex twice to ensure references are updated if needed\n",
    "        subprocess.run([\"pdflatex\", tex_filename], check=True)\n",
    "        subprocess.run([\"pdflatex\", tex_filename], check=True)\n",
    "        print(\"PDF successfully generated.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during LaTeX compilation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130d573-949f-4f7a-9be9-748fd95339c9",
   "metadata": {},
   "source": [
    "### D. Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9692a1d-d196-41ff-ab58-e36efae3b005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 06:56:25,574 - INFO - Book outline loaded from validation_book_outline.json\n",
      "2025-02-06 06:56:27,246 - INFO - DataFrame loaded from pickle file: regulations_with_embeddings.pkl\n",
      "2025-02-06 06:56:27,253 - INFO - Embeddings converted to numpy arrays (if necessary).\n",
      "2025-02-06 06:56:27,253 - INFO - Generating book content section by section...\n",
      "2025-02-06 06:56:27,254 - INFO - Processing section (Level 1): Part I: Foundations of Credit Risk\n",
      "2025-02-06 06:56:27,255 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 06:56:29,694 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 06:56:31,092 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 06:57:03,809 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 06:57:03,821 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 06:57:03,822 - INFO - Generation token usage: 4490 (Prompt: 376, Completion: 4114, Cost: $0.2525)\n",
      "2025-02-06 06:57:03,823 - INFO - Processing section (Level 2): Introduction to Credit Risk\n",
      "2025-02-06 06:57:03,823 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 06:57:04,180 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 06:57:05,562 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 06:57:27,936 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 06:57:27,939 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 06:57:27,939 - INFO - Generation token usage: 3296 (Prompt: 372, Completion: 2924, Cost: $0.1810)\n",
      "2025-02-06 06:57:27,940 - INFO - Processing section (Level 3): What is Credit Risk?\n",
      "2025-02-06 06:57:27,941 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 06:57:28,317 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 06:57:29,714 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 06:57:51,458 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 06:57:51,460 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 06:57:51,460 - INFO - Generation token usage: 2925 (Prompt: 359, Completion: 2566, Cost: $0.1593)\n",
      "2025-02-06 06:57:51,461 - INFO - Processing section (Level 3): Credit Risk Model Types\n",
      "2025-02-06 06:57:51,461 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 06:57:51,690 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 06:57:53,085 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 06:58:16,451 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 06:58:16,453 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 06:58:16,454 - INFO - Generation token usage: 2091 (Prompt: 437, Completion: 1654, Cost: $0.1058)\n",
      "2025-02-06 06:58:16,454 - INFO - Processing section (Level 3): Model Validation Importance\n",
      "2025-02-06 06:58:16,455 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 06:58:16,767 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 06:58:18,175 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 06:58:40,685 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 06:58:40,687 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 06:58:40,688 - INFO - Generation token usage: 2759 (Prompt: 520, Completion: 2239, Cost: $0.1421)\n",
      "2025-02-06 06:58:40,688 - INFO - Processing section (Level 3): Model Risk Implications\n",
      "2025-02-06 06:58:40,689 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 06:58:41,258 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 06:58:42,645 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 06:59:05,569 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 06:59:05,571 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 06:59:05,571 - INFO - Generation token usage: 2827 (Prompt: 390, Completion: 2437, Cost: $0.1521)\n",
      "2025-02-06 06:59:05,573 - INFO - Processing section (Level 3): Model Lifecycle\n",
      "2025-02-06 06:59:05,574 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 06:59:05,885 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 06:59:07,265 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 06:59:44,029 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 06:59:44,031 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 06:59:44,031 - INFO - Generation token usage: 3672 (Prompt: 371, Completion: 3301, Cost: $0.2036)\n",
      "2025-02-06 06:59:44,033 - INFO - Processing section (Level 3): Key Terminology\n",
      "2025-02-06 06:59:44,033 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 06:59:44,864 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 06:59:46,237 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:00:20,387 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:00:20,389 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:00:20,389 - INFO - Generation token usage: 4386 (Prompt: 413, Completion: 3973, Cost: $0.2446)\n",
      "2025-02-06 07:00:20,390 - INFO - Processing section (Level 2): Model Risk Management Principles\n",
      "2025-02-06 07:00:20,391 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:00:20,746 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:00:22,107 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:00:54,511 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:00:54,513 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:00:54,513 - INFO - Generation token usage: 3681 (Prompt: 349, Completion: 3332, Cost: $0.2052)\n",
      "2025-02-06 07:00:54,514 - INFO - Processing section (Level 3): Risk Management Frameworks\n",
      "2025-02-06 07:00:54,514 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:00:54,717 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:00:56,068 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:01:25,889 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:01:25,891 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:01:25,891 - INFO - Generation token usage: 2708 (Prompt: 411, Completion: 2297, Cost: $0.1440)\n",
      "2025-02-06 07:01:25,891 - INFO - Processing section (Level 3): Model Governance and Oversight\n",
      "2025-02-06 07:01:25,893 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:01:26,429 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:01:27,791 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:01:57,476 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:01:57,478 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:01:57,479 - INFO - Generation token usage: 3403 (Prompt: 366, Completion: 3037, Cost: $0.1877)\n",
      "2025-02-06 07:01:57,479 - INFO - Processing section (Level 3): Data Quality Impact\n",
      "2025-02-06 07:01:57,480 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:01:57,799 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:01:59,141 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:02:29,394 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:02:29,396 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:02:29,396 - INFO - Generation token usage: 3898 (Prompt: 370, Completion: 3528, Cost: $0.2172)\n",
      "2025-02-06 07:02:29,397 - INFO - Processing section (Level 3): Model Documentation\n",
      "2025-02-06 07:02:29,397 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:02:29,709 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:02:31,058 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:03:01,155 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:03:01,160 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:03:01,160 - INFO - Generation token usage: 2542 (Prompt: 364, Completion: 2178, Cost: $0.1361)\n",
      "2025-02-06 07:03:01,161 - INFO - Processing section (Level 3): Regulatory Standards\n",
      "2025-02-06 07:03:01,162 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:03:01,743 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:03:03,090 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:03:34,054 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:03:34,056 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:03:34,057 - INFO - Generation token usage: 3461 (Prompt: 422, Completion: 3039, Cost: $0.1887)\n",
      "2025-02-06 07:03:34,057 - INFO - Processing section (Level 3): Ethical Considerations\n",
      "2025-02-06 07:03:34,058 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:03:34,300 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:03:35,647 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:03:49,782 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:03:49,784 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:03:49,784 - INFO - Generation token usage: 1957 (Prompt: 400, Completion: 1557, Cost: $0.0994)\n",
      "2025-02-06 07:03:49,785 - INFO - Processing section (Level 1): Part II: PD Model Validation\n",
      "2025-02-06 07:03:49,785 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:03:50,391 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:03:51,736 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:04:10,919 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:04:10,920 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:04:10,921 - INFO - Generation token usage: 2165 (Prompt: 383, Completion: 1782, Cost: $0.1127)\n",
      "2025-02-06 07:04:10,922 - INFO - Processing section (Level 2): PD Discriminatory Power Tests\n",
      "2025-02-06 07:04:10,922 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:04:11,389 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:04:12,746 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:04:50,654 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:04:50,656 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:04:50,656 - INFO - Generation token usage: 3897 (Prompt: 432, Completion: 3465, Cost: $0.2144)\n",
      "2025-02-06 07:04:50,657 - INFO - Processing section (Level 3): Introduction to Discriminatory Power\n",
      "2025-02-06 07:04:50,657 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:04:51,033 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:04:52,382 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:05:11,005 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:05:11,006 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:05:11,007 - INFO - Generation token usage: 2290 (Prompt: 426, Completion: 1864, Cost: $0.1182)\n",
      "2025-02-06 07:05:11,007 - INFO - Processing section (Level 3): Key Tests\n",
      "2025-02-06 07:05:11,008 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:05:11,415 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:05:12,762 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:05:35,482 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:05:35,484 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:05:35,485 - INFO - Generation token usage: 2757 (Prompt: 414, Completion: 2343, Cost: $0.1468)\n",
      "2025-02-06 07:05:35,485 - INFO - Processing section (Level 4): ROC Curve and AUC\n",
      "2025-02-06 07:05:35,486 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:05:35,697 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:05:37,046 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:06:06,591 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:06:06,592 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:06:06,593 - INFO - Generation token usage: 3554 (Prompt: 337, Completion: 3217, Cost: $0.1981)\n",
      "2025-02-06 07:06:06,593 - INFO - Processing section (Level 4): Gini Coefficient\n",
      "2025-02-06 07:06:06,594 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:06:06,819 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:06:08,164 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:06:24,490 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:06:24,492 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:06:24,492 - INFO - Generation token usage: 2172 (Prompt: 445, Completion: 1727, Cost: $0.1103)\n",
      "2025-02-06 07:06:24,493 - INFO - Processing section (Level 4): Kolmogorov-Smirnov (KS) Statistic\n",
      "2025-02-06 07:06:24,494 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:06:24,861 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:06:26,209 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:06:52,695 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:06:52,697 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:06:52,697 - INFO - Generation token usage: 3042 (Prompt: 369, Completion: 2673, Cost: $0.1659)\n",
      "2025-02-06 07:06:52,698 - INFO - Processing section (Level 4): Cumulative Accuracy Profile (CAP)\n",
      "2025-02-06 07:06:52,698 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:06:53,171 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:06:54,539 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:07:30,424 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:07:30,426 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:07:30,427 - INFO - Generation token usage: 3750 (Prompt: 386, Completion: 3364, Cost: $0.2076)\n",
      "2025-02-06 07:07:30,427 - INFO - Processing section (Level 4): Binned vs. Unbinned Tests\n",
      "2025-02-06 07:07:30,428 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:07:30,801 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:07:32,153 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:07:59,742 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:07:59,744 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:07:59,745 - INFO - Generation token usage: 3256 (Prompt: 450, Completion: 2806, Cost: $0.1751)\n",
      "2025-02-06 07:07:59,746 - INFO - Processing section (Level 3): Benchmarking Discriminatory Power\n",
      "2025-02-06 07:07:59,746 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:08:00,069 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:08:01,409 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:08:20,367 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:08:20,372 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:08:20,372 - INFO - Generation token usage: 2893 (Prompt: 434, Completion: 2459, Cost: $0.1540)\n",
      "2025-02-06 07:08:20,373 - INFO - Processing section (Level 2): PD Calibration Tests\n",
      "2025-02-06 07:08:20,374 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:08:20,673 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:08:22,028 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:08:47,580 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:08:47,582 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:08:47,582 - INFO - Generation token usage: 2941 (Prompt: 438, Completion: 2503, Cost: $0.1568)\n",
      "2025-02-06 07:08:47,583 - INFO - Processing section (Level 3): Introduction to Calibration\n",
      "2025-02-06 07:08:47,584 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:08:47,898 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:08:49,267 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:09:07,866 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:09:07,868 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:09:07,869 - INFO - Generation token usage: 2522 (Prompt: 355, Completion: 2167, Cost: $0.1353)\n",
      "2025-02-06 07:09:07,870 - INFO - Processing section (Level 3): Key Tests\n",
      "2025-02-06 07:09:07,870 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:09:08,300 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:09:09,691 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:09:26,868 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:09:26,882 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:09:26,883 - INFO - Generation token usage: 2357 (Prompt: 412, Completion: 1945, Cost: $0.1229)\n",
      "2025-02-06 07:09:26,884 - INFO - Processing section (Level 4): Calibration Plots\n",
      "2025-02-06 07:09:26,884 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:09:27,299 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:09:28,697 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:10:01,075 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:10:01,076 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:10:01,077 - INFO - Generation token usage: 3847 (Prompt: 324, Completion: 3523, Cost: $0.2162)\n",
      "2025-02-06 07:10:01,077 - INFO - Processing section (Level 4): Brier Score\n",
      "2025-02-06 07:10:01,078 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:10:01,477 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:10:02,829 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:10:19,508 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:10:19,510 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:10:19,511 - INFO - Generation token usage: 2539 (Prompt: 399, Completion: 2140, Cost: $0.1344)\n",
      "2025-02-06 07:10:19,511 - INFO - Processing section (Level 4): Hosmer-Lemeshow Test\n",
      "2025-02-06 07:10:19,512 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:10:19,848 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:10:21,212 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:10:48,878 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:10:48,880 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:10:48,880 - INFO - Generation token usage: 3756 (Prompt: 408, Completion: 3348, Cost: $0.2070)\n",
      "2025-02-06 07:10:48,881 - INFO - Processing section (Level 4): Binomial Test\n",
      "2025-02-06 07:10:48,882 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:10:49,206 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:10:50,559 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:11:11,645 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:11:11,646 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:11:11,647 - INFO - Generation token usage: 2714 (Prompt: 342, Completion: 2372, Cost: $0.1474)\n",
      "2025-02-06 07:11:11,647 - INFO - Processing section (Level 4): Jeffreys Test\n",
      "2025-02-06 07:11:11,648 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:11:11,927 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:11:13,268 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:11:34,432 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:11:34,433 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:11:34,433 - INFO - Generation token usage: 2208 (Prompt: 362, Completion: 1846, Cost: $0.1162)\n",
      "2025-02-06 07:11:34,434 - INFO - Processing section (Level 4): Confidence Intervals\n",
      "2025-02-06 07:11:34,434 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:11:34,775 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:11:36,119 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:11:50,145 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:11:50,146 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:11:50,147 - INFO - Generation token usage: 2190 (Prompt: 461, Completion: 1729, Cost: $0.1107)\n",
      "2025-02-06 07:11:50,147 - INFO - Processing section (Level 4): Low Default Portfolio Tests\n",
      "2025-02-06 07:11:50,148 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:11:50,527 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:11:51,933 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:12:09,737 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:12:09,739 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:12:09,739 - INFO - Generation token usage: 2413 (Prompt: 317, Completion: 2096, Cost: $0.1305)\n",
      "2025-02-06 07:12:09,740 - INFO - Processing section (Level 3): Benchmarking Calibration\n",
      "2025-02-06 07:12:09,740 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:12:10,111 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:12:11,488 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:12:24,324 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:12:24,327 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:12:24,328 - INFO - Generation token usage: 1940 (Prompt: 434, Completion: 1506, Cost: $0.0969)\n",
      "2025-02-06 07:12:24,329 - INFO - Processing section (Level 2): PD Stability Tests\n",
      "2025-02-06 07:12:24,329 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:12:24,925 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:12:26,279 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:13:00,938 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:13:00,940 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:13:00,941 - INFO - Generation token usage: 4002 (Prompt: 396, Completion: 3606, Cost: $0.2223)\n",
      "2025-02-06 07:13:00,941 - INFO - Processing section (Level 3): Introduction to Model Stability\n",
      "2025-02-06 07:13:00,943 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:13:01,321 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:13:02,684 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:13:21,988 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:13:21,990 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:13:21,991 - INFO - Generation token usage: 2382 (Prompt: 521, Completion: 1861, Cost: $0.1195)\n",
      "2025-02-06 07:13:21,992 - INFO - Processing section (Level 3): Key Tests\n",
      "2025-02-06 07:13:21,992 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:13:22,212 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:13:23,572 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:13:45,958 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:13:45,960 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:13:45,961 - INFO - Generation token usage: 2653 (Prompt: 336, Completion: 2317, Cost: $0.1441)\n",
      "2025-02-06 07:13:45,961 - INFO - Processing section (Level 4): Population Stability Index (PSI)\n",
      "2025-02-06 07:13:45,962 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:13:46,210 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:13:47,576 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:14:11,060 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:14:11,062 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:14:11,063 - INFO - Generation token usage: 3131 (Prompt: 403, Completion: 2728, Cost: $0.1697)\n",
      "2025-02-06 07:14:11,064 - INFO - Processing section (Level 4): Characteristic Stability Index (CSI)\n",
      "2025-02-06 07:14:11,064 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:14:11,398 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:14:12,741 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:14:32,281 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:14:32,283 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:14:32,284 - INFO - Generation token usage: 2807 (Prompt: 341, Completion: 2466, Cost: $0.1531)\n",
      "2025-02-06 07:14:32,284 - INFO - Processing section (Level 4): Divergence Measures\n",
      "2025-02-06 07:14:32,285 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:14:32,511 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:14:33,866 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:14:56,763 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:14:56,765 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:14:56,766 - INFO - Generation token usage: 3082 (Prompt: 430, Completion: 2652, Cost: $0.1656)\n",
      "2025-02-06 07:14:56,766 - INFO - Processing section (Level 2): PD Backtesting\n",
      "2025-02-06 07:14:56,767 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:14:57,139 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:14:58,500 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:15:29,657 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:15:29,659 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:15:29,659 - INFO - Generation token usage: 3227 (Prompt: 430, Completion: 2797, Cost: $0.1743)\n",
      "2025-02-06 07:15:29,660 - INFO - Processing section (Level 3): Introduction to Backtesting\n",
      "2025-02-06 07:15:29,660 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:15:30,002 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:15:31,359 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:15:48,350 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:15:48,352 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:15:48,352 - INFO - Generation token usage: 2302 (Prompt: 472, Completion: 1830, Cost: $0.1169)\n",
      "2025-02-06 07:15:48,353 - INFO - Processing section (Level 3): Backtesting Techniques\n",
      "2025-02-06 07:15:48,354 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:15:48,687 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:15:50,054 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:16:16,067 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:16:16,070 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:16:16,070 - INFO - Generation token usage: 3509 (Prompt: 454, Completion: 3055, Cost: $0.1901)\n",
      "2025-02-06 07:16:16,071 - INFO - Processing section (Level 4): Traffic Light Approach\n",
      "2025-02-06 07:16:16,071 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:16:16,401 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:16:17,749 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:16:44,027 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:16:44,029 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:16:44,029 - INFO - Generation token usage: 3081 (Prompt: 406, Completion: 2675, Cost: $0.1666)\n",
      "2025-02-06 07:16:44,030 - INFO - Processing section (Level 4): Basel Backtesting Requirements\n",
      "2025-02-06 07:16:44,031 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:16:44,354 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:16:45,703 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:17:07,036 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:17:07,038 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:17:07,039 - INFO - Generation token usage: 2536 (Prompt: 332, Completion: 2204, Cost: $0.1372)\n",
      "2025-02-06 07:17:07,040 - INFO - Processing section (Level 4): Statistical tests\n",
      "2025-02-06 07:17:07,040 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:17:07,315 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:17:08,746 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:17:26,284 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:17:26,286 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:17:26,286 - INFO - Generation token usage: 2286 (Prompt: 327, Completion: 1959, Cost: $0.1224)\n",
      "2025-02-06 07:17:26,287 - INFO - Processing section (Level 3): Backtesting Reporting\n",
      "2025-02-06 07:17:26,288 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:17:26,664 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:17:28,045 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:17:48,738 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:17:48,740 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:17:48,740 - INFO - Generation token usage: 2607 (Prompt: 318, Completion: 2289, Cost: $0.1421)\n",
      "2025-02-06 07:17:48,741 - INFO - Processing section (Level 1): Part III: LGD, EAD, CCF, and ELBE Validation\n",
      "2025-02-06 07:17:48,741 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:17:49,136 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:17:50,467 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:18:20,710 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:18:20,712 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:18:20,713 - INFO - Generation token usage: 3862 (Prompt: 476, Completion: 3386, Cost: $0.2103)\n",
      "2025-02-06 07:18:20,714 - INFO - Processing section (Level 2): LGD Model Validation\n",
      "2025-02-06 07:18:20,714 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:18:20,973 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:18:22,316 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:18:45,769 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:18:45,771 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:18:45,772 - INFO - Generation token usage: 3249 (Prompt: 353, Completion: 2896, Cost: $0.1791)\n",
      "2025-02-06 07:18:45,772 - INFO - Processing section (Level 3): Introduction to LGD Validation\n",
      "2025-02-06 07:18:45,773 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:18:46,112 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:18:47,487 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:18:59,324 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:18:59,326 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:18:59,326 - INFO - Generation token usage: 1602 (Prompt: 356, Completion: 1246, Cost: $0.0801)\n",
      "2025-02-06 07:18:59,327 - INFO - Processing section (Level 3): Discriminatory Power Tests\n",
      "2025-02-06 07:18:59,327 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:18:59,664 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:19:01,010 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:19:25,321 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:19:25,323 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:19:25,323 - INFO - Generation token usage: 3025 (Prompt: 343, Completion: 2682, Cost: $0.1661)\n",
      "2025-02-06 07:19:25,324 - INFO - Processing section (Level 4): Generalized AUC (gAUC)\n",
      "2025-02-06 07:19:25,325 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:19:25,535 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:19:26,905 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:19:48,417 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:19:48,420 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:19:48,420 - INFO - Generation token usage: 2994 (Prompt: 387, Completion: 2607, Cost: $0.1622)\n",
      "2025-02-06 07:19:48,421 - INFO - Processing section (Level 3): Calibration Tests\n",
      "2025-02-06 07:19:48,422 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:19:48,676 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:19:50,040 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:20:09,703 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:20:09,706 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:20:09,706 - INFO - Generation token usage: 2565 (Prompt: 354, Completion: 2211, Cost: $0.1380)\n",
      "2025-02-06 07:20:09,707 - INFO - Processing section (Level 4): LGD Backtesting (t-test)\n",
      "2025-02-06 07:20:09,707 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:20:10,083 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:20:11,486 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:20:45,247 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:20:45,248 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:20:45,249 - INFO - Generation token usage: 4402 (Prompt: 415, Completion: 3987, Cost: $0.2454)\n",
      "2025-02-06 07:20:45,250 - INFO - Processing section (Level 4): Calibration Plots\n",
      "2025-02-06 07:20:45,250 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:20:46,252 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:20:47,578 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:21:05,957 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:21:05,959 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:21:05,960 - INFO - Generation token usage: 2553 (Prompt: 425, Completion: 2128, Cost: $0.1341)\n",
      "2025-02-06 07:21:05,961 - INFO - Processing section (Level 4): Coverage Level Adjusted R (CLAR)\n",
      "2025-02-06 07:21:05,961 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:21:06,262 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:21:07,622 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:21:26,383 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:21:26,385 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:21:26,386 - INFO - Generation token usage: 2254 (Prompt: 493, Completion: 1761, Cost: $0.1131)\n",
      "2025-02-06 07:21:26,387 - INFO - Processing section (Level 3): Stability Tests\n",
      "2025-02-06 07:21:26,387 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:21:26,695 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:21:28,038 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:21:56,050 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:21:56,052 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:21:56,053 - INFO - Generation token usage: 3709 (Prompt: 336, Completion: 3373, Cost: $0.2074)\n",
      "2025-02-06 07:21:56,054 - INFO - Processing section (Level 4): Population Stability Index (PSI)\n",
      "2025-02-06 07:21:56,054 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:21:56,421 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:21:57,737 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:22:19,371 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:22:19,373 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:22:19,374 - INFO - Generation token usage: 2559 (Prompt: 454, Completion: 2105, Cost: $0.1331)\n",
      "2025-02-06 07:22:19,374 - INFO - Processing section (Level 3): Qualitative Validation\n",
      "2025-02-06 07:22:19,375 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:22:19,707 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:22:21,035 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:22:34,872 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:22:34,875 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:22:34,876 - INFO - Generation token usage: 1852 (Prompt: 456, Completion: 1396, Cost: $0.0906)\n",
      "2025-02-06 07:22:34,876 - INFO - Processing section (Level 4): Assignment Process Statistics\n",
      "2025-02-06 07:22:34,877 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:22:35,186 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:22:36,549 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:22:51,371 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:22:51,373 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:22:51,373 - INFO - Generation token usage: 2075 (Prompt: 360, Completion: 1715, Cost: $0.1083)\n",
      "2025-02-06 07:22:51,374 - INFO - Processing section (Level 4): Portfolio Distribution\n",
      "2025-02-06 07:22:51,374 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:22:52,026 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:22:53,362 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:23:17,809 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:23:17,810 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:23:17,811 - INFO - Generation token usage: 2701 (Prompt: 399, Completion: 2302, Cost: $0.1441)\n",
      "2025-02-06 07:23:17,812 - INFO - Processing section (Level 2): EAD and CCF Model Validation\n",
      "2025-02-06 07:23:17,812 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:23:18,128 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:23:19,447 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:23:45,919 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:23:45,921 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:23:45,922 - INFO - Generation token usage: 3293 (Prompt: 401, Completion: 2892, Cost: $0.1795)\n",
      "2025-02-06 07:23:45,922 - INFO - Processing section (Level 3): Introduction to EAD/CCF\n",
      "2025-02-06 07:23:45,923 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:23:46,171 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:23:47,476 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:24:05,758 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:24:05,761 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:24:05,761 - INFO - Generation token usage: 2114 (Prompt: 396, Completion: 1718, Cost: $0.1090)\n",
      "2025-02-06 07:24:05,762 - INFO - Processing section (Level 3): CCF Discriminatory Power Tests\n",
      "2025-02-06 07:24:05,762 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:24:05,986 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:24:07,285 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:24:29,326 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:24:29,328 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:24:29,329 - INFO - Generation token usage: 3103 (Prompt: 421, Completion: 2682, Cost: $0.1672)\n",
      "2025-02-06 07:24:29,329 - INFO - Processing section (Level 4): Generalized AUC (gAUC)\n",
      "2025-02-06 07:24:29,330 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:24:29,711 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:24:31,020 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:24:53,044 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:24:53,046 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:24:53,046 - INFO - Generation token usage: 2775 (Prompt: 345, Completion: 2430, Cost: $0.1510)\n",
      "2025-02-06 07:24:53,047 - INFO - Processing section (Level 3): CCF Calibration Tests\n",
      "2025-02-06 07:24:53,047 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:24:53,618 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:24:54,940 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:25:30,429 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:25:30,431 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:25:30,432 - INFO - Generation token usage: 4012 (Prompt: 345, Completion: 3667, Cost: $0.2252)\n",
      "2025-02-06 07:25:30,432 - INFO - Processing section (Level 4): CCF Backtesting (t-test)\n",
      "2025-02-06 07:25:30,433 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:25:30,672 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:25:32,013 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:25:54,253 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:25:54,255 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:25:54,256 - INFO - Generation token usage: 2879 (Prompt: 381, Completion: 2498, Cost: $0.1556)\n",
      "2025-02-06 07:25:54,256 - INFO - Processing section (Level 3): EAD Model Validation\n",
      "2025-02-06 07:25:54,257 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:25:54,473 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:25:55,789 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:26:26,063 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:26:26,065 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:26:26,066 - INFO - Generation token usage: 2731 (Prompt: 358, Completion: 2373, Cost: $0.1477)\n",
      "2025-02-06 07:26:26,066 - INFO - Processing section (Level 4): EAD Backtesting (t-test)\n",
      "2025-02-06 07:26:26,067 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:26:26,402 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:26:27,739 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:26:54,658 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:26:54,660 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:26:54,660 - INFO - Generation token usage: 2988 (Prompt: 337, Completion: 2651, Cost: $0.1641)\n",
      "2025-02-06 07:26:54,661 - INFO - Processing section (Level 3): CCF/EAD Stability Test\n",
      "2025-02-06 07:26:54,662 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:26:54,957 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:26:56,297 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:27:27,251 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:27:27,252 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:27:27,253 - INFO - Generation token usage: 4058 (Prompt: 343, Completion: 3715, Cost: $0.2280)\n",
      "2025-02-06 07:27:27,254 - INFO - Processing section (Level 4): Population Stability Index (PSI)\n",
      "2025-02-06 07:27:27,254 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:27:30,550 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:27:31,870 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:27:55,004 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:27:55,006 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:27:55,006 - INFO - Generation token usage: 2565 (Prompt: 366, Completion: 2199, Cost: $0.1374)\n",
      "2025-02-06 07:27:55,007 - INFO - Processing section (Level 3): Qualitative Validation\n",
      "2025-02-06 07:27:55,007 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:27:55,311 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:27:56,650 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:28:23,552 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:28:23,554 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:28:23,555 - INFO - Generation token usage: 2875 (Prompt: 377, Completion: 2498, Cost: $0.1555)\n",
      "2025-02-06 07:28:23,555 - INFO - Processing section (Level 4): Assignment Process Statistics\n",
      "2025-02-06 07:28:23,556 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:28:23,803 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:28:25,162 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:28:53,463 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:28:53,465 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:28:53,466 - INFO - Generation token usage: 3081 (Prompt: 333, Completion: 2748, Cost: $0.1699)\n",
      "2025-02-06 07:28:53,467 - INFO - Processing section (Level 4): Portfolio Distribution\n",
      "2025-02-06 07:28:53,468 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:28:53,801 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:28:55,117 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:29:16,769 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:29:16,772 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:29:16,772 - INFO - Generation token usage: 2115 (Prompt: 339, Completion: 1776, Cost: $0.1116)\n",
      "2025-02-06 07:29:16,773 - INFO - Processing section (Level 2): ELBE and LGD-in-default Validation\n",
      "2025-02-06 07:29:16,774 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:29:17,421 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:29:18,750 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:29:36,815 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:29:36,817 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:29:36,818 - INFO - Generation token usage: 2461 (Prompt: 480, Completion: 1981, Cost: $0.1261)\n",
      "2025-02-06 07:29:36,818 - INFO - Processing section (Level 3): Introduction\n",
      "2025-02-06 07:29:36,819 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:29:37,094 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:29:38,435 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:29:59,954 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:29:59,956 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:29:59,956 - INFO - Generation token usage: 2511 (Prompt: 412, Completion: 2099, Cost: $0.1321)\n",
      "2025-02-06 07:29:59,957 - INFO - Processing section (Level 3): ELBE Calibration\n",
      "2025-02-06 07:29:59,958 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:30:00,188 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:30:01,501 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:30:26,847 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:30:26,849 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:30:26,850 - INFO - Generation token usage: 3423 (Prompt: 347, Completion: 3076, Cost: $0.1898)\n",
      "2025-02-06 07:30:26,851 - INFO - Processing section (Level 4): ELBE Backtesting (t-test)\n",
      "2025-02-06 07:30:26,851 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:30:27,173 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:30:28,598 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:30:47,626 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:30:47,628 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:30:47,629 - INFO - Generation token usage: 2642 (Prompt: 380, Completion: 2262, Cost: $0.1414)\n",
      "2025-02-06 07:30:47,630 - INFO - Processing section (Level 3): LGD-in-default Calibration\n",
      "2025-02-06 07:30:47,630 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:30:47,863 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:30:49,210 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:31:09,083 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:31:09,087 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:31:09,088 - INFO - Generation token usage: 2667 (Prompt: 355, Completion: 2312, Cost: $0.1440)\n",
      "2025-02-06 07:31:09,088 - INFO - Processing section (Level 4): LGD-in-default Back-testing (t-test)\n",
      "2025-02-06 07:31:09,089 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:31:09,432 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:31:10,733 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:31:30,410 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:31:30,412 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:31:30,413 - INFO - Generation token usage: 2684 (Prompt: 421, Completion: 2263, Cost: $0.1421)\n",
      "2025-02-06 07:31:30,414 - INFO - Processing section (Level 2): Benchmarking, Sensitivity, Stress Testing\n",
      "2025-02-06 07:31:30,414 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:31:30,767 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:31:32,094 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:31:54,193 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:31:54,196 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:31:54,196 - INFO - Generation token usage: 2719 (Prompt: 467, Completion: 2252, Cost: $0.1421)\n",
      "2025-02-06 07:31:54,197 - INFO - Processing section (Level 3): Benchmarking Models\n",
      "2025-02-06 07:31:54,198 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:31:54,783 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:31:56,129 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:32:12,284 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:32:12,286 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:32:12,287 - INFO - Generation token usage: 1601 (Prompt: 322, Completion: 1279, Cost: $0.0816)\n",
      "2025-02-06 07:32:12,287 - INFO - Processing section (Level 4): Selecting Benchmarks\n",
      "2025-02-06 07:32:12,288 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:32:12,725 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:32:14,041 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:32:31,335 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:32:31,341 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:32:31,341 - INFO - Generation token usage: 2451 (Prompt: 462, Completion: 1989, Cost: $0.1263)\n",
      "2025-02-06 07:32:31,342 - INFO - Processing section (Level 4): Internal and External Benchmarks\n",
      "2025-02-06 07:32:31,342 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:32:31,692 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:32:33,054 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:32:48,036 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:32:48,038 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:32:48,039 - INFO - Generation token usage: 2189 (Prompt: 345, Completion: 1844, Cost: $0.1158)\n",
      "2025-02-06 07:32:48,039 - INFO - Processing section (Level 4): Benchmarking Methods\n",
      "2025-02-06 07:32:48,040 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:32:48,270 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:32:49,595 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:33:18,354 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:33:18,356 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:33:18,356 - INFO - Generation token usage: 4041 (Prompt: 459, Completion: 3582, Cost: $0.2218)\n",
      "2025-02-06 07:33:18,357 - INFO - Processing section (Level 3): Sensitivity Analysis\n",
      "2025-02-06 07:33:18,357 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:33:18,695 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:33:20,001 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:33:43,911 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:33:43,913 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:33:43,913 - INFO - Generation token usage: 2988 (Prompt: 387, Completion: 2601, Cost: $0.1619)\n",
      "2025-02-06 07:33:43,914 - INFO - Processing section (Level 3): Stress Testing\n",
      "2025-02-06 07:33:43,915 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:33:44,230 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:33:45,549 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:34:08,016 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:34:08,018 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:34:08,018 - INFO - Generation token usage: 2734 (Prompt: 362, Completion: 2372, Cost: $0.1477)\n",
      "2025-02-06 07:34:08,018 - INFO - Processing section (Level 2): Advanced Topics\n",
      "2025-02-06 07:34:08,019 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:34:08,228 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:34:09,541 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:34:35,922 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:34:35,924 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:34:35,925 - INFO - Generation token usage: 3522 (Prompt: 399, Completion: 3123, Cost: $0.1934)\n",
      "2025-02-06 07:34:35,926 - INFO - Processing section (Level 3): Low Default Portfolios\n",
      "2025-02-06 07:34:35,926 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:34:36,160 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:34:37,464 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:34:56,352 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:34:56,354 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:34:56,355 - INFO - Generation token usage: 2626 (Prompt: 346, Completion: 2280, Cost: $0.1420)\n",
      "2025-02-06 07:34:56,355 - INFO - Processing section (Level 3): Overfitting, Model Selection, Data\n",
      "2025-02-06 07:34:56,356 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:34:56,576 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:34:57,875 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:35:19,713 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:35:19,715 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:35:19,715 - INFO - Generation token usage: 2841 (Prompt: 397, Completion: 2444, Cost: $0.1526)\n",
      "2025-02-06 07:35:19,716 - INFO - Processing section (Level 3): Machine Learning Models\n",
      "2025-02-06 07:35:19,717 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:35:20,087 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:35:21,404 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:35:42,084 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:35:42,090 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:35:42,090 - INFO - Generation token usage: 2549 (Prompt: 358, Completion: 2191, Cost: $0.1368)\n",
      "2025-02-06 07:35:42,091 - INFO - Processing section (Level 3): Explainable AI (XAI)\n",
      "2025-02-06 07:35:42,091 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:35:42,486 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:35:43,809 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:35:55,943 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:35:55,945 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:35:55,946 - INFO - Generation token usage: 1877 (Prompt: 425, Completion: 1452, Cost: $0.0935)\n",
      "2025-02-06 07:35:55,946 - INFO - Processing section (Level 3): Changing Economic Environment\n",
      "2025-02-06 07:35:55,947 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:35:56,290 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:35:57,690 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:36:20,240 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:36:20,242 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:36:20,243 - INFO - Generation token usage: 3139 (Prompt: 340, Completion: 2799, Cost: $0.1730)\n",
      "2025-02-06 07:36:20,243 - INFO - Processing section (Level 3): Specialised Lending exposures.\n",
      "2025-02-06 07:36:20,244 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:36:20,489 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:36:21,797 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:36:39,117 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:36:39,118 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:36:39,119 - INFO - Generation token usage: 2295 (Prompt: 335, Completion: 1960, Cost: $0.1226)\n",
      "2025-02-06 07:36:39,120 - INFO - Processing section (Level 1): Appendix\n",
      "2025-02-06 07:36:39,120 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:36:39,351 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:36:40,653 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:37:11,582 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:37:11,583 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:37:11,584 - INFO - Generation token usage: 4484 (Prompt: 322, Completion: 4162, Cost: $0.2545)\n",
      "2025-02-06 07:37:11,584 - INFO - Processing section (Level 2): Statistical Tables\n",
      "2025-02-06 07:37:11,585 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:37:11,907 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:37:13,215 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:37:55,564 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:37:55,566 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:37:55,567 - INFO - Generation token usage: 4692 (Prompt: 351, Completion: 4341, Cost: $0.2657)\n",
      "2025-02-06 07:37:55,567 - INFO - Processing section (Level 2): Glossary of Terms\n",
      "2025-02-06 07:37:55,568 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:37:55,914 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:37:57,249 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:38:24,070 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:38:24,073 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:38:24,074 - INFO - Generation token usage: 3351 (Prompt: 322, Completion: 3029, Cost: $0.1866)\n",
      "2025-02-06 07:38:24,075 - INFO - Processing section (Level 2): Code Library (Python/R)\n",
      "2025-02-06 07:38:24,076 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:38:24,321 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:38:25,637 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:39:08,443 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:39:08,445 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:39:08,446 - INFO - Generation token usage: 4054 (Prompt: 334, Completion: 3720, Cost: $0.2282)\n",
      "2025-02-06 07:39:08,446 - INFO - Processing section (Level 2): Case Studies\n",
      "2025-02-06 07:39:08,447 - INFO - Finding similar background for section intro...\n",
      "2025-02-06 07:39:08,676 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:39:09,986 - INFO - Generating text with OpenAI for section intro...\n",
      "2025-02-06 07:39:40,463 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-06 07:39:40,465 - INFO - LLM call for content generation completed.\n",
      "2025-02-06 07:39:40,466 - INFO - Generation token usage: 4444 (Prompt: 311, Completion: 4133, Cost: $0.2526)\n",
      "2025-02-06 07:39:40,469 - INFO - Saved LaTeX output to generated_book_v2.tex\n",
      "2025-02-06 07:39:40,469 - INFO - Book generation complete!\n",
      "2025-02-06 07:39:40,470 - INFO - Total cost of the run: $16.11\n",
      "2025-02-06 07:39:40,470 - INFO - Now you can compile 'generated_book_v2.tex' with LaTeX (e.g., pdflatex).\n"
     ]
    }
   ],
   "source": [
    "# --- Main Function (Modified for Flat Structure) ---\n",
    "def main():\n",
    "    \"\"\"Main function to generate the book content.\"\"\"\n",
    "    global TOTAL_COST  # Make sure to update this where you incur costs\n",
    "\n",
    "    # Load the book outline\n",
    "    book_outline = load_json_outline(JSON_OUTLINE_FILE)\n",
    "\n",
    "    # Load the background DataFrame.\n",
    "    try:\n",
    "        background_df = load_pandas_dataframe(PANDAS_DF_FILE)\n",
    "    except Exception as e:\n",
    "        logging.info(f\"Falling back to direct pickle load for background data: {e}\")\n",
    "        background_df = load_dataframe_from_pickle(PANDAS_DF_FILE)\n",
    "\n",
    "    # Create the LaTeX preamble\n",
    "    latex_content = create_latex_preamble(\n",
    "        title=\"Validation of credit risk models\",\n",
    "        author=\"Collaboration between Human and AI\"\n",
    "    )\n",
    "    logging.info(\"Generating book content section by section...\")\n",
    "\n",
    "    contents = book_outline[\"table_of_contents\"][:6]\n",
    "    # contents = book_outline[\"table_of_contents\"]\n",
    "\n",
    "    for section_data in contents:\n",
    "        level = section_data[\"level\"]\n",
    "        heading = section_data[\"heading\"]\n",
    "        goal = section_data[\"goal\"]\n",
    "        required_background = section_data[\"required_background\"]\n",
    "\n",
    "        logging.info(f\"Processing section (Level {level}): {heading}\")\n",
    "        logging.info(\"Finding similar background for section intro...\")\n",
    "\n",
    "        similar_background_text = find_similar_background_text(\n",
    "            background_df, goal, TEXT_COLUMN_NAME, EMBEDDING_COLUMN_NAME\n",
    "        )\n",
    "\n",
    "        logging.info(\"Generating text with OpenAI for section intro...\")\n",
    "    \n",
    "        generated_section_text = generate_content_text(\n",
    "            title=heading,\n",
    "            goal=goal,\n",
    "            level=level,\n",
    "            background_text=similar_background_text,\n",
    "            model=OPENAI_MODEL,\n",
    "            use_langchain=True  # Adjust as needed\n",
    "        )\n",
    "\n",
    "        # Convert any Markdown code blocks to lstlisting environments\n",
    "        generated_section_text = convert_markdown_code_blocks_to_lstlisting(generated_section_text)\n",
    "        latex_content += create_latex_section(generated_section_text)\n",
    "\n",
    "\n",
    "    latex_content += create_latex_postamble()\n",
    "\n",
    "    # Save the LaTeX output to a file\n",
    "    try:\n",
    "        with open(LATEX_OUTPUT_FILE, \"w\", encoding=\"utf-8\") as outfile:\n",
    "            outfile.write(latex_content)\n",
    "        logging.info(f\"Saved LaTeX output to {LATEX_OUTPUT_FILE}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving LaTeX file: {e}\")\n",
    "\n",
    "    logging.info(\"Book generation complete!\")\n",
    "    logging.info(f\"Total cost of the run: ${TOTAL_COST:.2f}\")\n",
    "    logging.info(f\"Now you can compile '{LATEX_OUTPUT_FILE}' with LaTeX (e.g., pdflatex).\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ce238-29a2-4cb7-96d1-575f4982853d",
   "metadata": {},
   "source": [
    "### E. Convert to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8abdae39-036f-4689-afe4-34dc18da61b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during LaTeX compilation: Command '['pdflatex', 'generated_book_v2.tex']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "compile_latex_to_pdf(\"generated_book_v2.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c301cc-6f0a-4ff1-88b7-e8b8cb6f527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdflatex -output-directory=C:/projects/generate_documents/latex_materials generated_book_v19.tex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
