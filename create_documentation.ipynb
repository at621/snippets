{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e322809-b24f-472c-9703-86a8f23d391d",
   "metadata": {},
   "source": [
    "### Create documentation\n",
    "\n",
    "**PROMPT**  \n",
    "You are a subject matter expert on credit risk policies, regulatory compliance (e.g., Basel III),   \n",
    "and internal governance standards. I have a set of documents covering regulations, internal   \n",
    "guidelines, and reference materials. I also have a Table of Contents (ToC) that outlines how I   \n",
    "want the final policy to be structured. \n",
    "\n",
    "Using only the content retrieved from the provided documents and guided by the ToC, please   \n",
    "create each policy section. For each section, incorporate references to relevant regulatory   \n",
    "requirements, define any necessary terminology, and outline best practices for credit risk   \n",
    "assessment, approval workflows, monitoring, reporting, governance, and compliance. \n",
    "\n",
    "Keep the language concise, clear, and aligned with standard industry formats. Structure your   \n",
    "final output according to the headings in the ToC, ensuring a coherent, well-organized policy   \n",
    "that meets both regulatory and internal standards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49962e85-f29d-4a82-a54f-ada46ff5a878",
   "metadata": {},
   "source": [
    "#### CreditRiskPolicyAgent Overview\n",
    "\n",
    "- **Purpose**: Automate creation and refinement of a Credit Risk Policy document  \n",
    "- **Components**:  \n",
    "  - **DocumentCreator**: Fetches context from Chroma and drafts each section  \n",
    "  - **DocumentEvaluator**: Reviews each draft, providing feedback for improvement  \n",
    "  - **FinalReviewer**: Conducts a final holistic assessment of the entire policy  \n",
    "\n",
    "#### Workflow\n",
    "\n",
    "1. **Draft**:  \n",
    "   The creator pulls relevant text from the Chroma database.  \n",
    "   It then produces an initial section draft.  \n",
    "\n",
    "2. **Evaluate**:  \n",
    "   The evaluator checks accuracy, clarity, and compliance.  \n",
    "   Feedback is generated for each section.  \n",
    "\n",
    "3. **Refine**:  \n",
    "   The creator refines the draft, based on evaluator feedback.  \n",
    "\n",
    "4. **Final Review**:  \n",
    "   Once all sections are ready, the FinalReviewer inspects the entire policy.  \n",
    "   It ensures coherence and makes any final improvements.  \n",
    "\n",
    "#### Key Methods\n",
    "\n",
    "- **draft_section(section_title)**  \n",
    "  Creates a preliminary version of a policy section.  \n",
    "\n",
    "- **evaluate_section(draft_text)**  \n",
    "  Reviews the text for correctness and suggests enhancements.  \n",
    "\n",
    "- **refine_with_feedback(draft_text, feedback)**  \n",
    "  Applies feedback to produce a better draft.  \n",
    "\n",
    "- **review_document(entire_document)**  \n",
    "  Performs the last check on the policy as a whole.  \n",
    "\n",
    "#### Usage\n",
    "\n",
    "1. **Initialize** the CreditRiskPolicyAgent with your API key and Chroma collection.  \n",
    "2. **Provide** a table of contents for the policy.  \n",
    "3. **Call** `build_policy`, which executes draft, evaluate, refine, and final review steps.  \n",
    "4. **Receive** a fully formed policy document, ready for adoption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c359fbc0-4fc6-4ba5-8241-10c566b0954a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 06:26:05,332 - INFO - Initializing CreditRiskPolicyAgent...\n",
      "2025-01-24 06:26:07,061 - INFO - Initializing DocumentCreator...\n",
      "2025-01-24 06:26:07,062 - INFO - DocumentCreator initialized.\n",
      "2025-01-24 06:26:07,062 - INFO - Initializing DocumentEvaluator...\n",
      "2025-01-24 06:26:07,063 - INFO - DocumentEvaluator initialized.\n",
      "2025-01-24 06:26:07,063 - INFO - Initializing FinalReviewer...\n",
      "2025-01-24 06:26:07,064 - INFO - FinalReviewer initialized.\n",
      "2025-01-24 06:26:07,064 - INFO - CreditRiskPolicyAgent initialized.\n",
      "2025-01-24 06:26:07,065 - INFO - Starting to build final document...\n",
      "2025-01-24 06:26:07,066 - INFO - Starting policy building process...\n",
      "2025-01-24 06:26:07,066 - INFO - Processing section: 'Introduction and Scope'...\n",
      "2025-01-24 06:26:07,066 - INFO - Drafting section: 'Introduction and Scope'...\n",
      "2025-01-24 06:26:07,067 - INFO - Retrieving context for section: 'Introduction and Scope'...\n",
      "2025-01-24 06:26:07,361 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:26:07,365 - INFO - Context retrieved for section: 'Introduction and Scope'. Context length: 0 characters.\n",
      "2025-01-24 06:26:26,843 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:26:26,871 - INFO - LLM call for drafting section 'Introduction and Scope' completed.\n",
      "2025-01-24 06:26:26,873 - INFO - Drafting section 'Introduction and Scope' token usage: 749 (Prompt: 79, Completion: 670, Cost: $0.0426)\n",
      "2025-01-24 06:26:26,873 - INFO - Section 'Introduction and Scope' drafted.\n",
      "2025-01-24 06:26:26,873 - INFO - Evaluating section...\n",
      "2025-01-24 06:26:39,289 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:26:39,295 - INFO - LLM call for section evaluation completed.\n",
      "2025-01-24 06:26:39,296 - INFO - Evaluation token usage: 1018 (Prompt: 715, Completion: 303, Cost: $0.0396)\n",
      "2025-01-24 06:26:39,296 - INFO - Section evaluated, feedback generated.\n",
      "2025-01-24 06:26:39,296 - INFO - Refining section with feedback...\n",
      "2025-01-24 06:26:59,261 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:26:59,263 - INFO - LLM call for refining section with feedback completed.\n",
      "2025-01-24 06:26:59,264 - INFO - Refinement token usage: 1684 (Prompt: 1009, Completion: 675, Cost: $0.0708)\n",
      "2025-01-24 06:26:59,264 - INFO - Section refined with feedback.\n",
      "2025-01-24 06:26:59,265 - INFO - Section 'Introduction and Scope' processing complete.\n",
      "2025-01-24 06:26:59,265 - INFO - Processing section: 'Definitions and Terminology'...\n",
      "2025-01-24 06:26:59,266 - INFO - Drafting section: 'Definitions and Terminology'...\n",
      "2025-01-24 06:26:59,266 - INFO - Retrieving context for section: 'Definitions and Terminology'...\n",
      "2025-01-24 06:26:59,670 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:26:59,674 - INFO - Context retrieved for section: 'Definitions and Terminology'. Context length: 0 characters.\n",
      "2025-01-24 06:27:21,329 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:27:21,338 - INFO - LLM call for drafting section 'Definitions and Terminology' completed.\n",
      "2025-01-24 06:27:21,339 - INFO - Drafting section 'Definitions and Terminology' token usage: 574 (Prompt: 74, Completion: 500, Cost: $0.0322)\n",
      "2025-01-24 06:27:21,339 - INFO - Section 'Definitions and Terminology' drafted.\n",
      "2025-01-24 06:27:21,340 - INFO - Evaluating section...\n",
      "2025-01-24 06:27:28,293 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:27:28,303 - INFO - LLM call for section evaluation completed.\n",
      "2025-01-24 06:27:28,303 - INFO - Evaluation token usage: 783 (Prompt: 545, Completion: 238, Cost: $0.0306)\n",
      "2025-01-24 06:27:28,304 - INFO - Section evaluated, feedback generated.\n",
      "2025-01-24 06:27:28,304 - INFO - Refining section with feedback...\n",
      "2025-01-24 06:27:42,122 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:27:42,126 - INFO - LLM call for refining section with feedback completed.\n",
      "2025-01-24 06:27:42,126 - INFO - Refinement token usage: 1325 (Prompt: 774, Completion: 551, Cost: $0.0563)\n",
      "2025-01-24 06:27:42,126 - INFO - Section refined with feedback.\n",
      "2025-01-24 06:27:42,127 - INFO - Section 'Definitions and Terminology' processing complete.\n",
      "2025-01-24 06:27:42,128 - INFO - Processing section: 'Risk Assessment Methodology'...\n",
      "2025-01-24 06:27:42,128 - INFO - Drafting section: 'Risk Assessment Methodology'...\n",
      "2025-01-24 06:27:42,129 - INFO - Retrieving context for section: 'Risk Assessment Methodology'...\n",
      "2025-01-24 06:27:42,506 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:27:42,509 - INFO - Context retrieved for section: 'Risk Assessment Methodology'. Context length: 0 characters.\n",
      "2025-01-24 06:27:53,263 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:27:53,270 - INFO - LLM call for drafting section 'Risk Assessment Methodology' completed.\n",
      "2025-01-24 06:27:53,271 - INFO - Drafting section 'Risk Assessment Methodology' token usage: 532 (Prompt: 78, Completion: 454, Cost: $0.0296)\n",
      "2025-01-24 06:27:53,271 - INFO - Section 'Risk Assessment Methodology' drafted.\n",
      "2025-01-24 06:27:53,272 - INFO - Evaluating section...\n",
      "2025-01-24 06:28:01,270 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:28:01,280 - INFO - LLM call for section evaluation completed.\n",
      "2025-01-24 06:28:01,281 - INFO - Evaluation token usage: 784 (Prompt: 499, Completion: 285, Cost: $0.0321)\n",
      "2025-01-24 06:28:01,281 - INFO - Section evaluated, feedback generated.\n",
      "2025-01-24 06:28:01,282 - INFO - Refining section with feedback...\n",
      "2025-01-24 06:28:12,370 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:28:12,374 - INFO - LLM call for refining section with feedback completed.\n",
      "2025-01-24 06:28:12,374 - INFO - Refinement token usage: 1297 (Prompt: 775, Completion: 522, Cost: $0.0546)\n",
      "2025-01-24 06:28:12,375 - INFO - Section refined with feedback.\n",
      "2025-01-24 06:28:12,375 - INFO - Section 'Risk Assessment Methodology' processing complete.\n",
      "2025-01-24 06:28:12,376 - INFO - Processing section: 'Credit Approval Workflow'...\n",
      "2025-01-24 06:28:12,377 - INFO - Drafting section: 'Credit Approval Workflow'...\n",
      "2025-01-24 06:28:12,378 - INFO - Retrieving context for section: 'Credit Approval Workflow'...\n",
      "2025-01-24 06:28:12,599 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:28:12,603 - INFO - Context retrieved for section: 'Credit Approval Workflow'. Context length: 0 characters.\n",
      "2025-01-24 06:28:34,815 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:28:34,817 - INFO - LLM call for drafting section 'Credit Approval Workflow' completed.\n",
      "2025-01-24 06:28:34,817 - INFO - Drafting section 'Credit Approval Workflow' token usage: 569 (Prompt: 76, Completion: 493, Cost: $0.0319)\n",
      "2025-01-24 06:28:34,818 - INFO - Section 'Credit Approval Workflow' drafted.\n",
      "2025-01-24 06:28:34,819 - INFO - Evaluating section...\n",
      "2025-01-24 06:28:42,647 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:28:42,652 - INFO - LLM call for section evaluation completed.\n",
      "2025-01-24 06:28:42,652 - INFO - Evaluation token usage: 796 (Prompt: 538, Completion: 258, Cost: $0.0316)\n",
      "2025-01-24 06:28:42,653 - INFO - Section evaluated, feedback generated.\n",
      "2025-01-24 06:28:42,653 - INFO - Refining section with feedback...\n",
      "2025-01-24 06:29:08,143 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:29:08,145 - INFO - LLM call for refining section with feedback completed.\n",
      "2025-01-24 06:29:08,146 - INFO - Refinement token usage: 1327 (Prompt: 787, Completion: 540, Cost: $0.0560)\n",
      "2025-01-24 06:29:08,146 - INFO - Section refined with feedback.\n",
      "2025-01-24 06:29:08,147 - INFO - Section 'Credit Approval Workflow' processing complete.\n",
      "2025-01-24 06:29:08,147 - INFO - Processing section: 'Monitoring and Reporting'...\n",
      "2025-01-24 06:29:08,148 - INFO - Drafting section: 'Monitoring and Reporting'...\n",
      "2025-01-24 06:29:08,148 - INFO - Retrieving context for section: 'Monitoring and Reporting'...\n",
      "2025-01-24 06:29:08,691 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:29:08,695 - INFO - Context retrieved for section: 'Monitoring and Reporting'. Context length: 0 characters.\n",
      "2025-01-24 06:29:28,161 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:29:28,174 - INFO - LLM call for drafting section 'Monitoring and Reporting' completed.\n",
      "2025-01-24 06:29:28,174 - INFO - Drafting section 'Monitoring and Reporting' token usage: 586 (Prompt: 75, Completion: 511, Cost: $0.0329)\n",
      "2025-01-24 06:29:28,175 - INFO - Section 'Monitoring and Reporting' drafted.\n",
      "2025-01-24 06:29:28,176 - INFO - Evaluating section...\n",
      "2025-01-24 06:29:38,728 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:29:38,730 - INFO - LLM call for section evaluation completed.\n",
      "2025-01-24 06:29:38,731 - INFO - Evaluation token usage: 796 (Prompt: 556, Completion: 240, Cost: $0.0311)\n",
      "2025-01-24 06:29:38,732 - INFO - Section evaluated, feedback generated.\n",
      "2025-01-24 06:29:38,732 - INFO - Refining section with feedback...\n",
      "2025-01-24 06:29:53,861 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:29:53,871 - INFO - LLM call for refining section with feedback completed.\n",
      "2025-01-24 06:29:53,871 - INFO - Refinement token usage: 1336 (Prompt: 787, Completion: 549, Cost: $0.0566)\n",
      "2025-01-24 06:29:53,872 - INFO - Section refined with feedback.\n",
      "2025-01-24 06:29:53,872 - INFO - Section 'Monitoring and Reporting' processing complete.\n",
      "2025-01-24 06:29:53,873 - INFO - Processing section: 'Governance and Compliance'...\n",
      "2025-01-24 06:29:53,874 - INFO - Drafting section: 'Governance and Compliance'...\n",
      "2025-01-24 06:29:53,874 - INFO - Retrieving context for section: 'Governance and Compliance'...\n",
      "2025-01-24 06:29:54,325 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:29:54,329 - INFO - Context retrieved for section: 'Governance and Compliance'. Context length: 0 characters.\n",
      "2025-01-24 06:30:18,455 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:30:18,457 - INFO - LLM call for drafting section 'Governance and Compliance' completed.\n",
      "2025-01-24 06:30:18,458 - INFO - Drafting section 'Governance and Compliance' token usage: 568 (Prompt: 74, Completion: 494, Cost: $0.0319)\n",
      "2025-01-24 06:30:18,458 - INFO - Section 'Governance and Compliance' drafted.\n",
      "2025-01-24 06:30:18,459 - INFO - Evaluating section...\n",
      "2025-01-24 06:30:28,245 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:30:28,326 - INFO - LLM call for section evaluation completed.\n",
      "2025-01-24 06:30:28,326 - INFO - Evaluation token usage: 881 (Prompt: 539, Completion: 342, Cost: $0.0367)\n",
      "2025-01-24 06:30:28,326 - INFO - Section evaluated, feedback generated.\n",
      "2025-01-24 06:30:28,327 - INFO - Refining section with feedback...\n",
      "2025-01-24 06:31:00,656 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:31:00,659 - INFO - LLM call for refining section with feedback completed.\n",
      "2025-01-24 06:31:00,660 - INFO - Refinement token usage: 1516 (Prompt: 872, Completion: 644, Cost: $0.0648)\n",
      "2025-01-24 06:31:00,660 - INFO - Section refined with feedback.\n",
      "2025-01-24 06:31:00,661 - INFO - Section 'Governance and Compliance' processing complete.\n",
      "2025-01-24 06:31:00,661 - INFO - Conducting final document review...\n",
      "2025-01-24 06:31:20,932 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 06:31:20,935 - INFO - LLM call for final document review completed.\n",
      "2025-01-24 06:31:20,936 - INFO - Final review token usage: 4153 (Prompt: 3554, Completion: 599, Cost: $0.1426)\n",
      "2025-01-24 06:31:20,936 - INFO - Final document review completed.\n",
      "2025-01-24 06:31:20,937 - INFO - Policy building process completed.\n",
      "2025-01-24 06:31:20,937 - INFO - Final document build complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL POLICY DOCUMENT:\n",
      "\n",
      "After a thorough review, the policy appears consistent and complete. It covers all the essential points needed for a robust credit risk policy, including the introduction and scope, best practices for credit risk management, regulatory compliance, policy review, exceptions, violations, definitions, risk assessment methodology, credit approval workflow, monitoring and reporting, and governance and compliance. \n",
      "\n",
      "The policy is also aligned with Basel III standards and regulatory requirements, which is crucial for any financial institution. The roles and responsibilities of different entities, such as the Board of Directors, Risk Management Committee, and Credit Department, are clearly defined. \n",
      "\n",
      "One suggestion for improvement could be to add a section on the consequences of policy violations. While Section 6 mentions that violations could lead to disciplinary action, it could be helpful to provide more details on the specific consequences, such as warnings, retraining, or legal action.\n",
      "\n",
      "Here is the final revised text:\n",
      "\n",
      "Introduction and Scope\n",
      "\n",
      "The Credit Risk Policy of our company outlines how we manage credit risk in line with Basel III framework and our internal guidelines. This policy applies to all credit exposures and details our procedures for credit risk assessment, management, and mitigation.\n",
      "\n",
      "Credit Risk Management Best Practices\n",
      "\n",
      "We employ a systematic process for identifying and classifying credit risk across all business lines and credit-related products. Our company assesses borrowers' creditworthiness through a thorough credit risk assessment process. We use both quantitative and qualitative factors to measure credit risk and implement effective credit risk mitigation strategies. We monitor and report our credit risk exposures and the quality of our credit portfolio regularly.\n",
      "\n",
      "Regulatory Compliance\n",
      "\n",
      "We comply with all relevant regulatory requirements related to credit risk management, including Basel III and local regulations.\n",
      "\n",
      "Policy Review and Exceptions\n",
      "\n",
      "This policy is reviewed at least annually to ensure its continued relevance and effectiveness. Any exceptions to this policy must be approved by the board of directors or a designated committee.\n",
      "\n",
      "Policy Violations\n",
      "\n",
      "Violations of this policy could result in disciplinary action, up to and including termination of employment. \n",
      "\n",
      "Definitions and Terminology\n",
      "\n",
      "Our Credit Risk Policy includes definitions of key terms such as Credit Risk, Credit Exposure, and Default.\n",
      "\n",
      "Risk Assessment Methodology\n",
      "\n",
      "Our Credit Risk Policy details our approach to identifying, measuring, and monitoring credit risks. We use both qualitative and quantitative methods to measure credit risk and comply with Basel III guidelines and our internal risk management guidelines.\n",
      "\n",
      "Credit Approval Workflow\n",
      "\n",
      "Our Credit Approval Workflow outlines the stages of our credit approval process, including credit application, assessment, scoring, approval, and disbursement.\n",
      "\n",
      "Monitoring and Reporting\n",
      "\n",
      "Our company is committed to monitoring and reporting credit risk. We prepare monthly credit risk reports and our activities comply with Basel III, local regulations, and internal risk management policies.\n",
      "\n",
      "Governance and Compliance\n",
      "\n",
      "We have a robust governance structure for managing credit risk, with clearly defined roles and responsibilities for the Board of Directors and the Credit Risk Management Committee. Compliance with our policy is mandatory for all employees involved in lending operations. \n",
      "\n",
      "This Credit Risk Policy ensures our company's financial stability and long-term success.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class DocumentCreator:\n",
    "    \"\"\"\n",
    "    Creates and refines policy sections.\n",
    "    Pulls context from Chroma by passing heading, overall doc, and section desc as the query.\n",
    "    \"\"\"\n",
    "    def __init__(self, llm, retriever):\n",
    "        logging.info(\"Initializing DocumentCreator...\")\n",
    "        self.llm = llm\n",
    "        self.retriever = retriever\n",
    "        logging.info(\"DocumentCreator initialized.\")\n",
    "\n",
    "    def retrieve_context(self, overall_desc, section_title, section_desc):\n",
    "        logging.info(f\"Retrieving context for section: '{section_title}'...\")\n",
    "        query_text = (\n",
    "            f\"Overall Document: {overall_desc}\\n\"\n",
    "            f\"Section Title: {section_title}\\n\"\n",
    "            f\"Section Description: {section_desc}\"\n",
    "        )\n",
    "        # Retrieve relevant documents\n",
    "        docs = self.retriever.get_relevant_documents(query_text)\n",
    "        context = \"\\n\".join([d.page_content for d in docs])\n",
    "        logging.info(f\"Context retrieved for section: '{section_title}'. Context length: {len(context)} characters.\")\n",
    "        return context\n",
    "\n",
    "    def draft_section(self, overall_desc, section_title, section_desc):\n",
    "        logging.info(f\"Drafting section: '{section_title}'...\")\n",
    "        # Create a chat prompt with system and user instructions\n",
    "        system_template = (\n",
    "            \"You are drafting a Credit Risk Policy section. \"\n",
    "            \"Incorporate best practices and references.\"\n",
    "        )\n",
    "        user_template = (\n",
    "            \"Section Title: {section_title}\\n\"\n",
    "            \"Overall Description: {overall_desc}\\n\"\n",
    "            \"Section Description: {section_desc}\\n\"\n",
    "            \"Relevant Context:\\n{context}\\n\\n\"\n",
    "            \"Draft the policy section.\"\n",
    "        )\n",
    "\n",
    "        system_msg = SystemMessagePromptTemplate.from_template(system_template)\n",
    "        human_msg = HumanMessagePromptTemplate.from_template(user_template)\n",
    "\n",
    "        # Retrieve any relevant context from Chroma\n",
    "        context = self.retrieve_context(overall_desc, section_title, section_desc)\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_msg, human_msg])\n",
    "        formatted_prompt = chat_prompt.format_messages(\n",
    "            section_title=section_title,\n",
    "            overall_desc=overall_desc,\n",
    "            section_desc=section_desc,\n",
    "            context=context\n",
    "        )\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            response = self.llm.invoke(formatted_prompt)\n",
    "            logging.info(f\"LLM call for drafting section '{section_title}' completed.\")\n",
    "            logging.info(f\"Drafting section '{section_title}' token usage: {cb.total_tokens} (Prompt: {cb.prompt_tokens}, Completion: {cb.completion_tokens}, Cost: ${cb.total_cost:.4f})\")\n",
    "\n",
    "        logging.info(f\"Section '{section_title}' drafted.\")\n",
    "        return response.content\n",
    "\n",
    "    def refine_with_feedback(self, draft, feedback):\n",
    "        logging.info(f\"Refining section with feedback...\")\n",
    "        system_template = (\n",
    "            \"You are refining a policy section draft based on reviewer feedback.\"\n",
    "        )\n",
    "        user_template = (\n",
    "            \"Original Draft:\\n{draft}\\n\\n\"\n",
    "            \"Reviewer Feedback:\\n{feedback}\\n\\n\"\n",
    "            \"Refine the draft, addressing all feedback.\"\n",
    "        )\n",
    "\n",
    "        system_msg = SystemMessagePromptTemplate.from_template(system_template)\n",
    "        human_msg = HumanMessagePromptTemplate.from_template(user_template)\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_msg, human_msg])\n",
    "        formatted_prompt = chat_prompt.format_messages(draft=draft, feedback=feedback)\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            response = self.llm.invoke(formatted_prompt)\n",
    "            logging.info(f\"LLM call for refining section with feedback completed.\")\n",
    "            logging.info(f\"Refinement token usage: {cb.total_tokens} (Prompt: {cb.prompt_tokens}, Completion: {cb.completion_tokens}, Cost: ${cb.total_cost:.4f})\")\n",
    "\n",
    "        logging.info(f\"Section refined with feedback.\")\n",
    "        return response.content\n",
    "\n",
    "class DocumentEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluates individual sections for correctness, clarity, and compliance.\n",
    "    Provides feedback for improvement.\n",
    "    \"\"\"\n",
    "    def __init__(self, llm):\n",
    "        logging.info(\"Initializing DocumentEvaluator...\")\n",
    "        self.llm = llm\n",
    "        logging.info(\"DocumentEvaluator initialized.\")\n",
    "\n",
    "    def evaluate_section(self, draft_section):\n",
    "        logging.info(\"Evaluating section...\")\n",
    "        system_template = \"You are an independent reviewer of a policy draft.\"\n",
    "        user_template = (\n",
    "            \"Draft Section:\\n{draft_section}\\n\\n\"\n",
    "            \"1) Evaluate correctness, clarity, and compliance.\\n\"\n",
    "            \"2) Suggest improvements.\\n\"\n",
    "            \"3) Provide concise feedback.\"\n",
    "        )\n",
    "\n",
    "        system_msg = SystemMessagePromptTemplate.from_template(system_template)\n",
    "        human_msg = HumanMessagePromptTemplate.from_template(user_template)\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_msg, human_msg])\n",
    "        formatted_prompt = chat_prompt.format_messages(draft_section=draft_section)\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            response = self.llm.invoke(formatted_prompt)\n",
    "            logging.info(\"LLM call for section evaluation completed.\")\n",
    "            logging.info(f\"Evaluation token usage: {cb.total_tokens} (Prompt: {cb.prompt_tokens}, Completion: {cb.completion_tokens}, Cost: ${cb.total_cost:.4f})\")\n",
    "\n",
    "        logging.info(\"Section evaluated, feedback generated.\")\n",
    "        return response.content\n",
    "\n",
    "class FinalReviewer:\n",
    "    \"\"\"\n",
    "    Conducts a holistic review of the entire assembled policy.\n",
    "    Ensures coherence, consistency, and completeness.\n",
    "    \"\"\"\n",
    "    def __init__(self, llm):\n",
    "        logging.info(\"Initializing FinalReviewer...\")\n",
    "        self.llm = llm\n",
    "        logging.info(\"FinalReviewer initialized.\")\n",
    "\n",
    "    def review_document(self, full_document):\n",
    "        logging.info(\"Conducting final document review...\")\n",
    "        system_template = (\n",
    "            \"You are a senior reviewer conducting a final review \"\n",
    "            \"of the entire policy.\"\n",
    "        )\n",
    "        user_template = (\n",
    "            \"Below is the entire policy:\\n\\n\"\n",
    "            \"{full_document}\\n\\n\"\n",
    "            \"1) Check consistency and completeness.\\n\"\n",
    "            \"2) Suggest improvements.\\n\"\n",
    "            \"3) Provide the final revised text.\"\n",
    "        )\n",
    "\n",
    "        system_msg = SystemMessagePromptTemplate.from_template(system_template)\n",
    "        human_msg = HumanMessagePromptTemplate.from_template(user_template)\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_msg, human_msg])\n",
    "        formatted_prompt = chat_prompt.format_messages(full_document=full_document)\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            response = self.llm.invoke(formatted_prompt)\n",
    "            logging.info(\"LLM call for final document review completed.\")\n",
    "            logging.info(f\"Final review token usage: {cb.total_tokens} (Prompt: {cb.prompt_tokens}, Completion: {cb.completion_tokens}, Cost: ${cb.total_cost:.4f})\")\n",
    "\n",
    "        logging.info(\"Final document review completed.\")\n",
    "        return response.content\n",
    "\n",
    "class CreditRiskPolicyAgent:\n",
    "    \"\"\"\n",
    "    Orchestrates creation, section-level evaluation, refinement,\n",
    "    and a final holistic review.\n",
    "    \"\"\"\n",
    "    def __init__(self, api_key, chroma_collection):\n",
    "        logging.info(\"Initializing CreditRiskPolicyAgent...\")\n",
    "        embeddings = OpenAIEmbeddings(api_key=api_key)\n",
    "        store = Chroma(collection_name=chroma_collection, embedding_function=embeddings)\n",
    "\n",
    "        # ChatOpenAI is the newer recommended approach for OpenAI chat models\n",
    "        self.llm = ChatOpenAI(model_name=\"gpt-4\", api_key=api_key)\n",
    "\n",
    "        self.creator = DocumentCreator(self.llm, store.as_retriever())\n",
    "        self.evaluator = DocumentEvaluator(self.llm)\n",
    "        self.final_reviewer = FinalReviewer(self.llm)\n",
    "        logging.info(\"CreditRiskPolicyAgent initialized.\")\n",
    "\n",
    "    def build_policy(self, overall_desc, toc_dict):\n",
    "        logging.info(\"Starting policy building process...\")\n",
    "        refined_sections = {}\n",
    "        total_tokens_policy = 0\n",
    "        total_cost_policy = 0\n",
    "\n",
    "        for key, s_info in toc_dict.items():\n",
    "            s_title = s_info[\"title\"]\n",
    "            s_desc = s_info[\"description\"]\n",
    "            logging.info(f\"Processing section: '{s_title}'...\")\n",
    "\n",
    "            # 1) Draft\n",
    "            draft = self.creator.draft_section(overall_desc, s_title, s_desc)\n",
    "            # 2) Evaluate\n",
    "            feedback = self.evaluator.evaluate_section(draft)\n",
    "            # 3) Refine\n",
    "            refined = self.creator.refine_with_feedback(draft, feedback)\n",
    "            refined_sections[s_title] = refined\n",
    "            logging.info(f\"Section '{s_title}' processing complete.\")\n",
    "\n",
    "        # Combine all sections for final review\n",
    "        entire_doc = \"\"\n",
    "        for s_title, text in refined_sections.items():\n",
    "            entire_doc += f\"{s_title}\\n\\n{text}\\n\\n\"\n",
    "\n",
    "        final_policy_output = self.final_reviewer.review_document(entire_doc)\n",
    "\n",
    "        final_policy = final_policy_output\n",
    "        logging.info(\"Policy building process completed.\")\n",
    "        return final_policy\n",
    "\n",
    "def main():\n",
    "    api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    chroma_collection = \"risk_universe\"\n",
    "\n",
    "    overall_doc_description = (\n",
    "        \"This document sets out the company's Credit Risk Policy, \"\n",
    "        \"aligned with Basel III and internal guidelines.\"\n",
    "    )\n",
    "\n",
    "    toc = {\n",
    "        \"section_1\": {\n",
    "            \"title\": \"Introduction and Scope\",\n",
    "            \"description\": \"High-level overview, disclaimers, and scope\"\n",
    "        },\n",
    "        \"section_2\": {\n",
    "            \"title\": \"Definitions and Terminology\",\n",
    "            \"description\": \"Define all key terms\"\n",
    "        },\n",
    "        \"section_3\": {\n",
    "            \"title\": \"Risk Assessment Methodology\",\n",
    "            \"description\": \"Methods for identifying, measuring, scoring risks\"\n",
    "        },\n",
    "        \"section_4\": {\n",
    "            \"title\": \"Credit Approval Workflow\",\n",
    "            \"description\": \"Steps, roles, responsibilities for approval\"\n",
    "        },\n",
    "        \"section_5\": {\n",
    "            \"title\": \"Monitoring and Reporting\",\n",
    "            \"description\": \"Ongoing monitoring frameworks and reporting\"\n",
    "        },\n",
    "        \"section_6\": {\n",
    "            \"title\": \"Governance and Compliance\",\n",
    "            \"description\": \"Governance structure and compliance needs\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    agent = CreditRiskPolicyAgent(api_key, chroma_collection)\n",
    "    logging.info(\"Starting to build final document...\")\n",
    "    final_document = agent.build_policy(overall_doc_description, toc)\n",
    "    logging.info(\"Final document build complete.\")\n",
    "    print(\"\\nFINAL POLICY DOCUMENT:\\n\")\n",
    "    print(final_document)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
