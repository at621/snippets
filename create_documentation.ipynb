{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e322809-b24f-472c-9703-86a8f23d391d",
   "metadata": {},
   "source": [
    "### System for generating, evaluating, and refining risk policy documents\n",
    "\n",
    "This code implements a system for generating, evaluating, and refining risk policy documents   \n",
    "using large language models (LLMs) and vector databases. The primary goal is to automate the   \n",
    "creation of high-quality policy documents that adhere to regulatory standards and organizational needs.   \n",
    "The system is designed with a modular architecture, dividing the task into distinct, manageable components,   \n",
    "each with a specific role in the document creation pipeline.\n",
    "\n",
    "The core components of the system include: a DocumentCreator responsible for drafting and refining policy   \n",
    "sections based on retrieved context, a DocumentEvaluator which provides feedback on the correctness, clarity,   \n",
    "and compliance of individual sections, and a FinalReviewer that ensures the overall document is coherent,   \n",
    "consistent, and complete. Additionally, a ChecklistEvaluator assesses the final document against a predefined   \n",
    "checklist of requirements, providing a structured analysis for quality assurance. These components work   \n",
    "together in a sequential manner, building and refining the document iteratively.\n",
    "\n",
    "The process starts with the DocumentCreator retrieving relevant context from a Chroma vector database using a   \n",
    "query constructed from the overall document description, section title, and section description. This context   \n",
    "is then passed to the LLM to draft an initial section using Markdown, optimized for clarity and future LaTeX   \n",
    "conversion. The generated draft undergoes an evaluation phase by the DocumentEvaluator, which identifies areas   \n",
    "for improvement. This feedback is then used by the DocumentCreator to refine the section, producing a more   \n",
    "polished result. This draft, evaluate, refine process is repeated for each section in a table of contents.\n",
    "\n",
    "Once all sections have been created, they are assembled into a complete document. The FinalReviewer then   \n",
    "conducts a holistic assessment of the entire policy, checking for consistency and completeness, and suggesting   \n",
    "improvements to the overall structure. After a final review, a ChecklistEvaluator assesses the document against   \n",
    "a predefined checklist of requirements. The results of this checklist evaluation are returned as a Pandas   \n",
    "DataFrame, providing a structured overview of the document’s compliance.\n",
    "\n",
    "To facilitate the transformation of the generated document, a LatexConverter converts the Markdown output into   \n",
    "a well-formatted LaTeX document, complete with a table of contents, sections, and escaped special characters.   \n",
    "The LaTeX document is then compiled into a PDF, allowing for a high-quality, professional output. This output   \n",
    "process ensures the generated policies are visually appealing and ready for further use.\n",
    "\n",
    "Finally, the main script initializes the components, retrieves the necessary configuration from environment   \n",
    "variables, and then orchestrates the entire policy generation process. It manages all the stages described,   \n",
    "from the context retrieval through to the final PDF compilation, logging all prompts, responses, and other   \n",
    "metrics for performance analysis. The program also outputs the final document, the checklist evaluation   \n",
    "results as a pandas dataframe and the cost and tokens used for each step of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646076a1-bc07-43fc-8d99-730d1e071c1e",
   "metadata": {},
   "source": [
    "#### High-level possible improvement points\n",
    "At a high level, the agent already covers the core lifecycle of drafting sections, evaluating them,   \n",
    "refining with feedback, and finally reviewing holistically. From a “principal components” standpoint,  \n",
    "here are some additional building blocks you might consider:\n",
    "\n",
    "**Workflow and Approval Stage**  \n",
    "Currently, the agent handles creation, evaluation, and refinement. Yet many policy and document    \n",
    "workflows require an approval stage involving multiple stakeholders. A “Workflow Orchestrator” or    \n",
    "“Approval Manager” could track different approval gates, requiring sign-off from designated roles. \n",
    "\n",
    "**Policy Governance / Versioning System**  \n",
    "Version control is often critical when generating business or regulatory documents. Keeping an    \n",
    "auditable record of changes (including timestamps, reasons for changes, and who initiated them)    \n",
    "would be valuable. A component that automatically logs versions, diffs, and rationales behind    \n",
    "revisions would address governance needs.\n",
    "\n",
    "**Compliance Validator**  \n",
    "Beyond evaluating clarity and correctness, you might want a module that specifically checks compliance    \n",
    "with relevant regulations (e.g., Basel III specifics, local legal requirements). This validator could    \n",
    "highlight noncompliant or missing elements, referencing actual regulatory texts.\n",
    "\n",
    "**Risk Assessment and Gap Analysis**  \n",
    "Especially for a Credit Risk Policy, an automated gap analysis module could compare the drafted document   \n",
    "to recognized regulatory frameworks or best practices libraries. It would flag coverage gaps where   \n",
    "crucial topics or sections are missing, prompting the user to address them.\n",
    "\n",
    "**Specialized Knowledge Base Integration**  \n",
    "If you have proprietary or domain-specific data sources beyond Chroma, you might integrate additional   \n",
    "retrievers and vector stores, or even direct API calls to knowledge bases or compliance databases.   \n",
    "This ensures the final document aligns with all internal and external mandates.\n",
    "\n",
    "**Collaboration Layer**  \n",
    "Large-scale policy creation often involves multiple contributors. A collaboration layer could store   \n",
    "and display each contributor’s feedback, track assigned tasks, and unify the agent’s automated   \n",
    "suggestions with the team’s manual edits.\n",
    "\n",
    "**Monitoring & Auditing**  \n",
    "Adding a logging, alerting, and audit trail for each stage of the document creation could be crucial  \n",
    "for compliance. It would track who ran what step, which context or data was retrieved, how many tokens   \n",
    "were used, and what the final text was at each iteration.\n",
    "\n",
    "All of these represent higher-level, “principal” enhancements that would strengthen the end-to-end   \n",
    "management and governance of your policy creation workflow, rather than just tweaking or refining the existing steps.\n",
    "\n",
    "\n",
    "#### Lower-level Missing Components / Improvement Points:\n",
    "1) Error Handling: No explicit exception handling (e.g., API failures, empty retrievals).\n",
    "2) Async or Parallelism: Large documents might benefit from concurrency or async retrieval/drafting.\n",
    "3) Prompt Customization: Could add parameters like temperature, max_tokens, or system-level instructions.\n",
    "4) Token/Cost Tracking: Nice approach, but consider storing usage stats persistently or summarizing them.\n",
    "5) Versioning / Persistence: Consider storing intermediate drafts or retrieval results (e.g., DB or file).\n",
    "6) Validation / Testing: A minimal testing suite for each class would help ensure reliability.\n",
    "7) Security & Confidentiality: If dealing with sensitive policies, ensure secure storage of API keys/logs.\n",
    "8) Explanation / Guidance to End Users: Possibly add docstrings or usage instructions for each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c05dad68-3585-48cc-a92b-fc9312ad228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "from typing import Any, Dict, List\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "import pandas as pd  # Import pandas\n",
    "import re\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Ensure no limitations in Jupyter Notebook output\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e537cb-ffc2-4845-b336-0d1949a56df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametrisation\n",
    "LOG_FILE = \"openai_history.json\"\n",
    "PDF_OUTPUT = \"policy.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dd9aa46-57d2-40b0-974e-0ee001fcbd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentCreator:\n",
    "    \"\"\"\n",
    "    Creates and refines policy sections.\n",
    "    Pulls context from Chroma by passing heading, overall doc, and section desc as the query.\n",
    "    \"\"\"\n",
    "    def __init__(self, llm, retriever):\n",
    "        logging.info(\"Initializing DocumentCreator...\")\n",
    "        self.llm = llm\n",
    "        self.retriever = retriever\n",
    "        logging.info(\"DocumentCreator initialized.\")\n",
    "\n",
    "    def retrieve_context(self, overall_desc, section_title, section_desc):\n",
    "        logging.info(f\"Retrieving context for section: '{section_title}'...\")\n",
    "        query_text = (\n",
    "            f\"Overall Document: {overall_desc}\\n\"\n",
    "            f\"Section Title: {section_title}\\n\"\n",
    "            f\"Section Description: {section_desc}\"\n",
    "        )\n",
    "        # Retrieve relevant documents\n",
    "        #Updated get relevant documents to .invoke()\n",
    "        docs = self.retriever.invoke(query_text)\n",
    "       \n",
    "        if not docs:\n",
    "            logging.warning(f\"No context retrieved from Chroma. Using dummy context.\")\n",
    "            context = \"This is a dummy context. Please ensure your ChromaDB is populated for better results.\"\n",
    "        else:\n",
    "            context = \"\\n\".join([d.page_content for d in docs])\n",
    "            logging.info(f\"Context length for section: '{section_title}'`: {len(context)} characters.\")\n",
    "       \n",
    "        return context\n",
    "\n",
    "    def draft_section(self, overall_desc, section_title, section_desc):\n",
    "        logging.info(f\"Drafting section: '{section_title}'...\")\n",
    "        # Create a chat prompt with system and user instructions\n",
    "        system_template = (\n",
    "            \"You are drafting a Credit Risk Policy section. \"\n",
    "            \"Incorporate best practices and references. \"\n",
    "            \"Format your output as Markdown, emphasizing clarity and readability for LaTeX conversion. \"\n",
    "            \"Use markdown headings (e.g., # for sections, ## for subsections) for structure and organize information logically. \"\n",
    "            \"Ensure the text is in well-structured paragraphs with correct grammar and punctuation.\"\n",
    "        )\n",
    "        user_template = (\n",
    "            \"Section Title: {section_title}\\n\"\n",
    "            \"Overall Description: {overall_desc}\\n\"\n",
    "            \"Section Description: {section_desc}\\n\"\n",
    "            \"Relevant Context:\\n{context}\\n\\n\"\n",
    "            \"Draft the policy section using markdown.\"\n",
    "        )\n",
    "\n",
    "        system_msg = SystemMessagePromptTemplate.from_template(system_template)\n",
    "        human_msg = HumanMessagePromptTemplate.from_template(user_template)\n",
    "\n",
    "        # Retrieve any relevant context from Chroma\n",
    "        context = self.retrieve_context(overall_desc, section_title, section_desc)\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_msg, human_msg])\n",
    "        formatted_prompt = chat_prompt.format_messages(\n",
    "            section_title=section_title,\n",
    "            overall_desc=overall_desc,\n",
    "            section_desc=section_desc,\n",
    "            context=context\n",
    "        )\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            response = self.llm.invoke(formatted_prompt)\n",
    "            logging.info(f\"LLM call for drafting section '{section_title}' completed.\")\n",
    "            logging.info(f\"Drafting section '{section_title}'\")\n",
    "            logging.info(f\"Token usage: {cb.total_tokens} (Prompt: {cb.prompt_tokens}, Completion: {cb.completion_tokens}, Cost: ${cb.total_cost:.4f})\")\n",
    "            draft_cost = cb.total_cost\n",
    "            draft_tokens = cb.total_tokens\n",
    "\n",
    "        self.log_message(formatted_prompt, response.content, \"draft\")\n",
    "        logging.info(f\"Section '{section_title}' drafted.\")\n",
    "        return response.content, draft_cost, draft_tokens # Return cost and tokens\n",
    "\n",
    "    def refine_with_feedback(self, draft, feedback):\n",
    "        logging.info(f\"Refining section with feedback...\")\n",
    "        system_template = (\n",
    "            \"You are refining a policy section draft based on reviewer feedback. \"\n",
    "            \"Format your output as Markdown, ensuring that the structure is consistent with the original draft. \"\n",
    "            \"Use markdown headings and structured paragraphs for clarity and easy conversion to LaTeX. \"\n",
    "            \"Address all feedback points carefully.\"\n",
    "        )\n",
    "        user_template = (\n",
    "            \"Original Draft:\\n{draft}\\n\\n\"\n",
    "            \"Reviewer Feedback:\\n{feedback}\\n\\n\"\n",
    "            \"Refine the draft, addressing all feedback. Preserve original structure.\"\n",
    "        )\n",
    "\n",
    "        system_msg = SystemMessagePromptTemplate.from_template(system_template)\n",
    "        human_msg = HumanMessagePromptTemplate.from_template(user_template)\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_msg, human_msg])\n",
    "        formatted_prompt = chat_prompt.format_messages(draft=draft, feedback=feedback)\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            response = self.llm.invoke(formatted_prompt)\n",
    "            logging.info(f\"LLM call for refining section with feedback completed.\")\n",
    "            logging.info(f\"Refinement token usage: {cb.total_tokens} (Prompt: {cb.prompt_tokens}, Completion: {cb.completion_tokens}, Cost: ${cb.total_cost:.4f})\")\n",
    "            refine_cost = cb.total_cost\n",
    "            refine_tokens = cb.total_tokens\n",
    "        \n",
    "        self.log_message(formatted_prompt, response.content, \"refine\")\n",
    "        logging.info(f\"Section refined with feedback.\")\n",
    "        return response.content, refine_cost, refine_tokens # Return cost and tokens\n",
    "    \n",
    "    def log_message(self, prompt, response, stage):\n",
    "        \"\"\"Logs the prompt and response to the JSON file immediately.\"\"\"\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        log_entry = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"stage\": stage,\n",
    "            \"prompt\": [msg.content for msg in prompt],\n",
    "            \"response\": response,\n",
    "        }\n",
    "        with open(LOG_FILE, 'a', encoding='utf-8') as f:\n",
    "            json.dump(log_entry, f, indent=2)\n",
    "            f.write('\\n')  # Add a newline to separate JSON objects in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9404ee-c3cc-47f8-b96f-772a8cd29bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluates individual sections for correctness, clarity, and compliance.\n",
    "    Provides feedback for improvement.\n",
    "    \"\"\"\n",
    "    def __init__(self, llm):\n",
    "        logging.info(\"Initializing DocumentEvaluator...\")\n",
    "        self.llm = llm\n",
    "        logging.info(\"DocumentEvaluator initialized.\")\n",
    "\n",
    "    def evaluate_section(self, draft_section):\n",
    "        logging.info(\"Evaluating section...\")\n",
    "        system_template = \"You are an independent reviewer of a policy draft.\"\n",
    "        user_template = (\n",
    "            \"Draft Section:\\n{draft_section}\\n\\n\"\n",
    "            \"1) Evaluate correctness, clarity, and compliance.\\n\"\n",
    "            \"2) Suggest improvements to the structure and content for better LaTeX conversion, such as proper use of headings.\\n\" #Added\n",
    "            \"3) Provide concise feedback.\"\n",
    "        )\n",
    "\n",
    "        system_msg = SystemMessagePromptTemplate.from_template(system_template)\n",
    "        human_msg = HumanMessagePromptTemplate.from_template(user_template)\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_msg, human_msg])\n",
    "        formatted_prompt = chat_prompt.format_messages(draft_section=draft_section)\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            response = self.llm.invoke(formatted_prompt)\n",
    "            logging.info(\"LLM call for section evaluation completed.\")\n",
    "            logging.info(f\"Evaluation token usage: {cb.total_tokens} (Prompt: {cb.prompt_tokens}, Completion: {cb.completion_tokens}, Cost: ${cb.total_cost:.4f})\")\n",
    "            eval_cost = cb.total_cost\n",
    "            eval_tokens = cb.total_tokens\n",
    "\n",
    "        self.log_message(formatted_prompt, response.content, \"eval\")\n",
    "        logging.info(\"Section evaluated, feedback generated.\")\n",
    "        return response.content, eval_cost, eval_tokens # Return cost and tokens\n",
    "\n",
    "    def log_message(self, prompt, response, stage):\n",
    "        \"\"\"Logs the prompt and response to the JSON file immediately.\"\"\"\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        log_entry = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"stage\": stage,\n",
    "            \"prompt\": [msg.content for msg in prompt],\n",
    "            \"response\": response,\n",
    "        }\n",
    "        with open(LOG_FILE, 'a', encoding='utf-8') as f:\n",
    "            json.dump(log_entry, f, indent=2)\n",
    "            f.write('\\n')  # Add a newline to separate JSON objects in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f992472-c25e-4048-b389-6ef2662accd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalReviewer:\n",
    "    \"\"\"\n",
    "    Conducts a holistic review of the entire assembled policy.\n",
    "    Ensures coherence, consistency, and completeness.\n",
    "    \"\"\"\n",
    "    def __init__(self, llm):\n",
    "        logging.info(\"Initializing FinalReviewer...\")\n",
    "        self.llm = llm\n",
    "        logging.info(\"FinalReviewer initialized.\")\n",
    "\n",
    "    def review_document(self, full_document):\n",
    "        logging.info(\"Conducting final document review...\")\n",
    "        system_template = (\n",
    "            \"You are a senior reviewer conducting a final review \"\n",
    "            \"of the entire policy. \"\n",
    "            \"Format your output as Markdown, ensure proper structure with markdown headings.\"\n",
    "        )\n",
    "        user_template = (\n",
    "            \"Below is the entire policy:\\n\\n\"\n",
    "            \"{full_document}\\n\\n\"\n",
    "            \"1) Check consistency, completeness, and proper use of headings.\\n\"\n",
    "            \"2) Suggest improvements.\\n\"\n",
    "            \"3) Provide the final revised text. Make sure all text is in a readable format for latex conversion.\"\n",
    "        )\n",
    "\n",
    "        system_msg = SystemMessagePromptTemplate.from_template(system_template)\n",
    "        human_msg = HumanMessagePromptTemplate.from_template(user_template)\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_msg, human_msg])\n",
    "        formatted_prompt = chat_prompt.format_messages(full_document=full_document)\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            response = self.llm.invoke(formatted_prompt)\n",
    "            logging.info(\"LLM call for final document review completed.\")\n",
    "            logging.info(f\"Final review token usage: {cb.total_tokens} (Prompt: {cb.prompt_tokens}, Completion: {cb.completion_tokens}, Cost: ${cb.total_cost:.4f})\")\n",
    "            final_review_cost = cb.total_cost\n",
    "            final_review_tokens = cb.total_tokens\n",
    "        \n",
    "        self.log_message(formatted_prompt, response.content, \"final_review\")\n",
    "        logging.info(\"Final document review completed.\")\n",
    "        return response.content, final_review_cost, final_review_tokens # Return cost and tokens\n",
    "    \n",
    "    def log_message(self, prompt, response, stage):\n",
    "        \"\"\"Logs the prompt and response to the JSON file immediately.\"\"\"\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        log_entry = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"stage\": stage,\n",
    "            \"prompt\": [msg.content for msg in prompt],\n",
    "            \"response\": response,\n",
    "        }\n",
    "        with open(LOG_FILE, 'a', encoding='utf-8') as f:\n",
    "            json.dump(log_entry, f, indent=2)\n",
    "            f.write('\\n')  # Add a newline to separate JSON objects in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3840cda9-6365-4f72-8c87-6f70b53088fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChecklistItem(BaseModel):\n",
    "    \"\"\"Pydantic model for a single checklist item.\"\"\"\n",
    "    requirement: str = Field(description=\"The requirement from the checklist\")\n",
    "    status: str = Field(description=\"yes/no/partially\")\n",
    "    reasoning: str = Field(description=\"The reasoning for the status\")\n",
    "\n",
    "class ChecklistOutput(BaseModel):\n",
    "    \"\"\"Pydantic model for a list of checklist items.\"\"\"\n",
    "    items: List[ChecklistItem] = Field(description=\"List of checklist items\")\n",
    "\n",
    "class ChecklistEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluates the final document against a checklist of requirements.\n",
    "    Returns results as a Pandas DataFrame directly.\n",
    "    \"\"\"\n",
    "    def __init__(self, llm):\n",
    "        logging.info(\"Initializing ChecklistEvaluator...\")\n",
    "        self.llm = llm\n",
    "        logging.info(\"ChecklistEvaluator initialized.\")\n",
    "        self.output_parser = PydanticOutputParser(pydantic_object=ChecklistOutput)\n",
    "\n",
    "    def _fix_json(self, json_str: str) -> str:\n",
    "        \"\"\"Attempt to fix common JSON errors.\"\"\"\n",
    "        # Remove any text before the first bracket\n",
    "        json_str = json_str[json_str.find('['):]\n",
    "        json_str = re.sub(r'\\\\', '', json_str)\n",
    "        return json_str\n",
    "\n",
    "    def evaluate_with_checklist(self, document, checklist):\n",
    "        logging.info(\"Evaluating document against checklist...\")\n",
    "        system_template = (\n",
    "            \"You are an expert reviewer evaluating a policy document \"\n",
    "            \"against a checklist of requirements. \"\n",
    "            \"Provide the output in a structured JSON format.\"\n",
    "        )\n",
    "        user_template = (\n",
    "            \"Policy Document:\\n{document}\\n\\n\"\n",
    "            \"Checklist of Requirements:\\n{checklist}\\n\\n\"\n",
    "            \"For each requirement, determine if it has been incorporated \"\n",
    "            \"into the document (yes/no/partially), and give a reasoning \"\n",
    "            \"for your opinion. Provide your reasoning in a clear and concise manner.\\n\\n\"\n",
    "            \"Output in the following JSON format: \\n{format_instructions}\\n\"\n",
    "        )\n",
    "\n",
    "        system_msg = SystemMessagePromptTemplate.from_template(system_template)\n",
    "        human_msg = HumanMessagePromptTemplate.from_template(user_template)\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_msg, human_msg])\n",
    "        formatted_prompt = chat_prompt.format_messages(\n",
    "            document=document,\n",
    "            checklist=checklist,\n",
    "            format_instructions = self.output_parser.get_format_instructions()\n",
    "        )\n",
    "        \n",
    "        with get_openai_callback() as cb:\n",
    "            response = self.llm.invoke(formatted_prompt)\n",
    "            logging.info(\"LLM call for checklist evaluation completed.\")\n",
    "            logging.info(f\"Checklist evaluation token usage: {cb.total_tokens} (Prompt: {cb.prompt_tokens}, Completion: {cb.completion_tokens}, Cost: ${cb.total_cost:.4f})\")\n",
    "            checklist_eval_cost = cb.total_cost\n",
    "            checklist_eval_tokens = cb.total_tokens\n",
    "        \n",
    "        # Attempt to parse the response multiple times and fix it, if possible\n",
    "        max_attempts = 3\n",
    "        for attempt in range(max_attempts):\n",
    "           try:\n",
    "                parsed_response = self.output_parser.parse(response.content)\n",
    "                df = pd.DataFrame([item.model_dump() for item in parsed_response.items])\n",
    "                self.log_message(formatted_prompt, response.content, \"checklist_eval\")\n",
    "                logging.info(\"Checklist evaluation completed successfully.\")\n",
    "                return df, checklist_eval_cost, checklist_eval_tokens\n",
    "           except Exception as e:\n",
    "                logging.warning(f\"Attempt {attempt+1}/{max_attempts} failed to parse checklist eval response: {e}\")\n",
    "                \n",
    "                # Try to fix the json and parse again\n",
    "                fixed_json = self._fix_json(response.content)\n",
    "                try:\n",
    "                    parsed_response = self.output_parser.parse(fixed_json)\n",
    "                    df = pd.DataFrame([item.model_dump() for item in parsed_response.items])\n",
    "                    self.log_message(formatted_prompt, response.content, \"checklist_eval\")\n",
    "                    logging.info(\"Checklist evaluation completed successfully after fixing JSON.\")\n",
    "                    return df, checklist_eval_cost, checklist_eval_tokens\n",
    "                except Exception as e:\n",
    "                      logging.warning(f\"Attempt {attempt+1}/{max_attempts} failed to parse checklist eval response after fix: {e}\")\n",
    "        \n",
    "        # If all attempts fail log the error and return an empty df\n",
    "        logging.error(\"Failed to parse checklist eval response, returning empty dataframe\")\n",
    "        self.log_message(formatted_prompt, response.content, \"checklist_eval_fail\")\n",
    "        return pd.DataFrame(), checklist_eval_cost, checklist_eval_tokens\n",
    "\n",
    "    \n",
    "    def log_message(self, prompt, response, stage):\n",
    "        \"\"\"Logs the prompt and response to the JSON file immediately.\"\"\"\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        log_entry = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"stage\": stage,\n",
    "            \"prompt\": [msg.content for msg in prompt],\n",
    "            \"response\": response,\n",
    "        }\n",
    "        with open(LOG_FILE, 'a', encoding='utf-8') as f:\n",
    "            json.dump(log_entry, f, indent=2)\n",
    "            f.write('\\n')  # Add a newline to separate JSON objects in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b122375a-6b9c-4717-a236-b366f68e2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatexConverter:\n",
    "    def __init__(self):\n",
    "        logging.info(\"Initializing LatexConverter...\")\n",
    "        logging.info(\"LatexConverter initialized.\")\n",
    "\n",
    "    def _escape_latex(self, text):\n",
    "        \"\"\"Escapes LaTeX special characters.\"\"\"\n",
    "         # List of special characters that need to be escaped in LaTeX.\n",
    "        specials = {\n",
    "            '&':  r'\\&',\n",
    "            '%':  r'\\%',\n",
    "            '$':  r'\\$',\n",
    "            '#':  r'\\#',\n",
    "            '_':  r'\\_',\n",
    "            '{':  r'\\{',\n",
    "            '}':  r'\\}',\n",
    "            '~':  r'\\textasciitilde{}',\n",
    "            '^':  r'\\textasciicircum{}',\n",
    "            '\\\\': r'\\textbackslash{}',\n",
    "            '<':  r'\\textless{}',\n",
    "            '>':  r'\\textgreater{}'\n",
    "        }\n",
    "        for char, escaped in specials.items():\n",
    "            text = text.replace(char, escaped)\n",
    "        return text\n",
    "\n",
    "    def markdown_to_latex(self, markdown_text, toc_list):\n",
    "        \"\"\"Converts a document in markdown format to LaTeX format.\"\"\"\n",
    "        latex_output = \"\"\n",
    "\n",
    "        # Add Document Class and Packages\n",
    "        latex_output += \"\\\\documentclass{article}\\n\"\n",
    "        latex_output += \"\\\\usepackage[utf8]{inputenc}\\n\"\n",
    "        latex_output += \"\\\\usepackage{graphicx}\\n\"  # Include graphicx package\n",
    "        latex_output += \"\\\\usepackage{hyperref}\\n\" #For hyperreferences\n",
    "        latex_output += \"\\\\title{Credit Risk Policy Document}\\n\"\n",
    "        latex_output += \"\\\\author{AI-Generated Document}\\n\"\n",
    "        latex_output += \"\\\\date{\\\\today}\\n\"\n",
    "        latex_output += \"\\\\begin{document}\\n\"\n",
    "        latex_output += \"\\\\maketitle\\n\"\n",
    "        \n",
    "        # Add table of contents\n",
    "        latex_output += \"\\\\tableofcontents\\n\"\n",
    "\n",
    "        # Process table of contents first\n",
    "        for title in toc_list:\n",
    "            # Escape LaTeX special characters in ToC titles\n",
    "             safe_title = self._escape_latex(title)\n",
    "             latex_output += f\"\\\\section{{{safe_title}}}\\n\"\n",
    "    \n",
    "        # Convert markdown into latex\n",
    "        lines = markdown_text.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"# \"):\n",
    "                line = line[2:]\n",
    "                safe_line = self._escape_latex(line)\n",
    "                latex_output += f\"\\\\section{{{safe_line}}}\\n\" #No * as this will appear in ToC\n",
    "            elif line.startswith(\"## \"):\n",
    "                line = line[3:]\n",
    "                safe_line = self._escape_latex(line)\n",
    "                latex_output += f\"\\\\subsection{{{safe_line}}}\\n\" #No * as this will appear in ToC\n",
    "            elif line.startswith(\"### \"):\n",
    "                line = line[4:]\n",
    "                safe_line = self._escape_latex(line)\n",
    "                latex_output += f\"\\\\subsubsection{{{safe_line}}}\\n\" #No * as this will appear in ToC\n",
    "            elif line:\n",
    "                #Handle bold and italics\n",
    "                line = line.replace(\"**\",\"\\\\textbf{\")\n",
    "                line = line.replace(\"}\", \"}\") # Correctly close bold text\n",
    "                line = line.replace(\"*\",\"\\\\textit{\")\n",
    "                line = line.replace(\"}\", \"}\") # Correctly close italics text\n",
    "                line = line.replace(\"``\",\"`\") # Remove as not needed\n",
    "                safe_line = self._escape_latex(line)\n",
    "                latex_output += f\"{safe_line}\\n\\n\" #Add paragraph\n",
    "            else:\n",
    "                 latex_output += \"\\n\" #Keep blank lines\n",
    "        latex_output += \"\\\\end{document}\\n\" #End document\n",
    "        return latex_output\n",
    "\n",
    "    def generate_pdf(self, latex_string, output_path=\"output.pdf\"):\n",
    "        \"\"\"Generates a PDF file from a LaTeX string.\"\"\"\n",
    "        try:\n",
    "            logging.info(\"Generating PDF...\")\n",
    "            # Create a temporary LaTeX file\n",
    "            with open(\"temp.tex\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(latex_string)\n",
    "\n",
    "            # Compile the LaTeX file into a PDF using pdflatex\n",
    "            subprocess.run([\"pdflatex\", \"temp.tex\"], check=True, capture_output=True)\n",
    "            logging.info(\"PDF compilation completed successfully\")\n",
    "\n",
    "            # Move the resulting PDF to the desired path\n",
    "            os.rename(\"temp.pdf\", output_path)\n",
    "            logging.info(f\"PDF saved to {output_path}\")\n",
    "\n",
    "            #Clean up the latex files\n",
    "            os.remove(\"temp.tex\")\n",
    "            os.remove(\"temp.log\")\n",
    "            os.remove(\"temp.aux\")\n",
    "            \n",
    "        except subprocess.CalledProcessError as e:\n",
    "             logging.error(f\"Error compiling LaTeX to PDF: {e}\")\n",
    "             logging.error(f\"LaTeX compilation error output: {e.stderr.decode('utf-8')}\")\n",
    "\n",
    "        except Exception as e:\n",
    "             logging.error(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9eadf-2578-4011-b51a-c2379ad52a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 07:35:06,147 - INFO - Initializing CreditRiskPolicyAgent...\n",
      "2025-01-25 07:35:07,047 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-01-25 07:35:08,063 - INFO - Initializing DocumentCreator...\n",
      "2025-01-25 07:35:08,064 - INFO - DocumentCreator initialized.\n",
      "2025-01-25 07:35:08,064 - INFO - Initializing DocumentEvaluator...\n",
      "2025-01-25 07:35:08,065 - INFO - DocumentEvaluator initialized.\n",
      "2025-01-25 07:35:08,065 - INFO - Initializing FinalReviewer...\n",
      "2025-01-25 07:35:08,065 - INFO - FinalReviewer initialized.\n",
      "2025-01-25 07:35:08,066 - INFO - Initializing ChecklistEvaluator...\n",
      "2025-01-25 07:35:08,066 - INFO - ChecklistEvaluator initialized.\n",
      "2025-01-25 07:35:08,067 - INFO - CreditRiskPolicyAgent initialized.\n",
      "2025-01-25 07:35:08,067 - INFO - Starting to build final document...\n",
      "2025-01-25 07:35:08,069 - INFO - Starting policy building process...\n",
      "2025-01-25 07:35:08,069 - INFO - Processing section: 'Introduction and Scope'...\n",
      "2025-01-25 07:35:08,069 - INFO - Drafting section: 'Introduction and Scope'...\n",
      "2025-01-25 07:35:08,070 - INFO - Retrieving context for section: 'Introduction and Scope'...\n",
      "2025-01-25 07:35:08,450 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 07:35:08,457 - WARNING - No context retrieved from Chroma. Using dummy context.\n",
      "2025-01-25 07:35:25,157 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 07:35:25,166 - INFO - LLM call for drafting section 'Introduction and Scope' completed.\n",
      "2025-01-25 07:35:25,167 - INFO - Drafting section 'Introduction and Scope'\n",
      "2025-01-25 07:35:25,167 - INFO - Token usage: 624 (Prompt: 145, Completion: 479, Cost: $0.0331)\n",
      "2025-01-25 07:35:25,168 - INFO - Section 'Introduction and Scope' drafted.\n",
      "2025-01-25 07:35:25,169 - INFO - Evaluating section...\n",
      "2025-01-25 07:35:35,870 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 07:35:35,873 - INFO - LLM call for section evaluation completed.\n",
      "2025-01-25 07:35:35,873 - INFO - Evaluation token usage: 832 (Prompt: 540, Completion: 292, Cost: $0.0337)\n",
      "2025-01-25 07:35:35,875 - INFO - Section evaluated, feedback generated.\n",
      "2025-01-25 07:35:35,875 - INFO - Refining section with feedback...\n",
      "2025-01-25 07:35:51,020 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 07:35:51,065 - INFO - LLM call for refining section with feedback completed.\n",
      "2025-01-25 07:35:51,065 - INFO - Refinement token usage: 1526 (Prompt: 848, Completion: 678, Cost: $0.0661)\n",
      "2025-01-25 07:35:51,067 - INFO - Section refined with feedback.\n",
      "2025-01-25 07:35:51,067 - INFO - Section 'Introduction and Scope' processing complete.\n",
      "2025-01-25 07:35:51,068 - INFO - Processing section: 'Credit Risk Appetite and Strategy'...\n",
      "2025-01-25 07:35:51,068 - INFO - Drafting section: 'Credit Risk Appetite and Strategy'...\n",
      "2025-01-25 07:35:51,069 - INFO - Retrieving context for section: 'Credit Risk Appetite and Strategy'...\n",
      "2025-01-25 07:35:51,593 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 07:35:51,597 - WARNING - No context retrieved from Chroma. Using dummy context.\n",
      "2025-01-25 07:41:38,287 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 07:41:38,290 - INFO - LLM call for drafting section 'Credit Risk Appetite and Strategy' completed.\n",
      "2025-01-25 07:41:38,290 - INFO - Drafting section 'Credit Risk Appetite and Strategy'\n",
      "2025-01-25 07:41:38,292 - INFO - Token usage: 693 (Prompt: 151, Completion: 542, Cost: $0.0370)\n",
      "2025-01-25 07:41:38,294 - INFO - Section 'Credit Risk Appetite and Strategy' drafted.\n",
      "2025-01-25 07:41:38,294 - INFO - Evaluating section...\n",
      "2025-01-25 07:46:00,158 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 07:46:00,162 - INFO - LLM call for section evaluation completed.\n",
      "2025-01-25 07:46:00,163 - INFO - Evaluation token usage: 912 (Prompt: 603, Completion: 309, Cost: $0.0366)\n",
      "2025-01-25 07:46:00,164 - INFO - Section evaluated, feedback generated.\n",
      "2025-01-25 07:46:00,165 - INFO - Refining section with feedback...\n"
     ]
    }
   ],
   "source": [
    "class CreditRiskPolicyAgent:\n",
    "    \"\"\"\n",
    "    Orchestrates creation, section-level evaluation, refinement,\n",
    "    and a final holistic review.\n",
    "    \"\"\"\n",
    "    def __init__(self, api_key, chroma_collection):\n",
    "        logging.info(\"Initializing CreditRiskPolicyAgent...\")\n",
    "        embeddings = OpenAIEmbeddings(api_key=api_key)\n",
    "        store = Chroma(collection_name=chroma_collection, embedding_function=embeddings)\n",
    "\n",
    "        # ChatOpenAI is the newer recommended approach for OpenAI chat models\n",
    "        self.llm = ChatOpenAI(model_name=\"gpt-4\", api_key=api_key)\n",
    "        \n",
    "        self.creator = DocumentCreator(self.llm, store.as_retriever())\n",
    "        self.evaluator = DocumentEvaluator(self.llm)\n",
    "        self.final_reviewer = FinalReviewer(self.llm)\n",
    "        self.checklist_evaluator = ChecklistEvaluator(self.llm)\n",
    "        logging.info(\"CreditRiskPolicyAgent initialized.\")\n",
    "\n",
    "    def build_policy(self, overall_desc, toc_dict, checklist):\n",
    "        logging.info(\"Starting policy building process...\")\n",
    "        refined_sections = {}\n",
    "        total_tokens_policy = 0 # Initialize total tokens\n",
    "        total_cost_policy = 0 # Initialize total cost\n",
    "        toc_list = []  #list to store titles for LaTeX ToC\n",
    "        \n",
    "        for key, s_info in toc_dict.items():\n",
    "            s_title = s_info[\"title\"]\n",
    "            s_desc = s_info[\"description\"]\n",
    "            logging.info(f\"Processing section: '{s_title}'...\")\n",
    "            toc_list.append(s_title) #Append the titles to the list\n",
    "\n",
    "            # 1) Draft\n",
    "            draft, draft_cost, draft_tokens = self.creator.draft_section(overall_desc, s_title, s_desc)\n",
    "            total_cost_policy += draft_cost # Accumulate cost\n",
    "            total_tokens_policy += draft_tokens # Accumulate tokens\n",
    "\n",
    "            # 2) Evaluate\n",
    "            feedback, eval_cost, eval_tokens = self.evaluator.evaluate_section(draft)\n",
    "            total_cost_policy += eval_cost # Accumulate cost\n",
    "            total_tokens_policy += eval_tokens # Accumulate tokens\n",
    "\n",
    "            # 3) Refine\n",
    "            refined, refine_cost, refine_tokens = self.creator.refine_with_feedback(draft, feedback)\n",
    "            refined_sections[s_title] = refined\n",
    "            total_cost_policy += refine_cost # Accumulate cost\n",
    "            total_tokens_policy += refine_tokens # Accumulate tokens\n",
    "            logging.info(f\"Section '{s_title}' processing complete.\")\n",
    "\n",
    "        # Combine all sections for final review\n",
    "        entire_doc = \"\"\n",
    "        for s_title, text in refined_sections.items():\n",
    "            entire_doc += f\"# {s_title}\\n\\n{text}\\n\\n\"\n",
    "\n",
    "        final_policy_output, final_review_cost, final_review_tokens = self.final_reviewer.review_document(entire_doc)\n",
    "        total_cost_policy += final_review_cost # Accumulate cost\n",
    "        total_tokens_policy += final_review_tokens # Accumulate tokens\n",
    "       \n",
    "        # Checklist Evaluation\n",
    "        checklist_evaluation, checklist_eval_cost, checklist_eval_tokens = self.checklist_evaluator.evaluate_with_checklist(final_policy_output, checklist)\n",
    "        total_cost_policy += checklist_eval_cost\n",
    "        total_tokens_policy += checklist_eval_tokens\n",
    "        \n",
    "        final_policy = final_policy_output\n",
    "        logging.info(\"Policy building process completed.\")\n",
    "        logging.info(f\"Total document creation cost: ${total_cost_policy:.4f}\") # Log total cost\n",
    "        logging.info(f\"Total tokens used for document creation: {total_tokens_policy}\") # Log total tokens\n",
    "        return final_policy, checklist_evaluation, toc_list\n",
    "\n",
    "def main():\n",
    "    api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    chroma_collection = \"risk_universe\"\n",
    "\n",
    "    overall_doc_description = (\n",
    "        \"This document sets out the company's Credit Risk Policy, \"\n",
    "        \"aligned with Basel III and internal guidelines.\"\n",
    "    )\n",
    "\n",
    "    toc = {\n",
    "        \"section_1\": {\n",
    "            \"title\": \"Introduction and Scope\",\n",
    "            \"description\": \"Define all key terms\"\n",
    "        },\n",
    "        \"section_2\":{\n",
    "            \"title\":\"Credit Risk Appetite and Strategy\",\n",
    "             \"description\":\"Define the organisations appetite for credit risk\"\n",
    "        },\n",
    "        \"section_3\": {\n",
    "            \"title\": \"Governance and Compliance\",\n",
    "            \"description\": \"Governance structure and compliance needs\"\n",
    "        }\n",
    "    }\n",
    "   \n",
    "    checklist = \"\"\"\n",
    "    1. The policy clearly states its objectives.\n",
    "    2. The policy aligns with Basel III regulatory requirements.\n",
    "    3. Key credit risk terms are clearly defined.\n",
    "    4. Roles and responsibilities for credit risk management are specified.\n",
    "    5. Credit approval process is clearly defined.\n",
    "    6. The policy covers credit risk assessment methodologies.\n",
    "    7. Credit monitoring and reporting procedures are outlined.\n",
    "    8. The policy addresses handling of problem loans and impairments.\n",
    "    9. The policy includes details on collateral management.\n",
    "    10. The policy has a process for regular review and updates.\n",
    "    \"\"\"\n",
    "\n",
    "    agent = CreditRiskPolicyAgent(api_key, chroma_collection)\n",
    "    logging.info(\"Starting to build final document...\")\n",
    "    final_document, checklist_evaluation, toc_list = agent.build_policy(overall_doc_description, toc, checklist)\n",
    "    logging.info(\"Final document build complete.\")\n",
    "       \n",
    "    # Convert to latex and generate pdf\n",
    "    latex_converter = LatexConverter()\n",
    "    latex_document = latex_converter.markdown_to_latex(final_document, toc_list)\n",
    "    latex_converter.generate_pdf(latex_document, PDF_OUTPUT)\n",
    "    logging.info(\"PDF creation completed\")\n",
    "\n",
    "    return final_document, checklist_evaluation\n",
    "\n",
    "final_document, checklist_evaluation = main()\n",
    "checklist_evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
