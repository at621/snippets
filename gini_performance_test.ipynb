{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Confidence bands around AUC\n",
        "\n",
        "The sensitivity, specificity and accuracy are proportions, thus the according confidence intervals can be calculated by using standard methods for proportions. Two types of 95% confidence intervals are generally constructed around proportions: asymptotic and exact 95% confidence interval. The exact confidence interval is constructed by using binomial distribution to reach an exact estimate. Asymptotic confidence interval is calculated by assuming a normal approximation of the sampling distribution.\n",
        "\n",
        "The choice of these two types of confidence interval depends on whether the sample proportion is a good approximation of normal distribution. If the number of event is very small or if the sample size is very small, the normal assumption cannot be met. Thus, exact confident interval is desired.\n",
        "\n",
        "\n",
        "### References\n",
        "- https://www.anaesthetist.com/mnm/stats/roc/Findex.htm\n",
        "- https://www.bis.org/publ/bcbs_wp14.htm\n",
        "- https://lexjansen.com/nesug/nesug10/hl/hl07.pdf\n",
        "- https://tbrieder.org/epidata/course_reading/b_altman.pdf"
      ],
      "metadata": {
        "id": "qZd96b9ka_Po"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VlKDXJ0QndkC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import time\n",
        "from scipy.stats import norm\n",
        "import scipy.stats\n",
        "from scipy import stats\n",
        "\n",
        "# Settings\n",
        "pd.set_option('display.float_format', '{:.3f}'.format)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A. Generate test dataset"
      ],
      "metadata": {
        "id": "zGeZNYfgI3X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_independent_data(n_samples):\n",
        "    np.random.seed(42)  # Seed for reproducibility\n",
        "\n",
        "    # Generate random scores normally distributed around 0, scale 1\n",
        "    scores = np.random.randn(n_samples)\n",
        "\n",
        "    # Generate defaults, where higher scores have a lower probability of default\n",
        "    # Using a logistic function to map scores to probabilities\n",
        "    probabilities = 1 / (1 + np.exp(-scores))\n",
        "    defaults = np.random.binomial(1, probabilities)\n",
        "\n",
        "    # Create DataFrame\n",
        "    data = pd.DataFrame({\n",
        "        'score': scores,\n",
        "        'default': defaults\n",
        "    })\n",
        "    return data\n",
        "\n",
        "# Generate a base dataset\n",
        "base_dataset_size = 100  # A reasonable starting size for our tests\n",
        "base_data = generate_independent_data(base_dataset_size)"
      ],
      "metadata": {
        "id": "qq3Bv4p0q6id"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B. Create algorithms for confidence bands"
      ],
      "metadata": {
        "id": "4PhDKPl6I852"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_gini(scores, defaults):\n",
        "    \"\"\"Calculate the Gini coefficient from scores and defaults using the ROC AUC method.\"\"\"\n",
        "    # return 2 * roc_auc_score(defaults, scores) - 1\n",
        "    return roc_auc_score(defaults, scores)\n",
        "\n",
        "def bootstrap_conf_band(data, n_iterations=100, scale_factor=1):\n",
        "    scores = data['score']\n",
        "    defaults = data['default']\n",
        "    original_size = len(data)\n",
        "    bootstrap_size = int(original_size * scale_factor)\n",
        "\n",
        "    original_gini = calculate_gini(scores, defaults)\n",
        "    bootstrap_ginis = []\n",
        "\n",
        "    # Perform bootstrapping\n",
        "    for _ in range(n_iterations):\n",
        "        bootstrapped_scores, bootstrapped_defaults = resample(\n",
        "            scores, defaults, n_samples=bootstrap_size, replace=True)\n",
        "        gini = calculate_gini(bootstrapped_scores, bootstrapped_defaults)\n",
        "        bootstrap_ginis.append(gini)\n",
        "\n",
        "    # Calculate the 5% and 95% confidence intervals\n",
        "    lower_bound = np.percentile(bootstrap_ginis, 5)\n",
        "    upper_bound = np.percentile(bootstrap_ginis, 95)\n",
        "    average_gini = np.mean(bootstrap_ginis)\n",
        "\n",
        "    return {\n",
        "        'original_gini': original_gini,\n",
        "        'average_bootstrapped_gini': average_gini,\n",
        "        '5%_confidence_level': lower_bound,\n",
        "        '95%_confidence_level': upper_bound\n",
        "    }"
      ],
      "metadata": {
        "id": "eM2epdRLn085"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hanley_conf_band(data):\n",
        "    # https://github.com/andrija-djurovic/PDtoolkit/blob/main/R/14_DISCRIMINATORY_POWER.R\n",
        "    pd = data['score']\n",
        "    y = data['default']\n",
        "\n",
        "    auc = roc_auc_score(y, pd)\n",
        "    q1 = auc / (2 - auc)\n",
        "    q2 = (2 * auc**2) / (1 + auc)\n",
        "    n1 = sum(y == 1)\n",
        "    n2 = sum(y == 0)\n",
        "    auc_se = np.sqrt((auc * (1 - auc) + (n1 - 1) * (q1 - auc**2) + (n2 - 1) * (q2 - auc**2)) / (n1 * n2))\n",
        "\n",
        "    return {\n",
        "        'original_gini': auc,\n",
        "        'average_bootstrapped_gini': 0,\n",
        "        '5%_confidence_level': auc - 1.96 * auc_se,\n",
        "        '95%_confidence_level': auc + 1.96 * auc_se,\n",
        "    }"
      ],
      "metadata": {
        "id": "gjD1RrbxJFLc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AUC comparison adapted from\n",
        "# https://github.com/Netflix/vmaf/\n",
        "def compute_midrank(x):\n",
        "    \"\"\"Computes midranks.\n",
        "    Args:\n",
        "       x - a 1D numpy array\n",
        "    Returns:\n",
        "       array of midranks\n",
        "    \"\"\"\n",
        "    J = np.argsort(x)\n",
        "    Z = x[J]\n",
        "    N = len(x)\n",
        "    T = np.zeros(N, dtype=float)\n",
        "    i = 0\n",
        "    while i < N:\n",
        "        j = i\n",
        "        while j < N and Z[j] == Z[i]:\n",
        "            j += 1\n",
        "        T[i:j] = 0.5*(i + j - 1)\n",
        "        i = j\n",
        "    T2 = np.empty(N, dtype=float)\n",
        "    # Note(kazeevn) +1 is due to Python using 0-based indexing\n",
        "    # instead of 1-based in the AUC formula in the paper\n",
        "    T2[J] = T + 1\n",
        "    return T2\n",
        "\n",
        "\n",
        "def compute_midrank_weight(x, sample_weight):\n",
        "    \"\"\"Computes midranks.\n",
        "    Args:\n",
        "       x - a 1D numpy array\n",
        "    Returns:\n",
        "       array of midranks\n",
        "    \"\"\"\n",
        "    J = np.argsort(x)\n",
        "    Z = x[J]\n",
        "    cumulative_weight = np.cumsum(sample_weight[J])\n",
        "    N = len(x)\n",
        "    T = np.zeros(N, dtype=float)\n",
        "    i = 0\n",
        "    while i < N:\n",
        "        j = i\n",
        "        while j < N and Z[j] == Z[i]:\n",
        "            j += 1\n",
        "        T[i:j] = cumulative_weight[i:j].mean()\n",
        "        i = j\n",
        "    T2 = np.empty(N, dtype=float)\n",
        "    T2[J] = T\n",
        "    return T2\n",
        "\n",
        "\n",
        "def fastDeLong(predictions_sorted_transposed, label_1_count, sample_weight):\n",
        "    if sample_weight is None:\n",
        "        return fastDeLong_no_weights(predictions_sorted_transposed, label_1_count)\n",
        "    else:\n",
        "        return fastDeLong_weights(predictions_sorted_transposed, label_1_count, sample_weight)\n",
        "\n",
        "\n",
        "def fastDeLong_weights(predictions_sorted_transposed, label_1_count, sample_weight):\n",
        "    \"\"\"\n",
        "    The fast version of DeLong's method for computing the covariance of\n",
        "    unadjusted AUC.\n",
        "    Args:\n",
        "       predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]\n",
        "          sorted such as the examples with label \"1\" are first\n",
        "    Returns:\n",
        "       (AUC value, DeLong covariance)\n",
        "    Reference:\n",
        "     @article{sun2014fast,\n",
        "       title={Fast Implementation of DeLong's Algorithm for\n",
        "              Comparing the Areas Under Correlated Receiver Oerating Characteristic Curves},\n",
        "       author={Xu Sun and Weichao Xu},\n",
        "       journal={IEEE Signal Processing Letters},\n",
        "       volume={21},\n",
        "       number={11},\n",
        "       pages={1389--1393},\n",
        "       year={2014},\n",
        "       publisher={IEEE}\n",
        "     }\n",
        "    \"\"\"\n",
        "    # Short variables are named as they are in the paper\n",
        "    m = label_1_count\n",
        "    n = predictions_sorted_transposed.shape[1] - m\n",
        "    positive_examples = predictions_sorted_transposed[:, :m]\n",
        "    negative_examples = predictions_sorted_transposed[:, m:]\n",
        "    k = predictions_sorted_transposed.shape[0]\n",
        "\n",
        "    tx = np.empty([k, m], dtype=float)\n",
        "    ty = np.empty([k, n], dtype=float)\n",
        "    tz = np.empty([k, m + n], dtype=float)\n",
        "    for r in range(k):\n",
        "        tx[r, :] = compute_midrank_weight(positive_examples[r, :], sample_weight[:m])\n",
        "        ty[r, :] = compute_midrank_weight(negative_examples[r, :], sample_weight[m:])\n",
        "        tz[r, :] = compute_midrank_weight(predictions_sorted_transposed[r, :], sample_weight)\n",
        "    total_positive_weights = sample_weight[:m].sum()\n",
        "    total_negative_weights = sample_weight[m:].sum()\n",
        "    pair_weights = np.dot(sample_weight[:m, np.newaxis], sample_weight[np.newaxis, m:])\n",
        "    total_pair_weights = pair_weights.sum()\n",
        "    aucs = (sample_weight[:m]*(tz[:, :m] - tx)).sum(axis=1) / total_pair_weights\n",
        "    v01 = (tz[:, :m] - tx[:, :]) / total_negative_weights\n",
        "    v10 = 1. - (tz[:, m:] - ty[:, :]) / total_positive_weights\n",
        "    sx = np.cov(v01)\n",
        "    sy = np.cov(v10)\n",
        "    delongcov = sx / m + sy / n\n",
        "    return aucs, delongcov\n",
        "\n",
        "\n",
        "def fastDeLong_no_weights(predictions_sorted_transposed, label_1_count):\n",
        "    \"\"\"\n",
        "    The fast version of DeLong's method for computing the covariance of\n",
        "    unadjusted AUC.\n",
        "    Args:\n",
        "       predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]\n",
        "          sorted such as the examples with label \"1\" are first\n",
        "    Returns:\n",
        "       (AUC value, DeLong covariance)\n",
        "    Reference:\n",
        "     @article{sun2014fast,\n",
        "       title={Fast Implementation of DeLong's Algorithm for\n",
        "              Comparing the Areas Under Correlated Receiver Oerating\n",
        "              Characteristic Curves},\n",
        "       author={Xu Sun and Weichao Xu},\n",
        "       journal={IEEE Signal Processing Letters},\n",
        "       volume={21},\n",
        "       number={11},\n",
        "       pages={1389--1393},\n",
        "       year={2014},\n",
        "       publisher={IEEE}\n",
        "     }\n",
        "    \"\"\"\n",
        "    # Short variables are named as they are in the paper\n",
        "    m = label_1_count\n",
        "    n = predictions_sorted_transposed.shape[1] - m\n",
        "    positive_examples = predictions_sorted_transposed[:, :m]\n",
        "    negative_examples = predictions_sorted_transposed[:, m:]\n",
        "    k = predictions_sorted_transposed.shape[0]\n",
        "\n",
        "    tx = np.empty([k, m], dtype=float)\n",
        "    ty = np.empty([k, n], dtype=float)\n",
        "    tz = np.empty([k, m + n], dtype=float)\n",
        "    for r in range(k):\n",
        "        tx[r, :] = compute_midrank(positive_examples[r, :])\n",
        "        ty[r, :] = compute_midrank(negative_examples[r, :])\n",
        "        tz[r, :] = compute_midrank(predictions_sorted_transposed[r, :])\n",
        "    aucs = tz[:, :m].sum(axis=1) / m / n - float(m + 1.0) / 2.0 / n\n",
        "    v01 = (tz[:, :m] - tx[:, :]) / n\n",
        "    v10 = 1.0 - (tz[:, m:] - ty[:, :]) / m\n",
        "    sx = np.cov(v01)\n",
        "    sy = np.cov(v10)\n",
        "    delongcov = sx / m + sy / n\n",
        "    return aucs, delongcov\n",
        "\n",
        "\n",
        "def calc_pvalue(aucs, sigma):\n",
        "    \"\"\"Computes log(10) of p-values.\n",
        "    Args:\n",
        "       aucs: 1D array of AUCs\n",
        "       sigma: AUC DeLong covariances\n",
        "    Returns:\n",
        "       log10(pvalue)\n",
        "    \"\"\"\n",
        "    l = np.array([[1, -1]])\n",
        "    z = np.abs(np.diff(aucs)) / np.sqrt(np.dot(np.dot(l, sigma), l.T))\n",
        "    return np.log10(2) + scipy.stats.norm.logsf(z, loc=0, scale=1) / np.log(10)\n",
        "\n",
        "\n",
        "def compute_ground_truth_statistics(ground_truth, sample_weight):\n",
        "    assert np.array_equal(np.unique(ground_truth), [0, 1])\n",
        "    order = (-ground_truth).argsort()\n",
        "    label_1_count = int(ground_truth.sum())\n",
        "    if sample_weight is None:\n",
        "        ordered_sample_weight = None\n",
        "    else:\n",
        "        ordered_sample_weight = sample_weight[order]\n",
        "\n",
        "    return order, label_1_count, ordered_sample_weight\n",
        "\n",
        "\n",
        "def delong_roc_variance(ground_truth, predictions, sample_weight=None):\n",
        "    \"\"\"\n",
        "    Computes ROC AUC variance for a single set of predictions\n",
        "    Args:\n",
        "       ground_truth: np.array of 0 and 1\n",
        "       predictions: np.array of floats of the probability of being class 1\n",
        "    \"\"\"\n",
        "    order, label_1_count, ordered_sample_weight = compute_ground_truth_statistics(\n",
        "        ground_truth, sample_weight)\n",
        "    predictions_sorted_transposed = predictions[np.newaxis, order]\n",
        "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count, ordered_sample_weight)\n",
        "    assert len(aucs) == 1, \"There is a bug in the code, please forward this to the developers\"\n",
        "    return aucs[0], delongcov\n",
        "\n",
        "\n",
        "def delong_conf_band(data):\n",
        "    scores = data['score'].to_numpy()\n",
        "    defaults = data['default'].to_numpy()\n",
        "\n",
        "    auc, auc_cov = delong_roc_variance(\n",
        "        defaults, scores)\n",
        "\n",
        "    auc_std = np.sqrt(auc_cov)\n",
        "    alpha = .95\n",
        "    lower_upper_q = np.abs(np.array([0, 1]) - (1 - alpha) / 2)\n",
        "\n",
        "    ci = stats.norm.ppf(\n",
        "        lower_upper_q,\n",
        "        loc=auc,\n",
        "        scale=auc_std)\n",
        "\n",
        "    return {\n",
        "        'original_gini': auc,\n",
        "        'average_bootstrapped_gini': 0,\n",
        "        '5%_confidence_level': ci[0],\n",
        "        '95%_confidence_level': ci[1],\n",
        "    }"
      ],
      "metadata": {
        "id": "_3R7nRGSTjAU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C. Run algorithms"
      ],
      "metadata": {
        "id": "KBep7iZBJKYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup for testing using the new base_data\n",
        "dataset_sizes = [1, 10, 1000]  # Scale factors relative to original dataset size\n",
        "iterations = [100]  # Number of bootstrap iterations\n",
        "\n",
        "# List of functions\n",
        "functions = [bootstrap_conf_band, hanley_conf_band, delong_conf_band]\n",
        "\n",
        "results = []\n",
        "for func in functions:\n",
        "  for size in dataset_sizes:\n",
        "      for num_runs in iterations:\n",
        "          # Generate larger dataset based on the size factor\n",
        "          test_data = generate_independent_data(base_dataset_size * size)\n",
        "\n",
        "          start_time = time.time()\n",
        "\n",
        "          result = func(test_data)\n",
        "\n",
        "\n",
        "          end_time = time.time()\n",
        "          time_taken = end_time - start_time\n",
        "\n",
        "          conf_range = result['95%_confidence_level'] - result['5%_confidence_level']\n",
        "\n",
        "\n",
        "          function_name = func.__name__\n",
        "          results.append({\n",
        "              'Function': function_name,\n",
        "              'Scale Factor': size,\n",
        "              'Iterations': num_runs,\n",
        "              'Time (seconds)': time_taken,\n",
        "              'Dataset size': len(test_data),\n",
        "\n",
        "              'original_gini': result['original_gini'],\n",
        "              'confidence_range': conf_range,\n",
        "              '5%_confidence_level': result['5%_confidence_level'],\n",
        "              '95%_confidence_level': result['95%_confidence_level'],\n",
        "              'average_bootstrapped_gini': result['average_bootstrapped_gini'],\n",
        "          })\n",
        "\n",
        "# Convert results to a DataFrame for better visualization\n",
        "results_df = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "VOcIoB6ZJFFL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Format specific columns to show numbers with thousands separators\n",
        "formatted_df = results_df.style.format({\n",
        "    'Time (seconds)': '{:,.3f}',\n",
        "    'Dataset size': '{:,}',\n",
        "    'original_gini': '{:,.2%}',\n",
        "    'confidence_range': '{:,.2%}',\n",
        "    '5%_confidence_level': '{:,.2%}',\n",
        "    '95%_confidence_level': '{:,.2%}',\n",
        "    'average_bootstrapped_gini': '{:,.2%}',\n",
        "})\n",
        "\n",
        "# Display the formatted DataFrame\n",
        "formatted_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "Y89aLzBrJFC0",
        "outputId": "6d97c25c-d472-4210-e542-52edf95cd158"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7a024d4eb5e0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_d7715\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_d7715_level0_col0\" class=\"col_heading level0 col0\" >Function</th>\n",
              "      <th id=\"T_d7715_level0_col1\" class=\"col_heading level0 col1\" >Scale Factor</th>\n",
              "      <th id=\"T_d7715_level0_col2\" class=\"col_heading level0 col2\" >Iterations</th>\n",
              "      <th id=\"T_d7715_level0_col3\" class=\"col_heading level0 col3\" >Time (seconds)</th>\n",
              "      <th id=\"T_d7715_level0_col4\" class=\"col_heading level0 col4\" >Dataset size</th>\n",
              "      <th id=\"T_d7715_level0_col5\" class=\"col_heading level0 col5\" >original_gini</th>\n",
              "      <th id=\"T_d7715_level0_col6\" class=\"col_heading level0 col6\" >confidence_range</th>\n",
              "      <th id=\"T_d7715_level0_col7\" class=\"col_heading level0 col7\" >5%_confidence_level</th>\n",
              "      <th id=\"T_d7715_level0_col8\" class=\"col_heading level0 col8\" >95%_confidence_level</th>\n",
              "      <th id=\"T_d7715_level0_col9\" class=\"col_heading level0 col9\" >average_bootstrapped_gini</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_d7715_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_d7715_row0_col0\" class=\"data row0 col0\" >bootstrap_conf_band</td>\n",
              "      <td id=\"T_d7715_row0_col1\" class=\"data row0 col1\" >1</td>\n",
              "      <td id=\"T_d7715_row0_col2\" class=\"data row0 col2\" >100</td>\n",
              "      <td id=\"T_d7715_row0_col3\" class=\"data row0 col3\" >0.155</td>\n",
              "      <td id=\"T_d7715_row0_col4\" class=\"data row0 col4\" >100</td>\n",
              "      <td id=\"T_d7715_row0_col5\" class=\"data row0 col5\" >70.51%</td>\n",
              "      <td id=\"T_d7715_row0_col6\" class=\"data row0 col6\" >16.34%</td>\n",
              "      <td id=\"T_d7715_row0_col7\" class=\"data row0 col7\" >61.53%</td>\n",
              "      <td id=\"T_d7715_row0_col8\" class=\"data row0 col8\" >77.87%</td>\n",
              "      <td id=\"T_d7715_row0_col9\" class=\"data row0 col9\" >69.84%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d7715_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_d7715_row1_col0\" class=\"data row1 col0\" >bootstrap_conf_band</td>\n",
              "      <td id=\"T_d7715_row1_col1\" class=\"data row1 col1\" >10</td>\n",
              "      <td id=\"T_d7715_row1_col2\" class=\"data row1 col2\" >100</td>\n",
              "      <td id=\"T_d7715_row1_col3\" class=\"data row1 col3\" >0.190</td>\n",
              "      <td id=\"T_d7715_row1_col4\" class=\"data row1 col4\" >1,000</td>\n",
              "      <td id=\"T_d7715_row1_col5\" class=\"data row1 col5\" >73.74%</td>\n",
              "      <td id=\"T_d7715_row1_col6\" class=\"data row1 col6\" >4.69%</td>\n",
              "      <td id=\"T_d7715_row1_col7\" class=\"data row1 col7\" >71.26%</td>\n",
              "      <td id=\"T_d7715_row1_col8\" class=\"data row1 col8\" >75.95%</td>\n",
              "      <td id=\"T_d7715_row1_col9\" class=\"data row1 col9\" >73.70%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d7715_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_d7715_row2_col0\" class=\"data row2 col0\" >bootstrap_conf_band</td>\n",
              "      <td id=\"T_d7715_row2_col1\" class=\"data row2 col1\" >1000</td>\n",
              "      <td id=\"T_d7715_row2_col2\" class=\"data row2 col2\" >100</td>\n",
              "      <td id=\"T_d7715_row2_col3\" class=\"data row2 col3\" >6.053</td>\n",
              "      <td id=\"T_d7715_row2_col4\" class=\"data row2 col4\" >100,000</td>\n",
              "      <td id=\"T_d7715_row2_col5\" class=\"data row2 col5\" >73.62%</td>\n",
              "      <td id=\"T_d7715_row2_col6\" class=\"data row2 col6\" >0.52%</td>\n",
              "      <td id=\"T_d7715_row2_col7\" class=\"data row2 col7\" >73.39%</td>\n",
              "      <td id=\"T_d7715_row2_col8\" class=\"data row2 col8\" >73.91%</td>\n",
              "      <td id=\"T_d7715_row2_col9\" class=\"data row2 col9\" >73.66%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d7715_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_d7715_row3_col0\" class=\"data row3 col0\" >hanley_conf_band</td>\n",
              "      <td id=\"T_d7715_row3_col1\" class=\"data row3 col1\" >1</td>\n",
              "      <td id=\"T_d7715_row3_col2\" class=\"data row3 col2\" >100</td>\n",
              "      <td id=\"T_d7715_row3_col3\" class=\"data row3 col3\" >0.003</td>\n",
              "      <td id=\"T_d7715_row3_col4\" class=\"data row3 col4\" >100</td>\n",
              "      <td id=\"T_d7715_row3_col5\" class=\"data row3 col5\" >70.51%</td>\n",
              "      <td id=\"T_d7715_row3_col6\" class=\"data row3 col6\" >20.75%</td>\n",
              "      <td id=\"T_d7715_row3_col7\" class=\"data row3 col7\" >60.13%</td>\n",
              "      <td id=\"T_d7715_row3_col8\" class=\"data row3 col8\" >80.88%</td>\n",
              "      <td id=\"T_d7715_row3_col9\" class=\"data row3 col9\" >0.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d7715_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_d7715_row4_col0\" class=\"data row4 col0\" >hanley_conf_band</td>\n",
              "      <td id=\"T_d7715_row4_col1\" class=\"data row4 col1\" >10</td>\n",
              "      <td id=\"T_d7715_row4_col2\" class=\"data row4 col2\" >100</td>\n",
              "      <td id=\"T_d7715_row4_col3\" class=\"data row4 col3\" >0.002</td>\n",
              "      <td id=\"T_d7715_row4_col4\" class=\"data row4 col4\" >1,000</td>\n",
              "      <td id=\"T_d7715_row4_col5\" class=\"data row4 col5\" >73.74%</td>\n",
              "      <td id=\"T_d7715_row4_col6\" class=\"data row4 col6\" >6.17%</td>\n",
              "      <td id=\"T_d7715_row4_col7\" class=\"data row4 col7\" >70.66%</td>\n",
              "      <td id=\"T_d7715_row4_col8\" class=\"data row4 col8\" >76.83%</td>\n",
              "      <td id=\"T_d7715_row4_col9\" class=\"data row4 col9\" >0.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d7715_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_d7715_row5_col0\" class=\"data row5 col0\" >hanley_conf_band</td>\n",
              "      <td id=\"T_d7715_row5_col1\" class=\"data row5 col1\" >1000</td>\n",
              "      <td id=\"T_d7715_row5_col2\" class=\"data row5 col2\" >100</td>\n",
              "      <td id=\"T_d7715_row5_col3\" class=\"data row5 col3\" >0.060</td>\n",
              "      <td id=\"T_d7715_row5_col4\" class=\"data row5 col4\" >100,000</td>\n",
              "      <td id=\"T_d7715_row5_col5\" class=\"data row5 col5\" >73.62%</td>\n",
              "      <td id=\"T_d7715_row5_col6\" class=\"data row5 col6\" >0.61%</td>\n",
              "      <td id=\"T_d7715_row5_col7\" class=\"data row5 col7\" >73.31%</td>\n",
              "      <td id=\"T_d7715_row5_col8\" class=\"data row5 col8\" >73.93%</td>\n",
              "      <td id=\"T_d7715_row5_col9\" class=\"data row5 col9\" >0.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d7715_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_d7715_row6_col0\" class=\"data row6 col0\" >delong_conf_band</td>\n",
              "      <td id=\"T_d7715_row6_col1\" class=\"data row6 col1\" >1</td>\n",
              "      <td id=\"T_d7715_row6_col2\" class=\"data row6 col2\" >100</td>\n",
              "      <td id=\"T_d7715_row6_col3\" class=\"data row6 col3\" >0.001</td>\n",
              "      <td id=\"T_d7715_row6_col4\" class=\"data row6 col4\" >100</td>\n",
              "      <td id=\"T_d7715_row6_col5\" class=\"data row6 col5\" >70.51%</td>\n",
              "      <td id=\"T_d7715_row6_col6\" class=\"data row6 col6\" >20.25%</td>\n",
              "      <td id=\"T_d7715_row6_col7\" class=\"data row6 col7\" >60.38%</td>\n",
              "      <td id=\"T_d7715_row6_col8\" class=\"data row6 col8\" >80.63%</td>\n",
              "      <td id=\"T_d7715_row6_col9\" class=\"data row6 col9\" >0.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d7715_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_d7715_row7_col0\" class=\"data row7 col0\" >delong_conf_band</td>\n",
              "      <td id=\"T_d7715_row7_col1\" class=\"data row7 col1\" >10</td>\n",
              "      <td id=\"T_d7715_row7_col2\" class=\"data row7 col2\" >100</td>\n",
              "      <td id=\"T_d7715_row7_col3\" class=\"data row7 col3\" >0.004</td>\n",
              "      <td id=\"T_d7715_row7_col4\" class=\"data row7 col4\" >1,000</td>\n",
              "      <td id=\"T_d7715_row7_col5\" class=\"data row7 col5\" >73.74%</td>\n",
              "      <td id=\"T_d7715_row7_col6\" class=\"data row7 col6\" >6.08%</td>\n",
              "      <td id=\"T_d7715_row7_col7\" class=\"data row7 col7\" >70.71%</td>\n",
              "      <td id=\"T_d7715_row7_col8\" class=\"data row7 col8\" >76.78%</td>\n",
              "      <td id=\"T_d7715_row7_col9\" class=\"data row7 col9\" >0.00%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d7715_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_d7715_row8_col0\" class=\"data row8 col0\" >delong_conf_band</td>\n",
              "      <td id=\"T_d7715_row8_col1\" class=\"data row8 col1\" >1000</td>\n",
              "      <td id=\"T_d7715_row8_col2\" class=\"data row8 col2\" >100</td>\n",
              "      <td id=\"T_d7715_row8_col3\" class=\"data row8 col3\" >0.308</td>\n",
              "      <td id=\"T_d7715_row8_col4\" class=\"data row8 col4\" >100,000</td>\n",
              "      <td id=\"T_d7715_row8_col5\" class=\"data row8 col5\" >73.62%</td>\n",
              "      <td id=\"T_d7715_row8_col6\" class=\"data row8 col6\" >0.61%</td>\n",
              "      <td id=\"T_d7715_row8_col7\" class=\"data row8 col7\" >73.32%</td>\n",
              "      <td id=\"T_d7715_row8_col8\" class=\"data row8 col8\" >73.93%</td>\n",
              "      <td id=\"T_d7715_row8_col9\" class=\"data row8 col9\" >0.00%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}