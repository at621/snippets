{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install PySpark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykLmOfJtkDG7",
        "outputId": "06b57453-ba9e-4851-ee81-8ff9916ff8f9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PySpark in /usr/local/lib/python3.8/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (from PySpark) (0.10.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "WHh74H3Kf7IB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import wraps\n",
        "import time\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"test_regression\").getOrCreate()"
      ],
      "metadata": {
        "id": "05lGSWi1jYkG"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset\n",
        "observations = 500000\n",
        "\n",
        "target = np.random.binomial(n=1, p=0.2, size=(observations, 1))\n",
        "y = (target + np.random.normal(0, 0.1, size=(observations, 1)))\n",
        "z = (target + np.random.normal(0, 0.1, size=(observations, 1)))\n",
        "w = (target + np.random.normal(0, 0.1, size=(observations, 1)))\n",
        "df = pd.DataFrame(np.hstack([target, y, z, w]), \n",
        "                  columns=['target', 'y', 'z', 'w'])\n",
        "\n",
        "# Create train test datasets\n",
        "train = df.sample(frac=0.8, random_state=1)\n",
        "test = df.drop(train.index)\n",
        "\n",
        "# Convert to pyspark dataset\n",
        "spark_train = spark.createDataFrame(train)\n",
        "spark_test = spark.createDataFrame(test)"
      ],
      "metadata": {
        "id": "w3R-k49ngGKV"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create functions for timing, pyspark regression and statsmodels regression\n",
        "def timeit(func):\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "        print(f\"{func.__name__} took {elapsed_time:.2f} seconds to run.\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@timeit\n",
        "def logit_pyspark(var, train_data, test_data):\n",
        "  # create a VectorAssembler to combine the independent variables\n",
        "  assembler = VectorAssembler(inputCols=[var], outputCol='features')\n",
        "  train_spark = assembler.transform(train_data)\n",
        "  test_spark = assembler.transform(test_data)\n",
        "\n",
        "  # Create model\n",
        "  lr = LogisticRegression(featuresCol='features', labelCol='target')\n",
        "  model = lr.fit(train_spark)\n",
        "\n",
        "  # Test model\n",
        "  predictions = model.transform(test_spark)\n",
        "  evaluator = BinaryClassificationEvaluator(labelCol='target')\n",
        "  auc = evaluator.evaluate(predictions)\n",
        "  print(f\"Model with {var} as the independent variable has AUC of {auc:.2f}\")\n",
        "\n",
        "@timeit\n",
        "def logit_statmodels(train_df, test_df, var):\n",
        "  # Create model\n",
        "  logit_model = sm.Logit(train_df[['target']], train_df[[var]])\n",
        "  result = logit_model.fit(disp=0)  \n",
        "\n",
        "  # Create AUC\n",
        "  test['y_pred'] = result.predict(test_df[[var]])\n",
        "  auc = roc_auc_score(test_df['target'], test_df['y_pred'])\n",
        "  print(f\"Model with {var} as the independent variable has AUC of {auc:.2f}\")"
      ],
      "metadata": {
        "id": "7loXDkWlgGEm"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test everything\n",
        "vars = ['y', 'z', 'w']\n",
        "\n",
        "# Test pyspark regression\n",
        "for var in vars:\n",
        "  # logit_pyspark(var, spark_train, spark_test)\n",
        "  logit_statmodels(train, test, var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYXRG4qkmYqU",
        "outputId": "2854b33c-9034-446e-9985-634a5ce28ac4"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model with y as the independent variable has AUC of 1.00\n",
            "logit_statmodels took 0.39 seconds to run.\n",
            "Model with z as the independent variable has AUC of 1.00\n",
            "logit_statmodels took 0.40 seconds to run.\n",
            "Model with w as the independent variable has AUC of 1.00\n",
            "logit_statmodels took 0.36 seconds to run.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test everything\n",
        "vars = ['y', 'z', 'w']\n",
        "\n",
        "# Test pyspark regression\n",
        "for var in vars:\n",
        "  logit_pyspark(var, spark_train, spark_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6fyVTaCmYlh",
        "outputId": "31b2852d-bf8a-404f-9920-75a1fa39c7d8"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model with y as the independent variable has AUC of 1.00\n",
            "logit_pyspark took 30.03 seconds to run.\n",
            "Model with z as the independent variable has AUC of 1.00\n",
            "logit_pyspark took 12.85 seconds to run.\n",
            "Model with w as the independent variable has AUC of 1.00\n",
            "logit_pyspark took 11.17 seconds to run.\n"
          ]
        }
      ]
    }
  ]
}